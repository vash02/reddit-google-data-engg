[2024-04-30T09:55:20.562+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T09:55:20.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T09:55:20.571+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:55:20.571+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T09:55:22.855+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:55:22.846+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T09:55:22.857+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T09:55:22.920+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 2.383 seconds
[2024-04-30T09:55:55.710+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T09:55:55.734+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T09:55:55.821+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:55:55.808+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T09:55:59.861+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:55:59.850+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T09:55:59.864+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T09:55:59.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 5.282 seconds
[2024-04-30T09:56:30.498+0000] {processor.py:161} INFO - Started process (PID=33) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T09:56:30.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T09:56:30.556+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:56:30.546+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T09:56:34.448+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:56:34.441+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T09:56:34.449+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T09:56:34.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 4.378 seconds
[2024-04-30T09:57:09.246+0000] {processor.py:161} INFO - Started process (PID=35) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T09:57:09.285+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T09:57:09.458+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:57:09.428+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T09:57:16.791+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:57:16.785+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T09:57:17.220+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T09:57:17.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 8.802 seconds
[2024-04-30T09:57:55.093+0000] {processor.py:161} INFO - Started process (PID=37) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T09:57:55.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T09:57:55.195+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:57:55.182+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T09:57:58.769+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:57:58.761+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T09:57:58.771+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T09:57:58.982+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 4.101 seconds
[2024-04-30T09:58:31.215+0000] {processor.py:161} INFO - Started process (PID=39) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T09:58:31.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T09:58:31.343+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:58:31.321+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T09:58:35.128+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:58:35.103+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T09:58:35.129+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T09:58:35.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 4.397 seconds
[2024-04-30T09:59:07.126+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T09:59:07.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T09:59:07.420+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:59:07.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T09:59:15.448+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:59:15.445+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T09:59:15.449+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T09:59:16.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 9.359 seconds
[2024-04-30T09:59:47.025+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T09:59:47.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T09:59:47.163+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:59:47.158+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T09:59:56.959+0000] {logging_mixin.py:188} INFO - [2024-04-30T09:59:56.941+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T09:59:56.962+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T09:59:57.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 10.801 seconds
[2024-04-30T10:00:28.396+0000] {processor.py:161} INFO - Started process (PID=45) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:00:28.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:00:28.402+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:00:28.402+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:00:29.438+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:00:29.431+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T10:00:29.439+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:00:29.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.143 seconds
[2024-04-30T10:00:59.834+0000] {processor.py:161} INFO - Started process (PID=47) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:00:59.841+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:00:59.862+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:00:59.859+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:01:02.477+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:01:02.465+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T10:01:02.482+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:01:03.354+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 3.576 seconds
[2024-04-30T10:01:34.925+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:01:35.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:01:35.315+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:01:35.304+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:01:39.368+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:01:39.347+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, process_images
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    import cv2
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 181, in <module>
    bootstrap()
  File "/home/airflow/.local/lib/python3.9/site-packages/cv2/__init__.py", line 153, in bootstrap
    native_module = importlib.import_module("cv2")
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: libGL.so.1: cannot open shared object file: No such file or directory
[2024-04-30T10:01:39.374+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:01:39.679+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 4.881 seconds
[2024-04-30T10:02:12.166+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:02:12.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:02:12.548+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:02:12.523+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:18:36.404+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:18:36.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:18:36.415+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:18:36.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:18:39.615+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:18:39.609+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 7, in <module>
    import cv2
ModuleNotFoundError: No module named 'cv2'
[2024-04-30T10:18:39.618+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:18:39.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 3.393 seconds
[2024-04-30T10:19:21.404+0000] {processor.py:161} INFO - Started process (PID=28) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:19:21.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:19:21.418+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:19:21.417+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:19:22.911+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:19:22.905+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 7, in <module>
    import cv2
ModuleNotFoundError: No module named 'cv2'
[2024-04-30T10:19:22.913+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:19:22.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.554 seconds
[2024-04-30T10:19:53.640+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:19:53.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:19:53.673+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:19:53.661+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:19:55.706+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:19:55.704+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 7, in <module>
    import cv2
ModuleNotFoundError: No module named 'cv2'
[2024-04-30T10:19:55.707+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:19:55.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 2.234 seconds
[2024-04-30T10:20:26.265+0000] {processor.py:161} INFO - Started process (PID=32) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:20:26.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:20:26.290+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:26.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:20:27.649+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:20:27.785+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:27.784+0000] {override.py:1829} INFO - Created Permission View: can edit on DAG:etl_reddit_pipeline
[2024-04-30T10:20:27.789+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:27.789+0000] {override.py:1829} INFO - Created Permission View: can read on DAG:etl_reddit_pipeline
[2024-04-30T10:20:27.791+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:27.791+0000] {override.py:1829} INFO - Created Permission View: can delete on DAG:etl_reddit_pipeline
[2024-04-30T10:20:27.791+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:27.791+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:20:27.796+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:27.796+0000] {dag.py:3118} INFO - Creating ORM DAG for etl_reddit_pipeline
[2024-04-30T10:20:27.804+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:27.804+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-29 00:00:00+00:00, run_after=2024-04-30 00:00:00+00:00
[2024-04-30T10:20:27.818+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.607 seconds
[2024-04-30T10:20:58.191+0000] {processor.py:161} INFO - Started process (PID=34) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:20:58.193+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:20:58.198+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:58.197+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:20:58.625+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:20:58.635+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:58.635+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:20:58.645+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:20:58.645+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:20:58.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.493 seconds
[2024-04-30T10:21:28.927+0000] {processor.py:161} INFO - Started process (PID=36) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:21:28.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:21:28.934+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:21:28.933+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:21:29.326+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:21:29.380+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:21:29.380+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:21:29.389+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:21:29.389+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:21:29.396+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.484 seconds
[2024-04-30T10:21:59.963+0000] {processor.py:161} INFO - Started process (PID=38) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:21:59.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:21:59.981+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:21:59.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:22:00.400+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:22:00.432+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:00.431+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:22:00.444+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:00.444+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:22:00.453+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.505 seconds
[2024-04-30T10:22:30.749+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:22:30.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:22:30.757+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:30.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:22:31.261+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:22:31.284+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:31.284+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:22:31.296+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:22:31.296+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:22:31.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.571 seconds
[2024-04-30T10:23:01.687+0000] {processor.py:161} INFO - Started process (PID=42) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:23:01.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:23:01.691+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:23:01.690+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:23:02.126+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:23:02.149+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:23:02.149+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:23:02.161+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:23:02.161+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:23:02.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.492 seconds
[2024-04-30T10:23:32.500+0000] {processor.py:161} INFO - Started process (PID=44) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:23:32.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:23:32.504+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:23:32.503+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:23:32.925+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:23:32.944+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:23:32.944+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:23:32.956+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:23:32.956+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:23:32.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.474 seconds
[2024-04-30T10:24:03.458+0000] {processor.py:161} INFO - Started process (PID=46) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:24:03.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:24:03.467+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:03.467+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:24:03.830+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:24:03.836+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:03.835+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:24:03.846+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:03.846+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:24:03.856+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.415 seconds
[2024-04-30T10:24:34.269+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:24:34.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:24:34.283+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:34.280+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:24:34.700+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:24:34.758+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:34.757+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:24:34.767+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:24:34.767+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:24:34.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.522 seconds
[2024-04-30T10:25:05.082+0000] {processor.py:161} INFO - Started process (PID=50) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:25:05.083+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:25:05.086+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:05.086+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:25:05.471+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:25:05.487+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:05.487+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:25:05.496+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:05.496+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:25:05.502+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.435 seconds
[2024-04-30T10:25:35.904+0000] {processor.py:161} INFO - Started process (PID=52) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:25:35.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:25:35.908+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:35.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:25:36.340+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:25:36.360+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:36.359+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:25:36.372+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:25:36.371+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:25:36.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.487 seconds
[2024-04-30T10:26:06.912+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:26:06.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:26:06.927+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:06.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:26:07.333+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:26:07.358+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:07.357+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:26:07.369+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:07.369+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:26:07.377+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.478 seconds
[2024-04-30T10:26:37.724+0000] {processor.py:161} INFO - Started process (PID=56) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:26:37.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:26:37.729+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:37.729+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:26:38.151+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:26:38.172+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:38.171+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:26:38.183+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:26:38.183+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:26:38.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.488 seconds
[2024-04-30T10:27:08.566+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:27:08.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:27:08.574+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:08.573+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:27:08.970+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:27:08.988+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:08.988+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:27:08.999+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:08.999+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:27:09.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.473 seconds
[2024-04-30T10:27:39.422+0000] {processor.py:161} INFO - Started process (PID=60) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:27:39.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:27:39.434+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:39.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:27:39.905+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:27:39.927+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:39.927+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:27:39.938+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:27:39.937+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:27:39.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.546 seconds
[2024-04-30T10:28:10.318+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:28:10.320+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:28:10.324+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:10.323+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:28:10.896+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:28:10.916+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:10.916+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:28:10.927+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:10.927+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:28:10.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.637 seconds
[2024-04-30T10:28:41.305+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:28:41.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:28:41.308+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:41.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:28:42.228+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:28:42.252+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:42.252+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:28:42.268+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:28:42.268+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:28:42.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.981 seconds
[2024-04-30T10:29:12.755+0000] {processor.py:161} INFO - Started process (PID=66) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T10:29:12.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T10:29:12.763+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:29:12.762+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T10:29:16.638+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T10:29:16.935+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:29:16.931+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T10:29:16.974+0000] {logging_mixin.py:188} INFO - [2024-04-30T10:29:16.974+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T10:29:17.013+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 4.301 seconds
[2024-04-30T16:43:04.889+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:43:04.891+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:43:04.895+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:43:04.894+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:43:06.127+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:43:06.205+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:43:06.204+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:43:06.243+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:43:06.243+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-29 00:00:00+00:00, run_after=2024-04-30 00:00:00+00:00
[2024-04-30T16:43:06.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.388 seconds
[2024-04-30T16:43:37.096+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:43:37.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:43:37.120+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:43:37.116+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:43:42.247+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:43:43.019+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:43:43.001+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:43:43.116+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:43:43.115+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-29 00:00:00+00:00, run_after=2024-04-30 00:00:00+00:00
[2024-04-30T16:43:43.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 6.109 seconds
[2024-04-30T16:44:17.788+0000] {processor.py:161} INFO - Started process (PID=33) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:44:17.835+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:44:17.951+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:44:17.926+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:44:23.582+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:44:23.629+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:44:23.628+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:44:23.647+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:44:23.647+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-29 00:00:00+00:00, run_after=2024-04-30 00:00:00+00:00
[2024-04-30T16:44:23.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 6.881 seconds
[2024-04-30T16:54:07.378+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:54:07.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:54:07.382+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:54:07.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:54:08.536+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:54:08.789+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:54:08.788+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:54:08.931+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:54:08.930+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:54:08.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.593 seconds
[2024-04-30T16:54:40.203+0000] {processor.py:161} INFO - Started process (PID=46) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:54:40.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:54:40.296+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:54:40.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:54:44.455+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:54:44.541+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:54:44.540+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:54:44.614+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:54:44.614+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:54:44.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 4.629 seconds
[2024-04-30T16:55:11.577+0000] {processor.py:161} INFO - Started process (PID=28) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:55:11.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:55:11.585+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:55:11.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:55:12.946+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:55:13.121+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:55:13.120+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:55:13.267+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:55:13.266+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:55:13.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.722 seconds
[2024-04-30T16:55:43.885+0000] {processor.py:161} INFO - Started process (PID=30) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:55:43.886+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:55:43.900+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:55:43.898+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:55:45.036+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:55:45.063+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:55:45.062+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:55:45.078+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:55:45.078+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:55:45.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.237 seconds
[2024-04-30T16:56:15.324+0000] {processor.py:161} INFO - Started process (PID=32) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:56:15.326+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:56:15.329+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:56:15.328+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:56:15.762+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:56:15.818+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:56:15.818+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:56:15.827+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:56:15.827+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:56:15.834+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.521 seconds
[2024-04-30T16:56:46.255+0000] {processor.py:161} INFO - Started process (PID=34) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:56:46.257+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:56:46.259+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:56:46.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:56:46.772+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:56:46.797+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:56:46.797+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:56:46.808+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:56:46.808+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:56:46.820+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.575 seconds
[2024-04-30T16:57:17.053+0000] {processor.py:161} INFO - Started process (PID=36) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:57:17.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:57:17.061+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:57:17.061+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:57:17.554+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:57:17.583+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:57:17.582+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:57:17.594+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:57:17.594+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:57:17.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.574 seconds
[2024-04-30T16:57:48.034+0000] {processor.py:161} INFO - Started process (PID=38) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:57:48.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:57:48.040+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:57:48.039+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:57:48.451+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:57:48.468+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:57:48.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:57:48.477+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:57:48.477+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:57:48.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.467 seconds
[2024-04-30T16:58:18.755+0000] {processor.py:161} INFO - Started process (PID=40) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:58:18.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:58:18.761+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:58:18.761+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:58:19.171+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:58:19.187+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:58:19.187+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:58:19.196+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:58:19.196+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:58:19.204+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.465 seconds
[2024-04-30T16:58:49.601+0000] {processor.py:161} INFO - Started process (PID=42) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:58:49.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:58:49.607+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:58:49.606+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:58:50.016+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:58:50.032+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:58:50.031+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:58:50.041+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:58:50.041+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:58:50.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.489 seconds
[2024-04-30T16:59:20.407+0000] {processor.py:161} INFO - Started process (PID=44) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:59:20.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:59:20.414+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:59:20.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:59:20.819+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:59:20.833+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:59:20.833+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:59:20.843+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:59:20.843+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:59:20.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.459 seconds
[2024-04-30T16:59:51.257+0000] {processor.py:161} INFO - Started process (PID=46) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T16:59:51.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T16:59:51.265+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:59:51.264+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T16:59:51.687+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T16:59:51.701+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:59:51.700+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T16:59:51.710+0000] {logging_mixin.py:188} INFO - [2024-04-30T16:59:51.710+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T16:59:51.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.480 seconds
[2024-04-30T17:00:22.192+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:00:22.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:00:22.199+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:00:22.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:00:22.593+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:00:22.608+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:00:22.608+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:00:22.617+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:00:22.617+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:00:22.624+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.469 seconds
[2024-04-30T17:00:53.014+0000] {processor.py:161} INFO - Started process (PID=50) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:00:53.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:00:53.020+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:00:53.019+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:00:53.449+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:00:53.465+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:00:53.465+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:00:53.476+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:00:53.476+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:00:53.483+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.484 seconds
[2024-04-30T17:01:23.887+0000] {processor.py:161} INFO - Started process (PID=52) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:01:23.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:01:23.891+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:01:23.891+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:01:24.286+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:01:24.317+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:01:24.317+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:01:24.326+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:01:24.326+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:01:24.334+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.459 seconds
[2024-04-30T17:01:54.707+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:01:54.709+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:01:54.714+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:01:54.713+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:01:55.125+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:01:55.153+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:01:55.152+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:01:55.163+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:01:55.163+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:01:55.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.502 seconds
[2024-04-30T17:02:25.562+0000] {processor.py:161} INFO - Started process (PID=56) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:02:25.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:02:25.567+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:02:25.567+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:02:25.979+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:02:25.997+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:02:25.996+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:02:26.016+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:02:26.016+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:02:26.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.478 seconds
[2024-04-30T17:02:56.390+0000] {processor.py:161} INFO - Started process (PID=58) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:02:56.392+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:02:56.396+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:02:56.395+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:02:56.798+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:02:56.814+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:02:56.814+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:02:56.823+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:02:56.823+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:02:56.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.458 seconds
[2024-04-30T17:03:27.207+0000] {processor.py:161} INFO - Started process (PID=60) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:03:27.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:03:27.212+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:03:27.211+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:03:27.629+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:03:27.646+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:03:27.646+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:03:27.655+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:03:27.655+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:03:27.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.472 seconds
[2024-04-30T17:03:58.082+0000] {processor.py:161} INFO - Started process (PID=62) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:03:58.086+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:03:58.096+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:03:58.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:03:58.514+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:03:58.532+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:03:58.531+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:03:58.541+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:03:58.541+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:03:58.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.479 seconds
[2024-04-30T17:04:29.027+0000] {processor.py:161} INFO - Started process (PID=64) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:04:29.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:04:29.032+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:04:29.031+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:04:29.447+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:04:29.465+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:04:29.465+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:04:29.474+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:04:29.474+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:04:29.481+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.465 seconds
[2024-04-30T17:04:59.901+0000] {processor.py:161} INFO - Started process (PID=66) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:04:59.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:04:59.910+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:04:59.909+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:05:00.371+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:05:00.388+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:05:00.387+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:05:00.398+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:05:00.398+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:05:00.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.530 seconds
[2024-04-30T17:05:30.813+0000] {processor.py:161} INFO - Started process (PID=68) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:05:30.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:05:30.822+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:05:30.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:05:31.237+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:05:31.255+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:05:31.255+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:05:31.265+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:05:31.264+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:05:31.271+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.485 seconds
[2024-04-30T17:06:01.649+0000] {processor.py:161} INFO - Started process (PID=70) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:06:01.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:06:01.655+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:06:01.654+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:06:02.063+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:06:02.082+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:06:02.081+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:06:02.091+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:06:02.091+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:06:02.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.466 seconds
[2024-04-30T17:06:32.537+0000] {processor.py:161} INFO - Started process (PID=72) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:06:32.540+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:06:32.544+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:06:32.543+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:06:33.056+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:06:33.079+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:06:33.079+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:06:33.091+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:06:33.091+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:06:33.098+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.591 seconds
[2024-04-30T17:07:03.520+0000] {processor.py:161} INFO - Started process (PID=74) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:07:03.525+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:07:03.535+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:07:03.535+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:07:03.963+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:07:03.979+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:07:03.979+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:07:03.988+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:07:03.988+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:07:03.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.485 seconds
[2024-04-30T17:07:34.361+0000] {processor.py:161} INFO - Started process (PID=76) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:07:34.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:07:34.370+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:07:34.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:07:34.926+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:07:34.946+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:07:34.945+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:07:34.973+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:07:34.973+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:07:34.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.649 seconds
[2024-04-30T17:08:05.425+0000] {processor.py:161} INFO - Started process (PID=78) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:08:05.427+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:08:05.430+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:08:05.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:08:05.873+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:08:05.890+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:08:05.890+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:08:05.900+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:08:05.900+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:08:05.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.493 seconds
[2024-04-30T17:08:36.335+0000] {processor.py:161} INFO - Started process (PID=80) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:08:36.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:08:36.344+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:08:36.343+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:08:36.758+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:08:36.782+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:08:36.782+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:08:36.795+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:08:36.795+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:08:36.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.482 seconds
[2024-04-30T17:09:07.220+0000] {processor.py:161} INFO - Started process (PID=82) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:09:07.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:09:07.225+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:09:07.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:09:07.638+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:09:07.660+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:09:07.660+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:09:07.669+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:09:07.669+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:09:07.675+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.465 seconds
[2024-04-30T17:09:38.113+0000] {processor.py:161} INFO - Started process (PID=84) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:09:38.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:09:38.119+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:09:38.119+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:09:38.516+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:09:38.531+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:09:38.531+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:09:38.551+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:09:38.551+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:09:38.558+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.459 seconds
[2024-04-30T17:10:08.953+0000] {processor.py:161} INFO - Started process (PID=86) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:10:08.955+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:10:08.959+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:10:08.959+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:10:09.467+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:10:09.487+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:10:09.486+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:10:09.497+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:10:09.497+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:10:09.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.565 seconds
[2024-04-30T17:10:40.050+0000] {processor.py:161} INFO - Started process (PID=88) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:10:40.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:10:40.057+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:10:40.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:10:40.699+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:10:40.726+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:10:40.726+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:10:40.739+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:10:40.739+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:10:40.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.712 seconds
[2024-04-30T17:11:11.336+0000] {processor.py:161} INFO - Started process (PID=90) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:11:11.339+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:11:11.343+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:11:11.343+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:11:12.118+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:11:12.158+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:11:12.158+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:11:12.170+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:11:12.170+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:11:12.180+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.860 seconds
[2024-04-30T17:11:42.852+0000] {processor.py:161} INFO - Started process (PID=92) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:11:42.855+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:11:42.861+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:11:42.861+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:11:43.390+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:11:43.410+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:11:43.410+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:11:43.424+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:11:43.424+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:11:43.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.617 seconds
[2024-04-30T17:12:14.097+0000] {processor.py:161} INFO - Started process (PID=94) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:12:14.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:12:14.102+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:12:14.102+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:12:14.583+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:12:14.603+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:12:14.603+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:12:14.620+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:12:14.620+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:12:14.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.549 seconds
[2024-04-30T17:12:44.952+0000] {processor.py:161} INFO - Started process (PID=96) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:12:44.954+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:12:44.959+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:12:44.958+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:12:45.980+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:12:46.020+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:12:46.019+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:12:46.034+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:12:46.034+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:12:46.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.109 seconds
[2024-04-30T17:13:16.538+0000] {processor.py:161} INFO - Started process (PID=98) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:13:16.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:13:16.542+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:13:16.542+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:13:16.951+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:13:16.971+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:13:16.971+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:13:16.986+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:13:16.986+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:13:16.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.468 seconds
[2024-04-30T17:13:47.382+0000] {processor.py:161} INFO - Started process (PID=100) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:13:47.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:13:47.386+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:13:47.386+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:13:47.856+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:13:47.876+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:13:47.876+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:13:47.889+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:13:47.889+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:13:47.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.531 seconds
[2024-04-30T17:14:18.580+0000] {processor.py:161} INFO - Started process (PID=102) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:14:18.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:14:18.601+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:14:18.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:14:20.167+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:14:20.308+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:14:20.306+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:14:20.369+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:14:20.368+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:14:20.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.875 seconds
[2024-04-30T17:14:51.042+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:14:51.046+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:14:51.057+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:14:51.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:14:51.638+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:14:51.662+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:14:51.662+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:14:51.674+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:14:51.673+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:14:51.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.677 seconds
[2024-04-30T17:15:22.339+0000] {processor.py:161} INFO - Started process (PID=106) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:15:22.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:15:22.350+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:15:22.350+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:15:22.781+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:15:22.803+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:15:22.803+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:15:22.825+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:15:22.825+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:15:22.831+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.530 seconds
[2024-04-30T17:15:53.265+0000] {processor.py:161} INFO - Started process (PID=108) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:15:53.268+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:15:53.279+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:15:53.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:15:53.882+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:15:53.901+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:15:53.901+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:15:53.911+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:15:53.911+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:15:53.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.680 seconds
[2024-04-30T17:16:24.539+0000] {processor.py:161} INFO - Started process (PID=110) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:16:24.541+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:16:24.547+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:16:24.546+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:16:25.284+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:16:25.321+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:16:25.321+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:16:25.333+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:16:25.333+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:16:25.341+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.834 seconds
[2024-04-30T17:16:56.006+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:16:56.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:16:56.012+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:16:56.012+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:16:56.546+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:16:56.578+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:16:56.578+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:16:56.594+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:16:56.594+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:16:56.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.616 seconds
[2024-04-30T17:17:27.170+0000] {processor.py:161} INFO - Started process (PID=114) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:17:27.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:17:27.174+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:17:27.174+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:17:27.765+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:17:27.783+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:17:27.783+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:17:27.793+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:17:27.793+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:17:27.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.662 seconds
[2024-04-30T17:17:58.175+0000] {processor.py:161} INFO - Started process (PID=116) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:17:58.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:17:58.181+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:17:58.180+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:17:58.668+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:17:58.703+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:17:58.703+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:17:58.714+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:17:58.714+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:17:58.723+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.564 seconds
[2024-04-30T17:18:29.263+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:18:29.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:18:29.267+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:18:29.266+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:18:29.689+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:18:29.708+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:18:29.708+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:18:29.717+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:18:29.717+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:18:29.725+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.481 seconds
[2024-04-30T17:19:00.118+0000] {processor.py:161} INFO - Started process (PID=120) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:19:00.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:19:00.123+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:19:00.122+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:19:00.557+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:19:00.588+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:19:00.587+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:19:00.598+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:19:00.597+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:19:00.605+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.501 seconds
[2024-04-30T17:19:31.136+0000] {processor.py:161} INFO - Started process (PID=122) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:19:31.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:19:31.141+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:19:31.141+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:19:31.575+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:19:31.596+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:19:31.596+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:19:31.611+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:19:31.611+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:19:31.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.494 seconds
[2024-04-30T17:20:02.032+0000] {processor.py:161} INFO - Started process (PID=124) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:20:02.035+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:20:02.041+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:20:02.041+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:20:02.449+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:20:02.470+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:20:02.470+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:20:02.486+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:20:02.486+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:20:02.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.477 seconds
[2024-04-30T17:20:32.956+0000] {processor.py:161} INFO - Started process (PID=126) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:20:32.959+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:20:32.963+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:20:32.963+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:20:33.396+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:20:33.413+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:20:33.413+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:20:33.423+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:20:33.423+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:20:33.430+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.491 seconds
[2024-04-30T17:21:03.852+0000] {processor.py:161} INFO - Started process (PID=128) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:21:03.854+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:21:03.858+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:21:03.857+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:21:04.368+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:21:04.388+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:21:04.388+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:21:04.400+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:21:04.400+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:21:04.407+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.570 seconds
[2024-04-30T17:21:34.876+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:21:34.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:21:34.883+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:21:34.882+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:21:35.489+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:21:35.514+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:21:35.514+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:21:35.530+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:21:35.530+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:21:35.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.676 seconds
[2024-04-30T17:22:06.070+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:22:06.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:22:06.076+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:22:06.076+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:22:06.532+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:22:06.530+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:22:06.533+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:22:06.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.499 seconds
[2024-04-30T17:22:36.877+0000] {processor.py:161} INFO - Started process (PID=134) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:22:36.879+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:22:36.881+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:22:36.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:22:37.268+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:22:37.268+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:22:37.269+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:22:37.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.419 seconds
[2024-04-30T17:23:07.748+0000] {processor.py:161} INFO - Started process (PID=136) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:23:07.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:23:07.757+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:23:07.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:23:08.366+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:23:08.365+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:23:08.366+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:23:08.379+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.657 seconds
[2024-04-30T17:23:38.849+0000] {processor.py:161} INFO - Started process (PID=138) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:23:38.850+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:23:38.851+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:23:38.851+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:23:39.240+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:23:39.240+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:23:39.241+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:23:39.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.417 seconds
[2024-04-30T17:24:09.353+0000] {processor.py:161} INFO - Started process (PID=140) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:24:09.355+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:24:09.356+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:24:09.356+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:24:09.762+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:24:09.761+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:24:09.762+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:24:09.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.446 seconds
[2024-04-30T17:24:40.081+0000] {processor.py:161} INFO - Started process (PID=142) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:24:40.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:24:40.084+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:24:40.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:24:40.504+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:24:40.503+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:24:40.504+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:24:40.523+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.451 seconds
[2024-04-30T17:25:10.927+0000] {processor.py:161} INFO - Started process (PID=144) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:25:10.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:25:10.929+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:25:10.928+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:25:11.286+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:25:11.285+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:25:11.286+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:25:11.296+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.382 seconds
[2024-04-30T17:25:41.812+0000] {processor.py:161} INFO - Started process (PID=146) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:25:41.813+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:25:41.814+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:25:41.814+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:25:42.180+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:25:42.179+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:25:42.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:25:42.199+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.398 seconds
[2024-04-30T17:26:12.308+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:26:12.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:26:12.310+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:26:12.310+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:26:12.733+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:26:12.731+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:26:12.733+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:26:12.765+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.466 seconds
[2024-04-30T17:26:43.139+0000] {processor.py:161} INFO - Started process (PID=150) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:26:43.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:26:43.141+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:26:43.141+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:26:43.548+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:26:43.547+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:26:43.548+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:26:43.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.434 seconds
[2024-04-30T17:27:13.728+0000] {processor.py:161} INFO - Started process (PID=152) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:27:13.731+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:27:13.734+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:27:13.733+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:27:14.631+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:27:14.629+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:27:14.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:27:14.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.992 seconds
[2024-04-30T17:27:45.576+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:27:45.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:27:45.580+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:27:45.579+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:27:46.014+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:27:46.013+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:27:46.015+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:27:46.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.489 seconds
[2024-04-30T17:28:16.509+0000] {processor.py:161} INFO - Started process (PID=156) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:28:16.511+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:28:16.513+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:28:16.512+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:28:16.924+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:28:16.923+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:28:16.924+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:28:16.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.446 seconds
[2024-04-30T17:28:47.389+0000] {processor.py:161} INFO - Started process (PID=158) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:28:47.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:28:47.393+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:28:47.392+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:28:47.811+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:28:47.810+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:28:47.811+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:28:47.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.464 seconds
[2024-04-30T17:29:18.263+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:29:18.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:29:18.265+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:29:18.265+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:29:18.653+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:29:18.652+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:29:18.654+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:29:18.666+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.412 seconds
[2024-04-30T17:29:49.025+0000] {processor.py:161} INFO - Started process (PID=162) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:29:49.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:29:49.027+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:29:49.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:29:49.413+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:29:49.412+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:29:49.413+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:29:49.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.434 seconds
[2024-04-30T17:30:19.910+0000] {processor.py:161} INFO - Started process (PID=164) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:30:19.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:30:19.914+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:30:19.913+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:30:20.290+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:30:20.289+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:30:20.291+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:30:20.304+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.415 seconds
[2024-04-30T17:30:50.671+0000] {processor.py:161} INFO - Started process (PID=166) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:30:50.672+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:30:50.673+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:30:50.672+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:30:51.047+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:30:51.046+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:30:51.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:30:51.062+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.414 seconds
[2024-04-30T17:31:21.441+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:31:21.442+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:31:21.443+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:31:21.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:31:21.928+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:31:21.927+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:31:21.928+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:31:21.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.544 seconds
[2024-04-30T17:31:52.359+0000] {processor.py:161} INFO - Started process (PID=170) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:31:52.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:31:52.363+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:31:52.363+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:31:52.769+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:31:52.768+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'connect_reddit' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:31:52.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:31:52.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.436 seconds
[2024-04-30T17:32:09.678+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:32:09.684+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:32:09.686+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:32:09.685+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:32:10.346+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:32:10.442+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:32:10.441+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:32:10.455+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:32:10.455+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:32:10.465+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.827 seconds
[2024-04-30T17:32:40.906+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:32:40.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:32:40.910+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:32:40.909+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:32:41.315+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:32:41.337+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:32:41.336+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:32:41.347+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:32:41.346+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:32:41.355+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.462 seconds
[2024-04-30T17:33:11.750+0000] {processor.py:161} INFO - Started process (PID=176) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:33:11.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:33:11.753+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:33:11.753+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:33:12.189+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:33:12.205+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:33:12.205+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:33:12.215+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:33:12.214+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:33:12.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.484 seconds
[2024-04-30T17:33:42.621+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:33:42.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:33:42.623+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:33:42.623+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:33:43.042+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:33:43.057+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:33:43.057+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:33:43.070+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:33:43.070+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:33:43.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.466 seconds
[2024-04-30T17:34:13.532+0000] {processor.py:161} INFO - Started process (PID=180) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:34:13.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:34:13.534+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:34:13.533+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:34:13.949+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:34:13.964+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:34:13.964+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:34:13.977+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:34:13.977+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:34:13.991+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.489 seconds
[2024-04-30T17:34:44.490+0000] {processor.py:161} INFO - Started process (PID=182) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:34:44.491+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:34:44.492+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:34:44.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:34:44.898+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:34:44.921+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:34:44.921+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T17:34:44.931+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:34:44.930+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T17:34:44.937+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.456 seconds
[2024-04-30T17:35:15.231+0000] {processor.py:161} INFO - Started process (PID=184) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:35:15.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:35:15.236+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:35:15.234+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:35:15.885+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:35:15.883+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:35:15.885+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:35:15.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.714 seconds
[2024-04-30T17:35:46.372+0000] {processor.py:161} INFO - Started process (PID=186) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:35:46.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:35:46.374+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:35:46.374+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:35:46.734+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:35:46.733+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:35:46.735+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:35:46.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.389 seconds
[2024-04-30T17:36:17.064+0000] {processor.py:161} INFO - Started process (PID=188) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:36:17.066+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:36:17.067+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:36:17.067+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:36:17.489+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:36:17.488+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:36:17.489+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:36:17.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.455 seconds
[2024-04-30T17:36:47.964+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:36:47.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:36:47.966+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:36:47.966+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:36:48.324+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:36:48.322+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:36:48.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:36:48.337+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.399 seconds
[2024-04-30T17:37:18.759+0000] {processor.py:161} INFO - Started process (PID=192) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:37:18.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:37:18.762+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:37:18.762+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:37:19.142+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:37:19.141+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:37:19.142+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:37:19.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.407 seconds
[2024-04-30T17:37:49.525+0000] {processor.py:161} INFO - Started process (PID=194) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:37:49.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:37:49.531+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:37:49.529+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:37:49.926+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:37:49.925+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:37:49.926+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:37:49.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.428 seconds
[2024-04-30T17:38:20.347+0000] {processor.py:161} INFO - Started process (PID=196) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:38:20.350+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:38:20.351+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:38:20.350+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:38:20.753+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:38:20.752+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:38:20.753+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:38:20.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.432 seconds
[2024-04-30T17:38:51.150+0000] {processor.py:161} INFO - Started process (PID=198) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:38:51.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:38:51.156+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:38:51.155+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:38:51.533+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:38:51.532+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:38:51.534+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:38:51.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.428 seconds
[2024-04-30T17:39:21.945+0000] {processor.py:161} INFO - Started process (PID=200) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:39:21.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:39:21.947+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:39:21.947+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:39:22.321+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:39:22.320+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:39:22.322+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:39:22.332+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.414 seconds
[2024-04-30T17:39:52.735+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:39:52.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:39:52.738+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:39:52.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:39:53.136+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:39:53.134+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:39:53.136+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:39:53.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.430 seconds
[2024-04-30T17:40:23.601+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:40:23.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:40:23.604+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:40:23.604+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:40:23.963+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:40:23.962+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:40:23.964+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:40:23.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.390 seconds
[2024-04-30T17:40:54.372+0000] {processor.py:161} INFO - Started process (PID=206) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:40:54.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:40:54.375+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:40:54.374+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:40:54.740+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:40:54.738+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:40:54.740+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:40:54.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.392 seconds
[2024-04-30T17:41:25.166+0000] {processor.py:161} INFO - Started process (PID=208) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:41:25.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:41:25.170+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:41:25.169+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:41:25.576+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:41:25.575+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:41:25.577+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:41:25.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.436 seconds
[2024-04-30T17:41:56.029+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:41:56.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:41:56.032+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:41:56.031+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:41:56.396+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:41:56.394+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:41:56.396+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:41:56.407+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.392 seconds
[2024-04-30T17:42:26.847+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:42:26.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:42:26.856+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:42:26.855+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:42:27.234+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:42:27.232+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:42:27.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:42:27.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.419 seconds
[2024-04-30T17:42:57.637+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:42:57.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:42:57.642+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:42:57.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:42:58.024+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:42:58.023+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:42:58.024+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:42:58.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.446 seconds
[2024-04-30T17:43:28.455+0000] {processor.py:161} INFO - Started process (PID=216) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:43:28.457+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:43:28.459+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:43:28.458+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:43:28.844+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:43:28.842+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:43:28.844+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:43:28.864+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.428 seconds
[2024-04-30T17:43:59.310+0000] {processor.py:161} INFO - Started process (PID=218) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:43:59.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:43:59.313+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:43:59.312+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:43:59.688+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:43:59.687+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:43:59.688+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:43:59.700+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.414 seconds
[2024-04-30T17:44:30.100+0000] {processor.py:161} INFO - Started process (PID=220) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:44:30.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:44:30.104+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:44:30.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:44:30.467+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:44:30.466+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:44:30.468+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:44:30.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.413 seconds
[2024-04-30T17:45:00.892+0000] {processor.py:161} INFO - Started process (PID=222) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:45:00.895+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:45:00.897+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:45:00.896+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:45:01.304+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:45:01.303+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:45:01.304+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:45:01.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.454 seconds
[2024-04-30T17:45:31.819+0000] {processor.py:161} INFO - Started process (PID=224) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:45:31.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:45:31.822+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:45:31.821+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:45:32.189+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:45:32.188+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:45:32.189+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:45:32.206+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.399 seconds
[2024-04-30T17:46:02.625+0000] {processor.py:161} INFO - Started process (PID=226) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:46:02.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:46:02.628+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:46:02.627+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:46:03.007+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:46:03.006+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:46:03.007+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:46:03.023+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.423 seconds
[2024-04-30T17:46:33.499+0000] {processor.py:161} INFO - Started process (PID=228) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:46:33.501+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:46:33.502+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:46:33.502+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:46:33.909+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:46:33.907+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:46:33.909+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:46:33.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.443 seconds
[2024-04-30T17:47:04.303+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:47:04.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:47:04.306+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:47:04.306+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:47:04.692+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:47:04.691+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:47:04.692+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:47:04.716+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.425 seconds
[2024-04-30T17:47:35.191+0000] {processor.py:161} INFO - Started process (PID=232) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:47:35.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:47:35.193+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:47:35.192+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:47:35.631+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:47:35.630+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:47:35.632+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:47:35.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.478 seconds
[2024-04-30T17:48:06.099+0000] {processor.py:161} INFO - Started process (PID=234) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:48:06.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:48:06.102+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:48:06.101+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:48:06.815+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:48:06.814+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
ImportError: cannot import name 'extract_images' from 'etls.redditEtl' (/opt/airflow/etls/redditEtl.py)
[2024-04-30T17:48:06.816+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:48:06.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.774 seconds
[2024-04-30T17:48:37.286+0000] {processor.py:161} INFO - Started process (PID=236) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:48:37.288+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:48:37.289+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:48:37.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:48:37.708+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:48:37.707+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:48:37.708+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:48:37.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.462 seconds
[2024-04-30T17:49:08.296+0000] {processor.py:161} INFO - Started process (PID=238) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:49:08.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:49:08.306+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:49:08.303+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:49:08.893+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:49:08.891+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:49:08.893+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:49:08.919+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.650 seconds
[2024-04-30T17:49:39.267+0000] {processor.py:161} INFO - Started process (PID=240) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:49:39.281+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:49:39.284+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:49:39.283+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:49:40.527+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:49:40.526+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:49:40.528+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:49:40.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.386 seconds
[2024-04-30T17:50:11.320+0000] {processor.py:161} INFO - Started process (PID=242) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:50:11.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:50:11.333+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:50:11.330+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:50:12.325+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:50:12.324+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:50:12.326+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:50:12.356+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.116 seconds
[2024-04-30T17:50:42.921+0000] {processor.py:161} INFO - Started process (PID=244) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:50:42.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:50:42.927+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:50:42.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:50:43.336+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:50:43.335+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:50:43.336+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:50:43.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.444 seconds
[2024-04-30T17:51:13.866+0000] {processor.py:161} INFO - Started process (PID=246) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:51:13.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:51:13.869+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:51:13.868+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:51:14.307+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:51:14.306+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:51:14.307+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:51:14.329+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.476 seconds
[2024-04-30T17:51:44.828+0000] {processor.py:161} INFO - Started process (PID=248) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:51:44.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:51:44.831+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:51:44.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:51:45.249+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:51:45.248+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:51:45.249+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:51:45.267+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.469 seconds
[2024-04-30T17:52:15.675+0000] {processor.py:161} INFO - Started process (PID=250) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:52:15.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:52:15.684+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:52:15.683+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:52:16.086+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:52:16.085+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:52:16.086+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:52:16.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.439 seconds
[2024-04-30T17:52:46.521+0000] {processor.py:161} INFO - Started process (PID=252) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:52:46.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:52:46.528+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:52:46.527+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:52:46.914+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:52:46.910+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:52:46.914+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:52:46.930+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.431 seconds
[2024-04-30T17:53:17.331+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:53:17.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:53:17.334+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:53:17.333+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:53:17.735+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:53:17.735+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:53:17.736+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:53:17.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.432 seconds
[2024-04-30T17:53:48.195+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:53:48.197+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:53:48.198+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:53:48.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:53:48.562+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:53:48.560+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:53:48.563+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:53:48.581+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.405 seconds
[2024-04-30T17:54:18.991+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:54:18.994+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:54:18.996+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:54:18.995+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:54:19.369+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:54:19.367+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:54:19.369+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:54:19.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.417 seconds
[2024-04-30T17:54:49.799+0000] {processor.py:161} INFO - Started process (PID=260) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:54:49.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:54:49.802+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:54:49.801+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:54:50.224+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:54:50.222+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:54:50.224+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:54:50.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.477 seconds
[2024-04-30T17:55:20.740+0000] {processor.py:161} INFO - Started process (PID=262) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:55:20.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:55:20.743+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:55:20.742+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:55:21.243+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:55:21.242+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:55:21.244+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:55:21.260+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.547 seconds
[2024-04-30T17:55:51.732+0000] {processor.py:161} INFO - Started process (PID=264) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:55:51.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:55:51.737+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:55:51.735+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:55:52.247+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:55:52.239+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:55:52.250+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:55:52.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.595 seconds
[2024-04-30T17:56:22.818+0000] {processor.py:161} INFO - Started process (PID=266) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:56:22.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:56:22.823+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:56:22.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:56:23.256+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:56:23.255+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:56:23.257+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:56:23.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.468 seconds
[2024-04-30T17:56:53.502+0000] {processor.py:161} INFO - Started process (PID=268) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:56:53.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:56:53.506+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:56:53.506+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:56:53.885+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:56:53.884+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:56:53.886+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:56:53.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.411 seconds
[2024-04-30T17:57:24.043+0000] {processor.py:161} INFO - Started process (PID=270) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:57:24.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:57:24.046+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:57:24.045+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:57:24.491+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:57:24.490+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:57:24.492+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:57:24.507+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.495 seconds
[2024-04-30T17:57:54.752+0000] {processor.py:161} INFO - Started process (PID=272) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:57:54.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:57:54.756+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:57:54.755+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:57:55.111+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:57:55.110+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:57:55.111+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:57:55.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.386 seconds
[2024-04-30T17:58:25.492+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:58:25.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:58:25.496+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:58:25.495+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:58:25.997+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:58:25.995+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:58:25.997+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:58:26.019+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.551 seconds
[2024-04-30T17:58:56.428+0000] {processor.py:161} INFO - Started process (PID=276) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:58:56.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:58:56.433+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:58:56.432+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:58:56.874+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:58:56.872+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:58:56.875+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:58:56.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.477 seconds
[2024-04-30T17:59:27.400+0000] {processor.py:161} INFO - Started process (PID=278) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:59:27.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:59:27.403+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:59:27.402+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:59:27.807+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:59:27.805+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:59:27.807+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:59:27.830+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.441 seconds
[2024-04-30T17:59:58.246+0000] {processor.py:161} INFO - Started process (PID=280) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T17:59:58.247+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T17:59:58.248+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:59:58.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T17:59:58.624+0000] {logging_mixin.py:188} INFO - [2024-04-30T17:59:58.622+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T17:59:58.624+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T17:59:58.638+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.407 seconds
[2024-04-30T18:00:29.293+0000] {processor.py:161} INFO - Started process (PID=282) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:00:29.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:00:29.298+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:00:29.297+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:00:29.893+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:00:29.891+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:00:29.893+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:00:29.928+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.657 seconds
[2024-04-30T18:01:00.151+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:01:00.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:01:00.158+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:01:00.156+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:01:00.630+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:01:00.628+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:01:00.630+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:01:00.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.541 seconds
[2024-04-30T18:01:31.097+0000] {processor.py:161} INFO - Started process (PID=286) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:01:31.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:01:31.100+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:01:31.100+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:01:31.775+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:01:31.771+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:01:31.775+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:01:31.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.707 seconds
[2024-04-30T18:02:02.250+0000] {processor.py:161} INFO - Started process (PID=288) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:02:02.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:02:02.254+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:02:02.254+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:02:02.839+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:02:02.837+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:02:02.839+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:02:02.904+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.671 seconds
[2024-04-30T18:02:33.341+0000] {processor.py:161} INFO - Started process (PID=290) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:02:33.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:02:33.343+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:02:33.343+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:02:33.751+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:02:33.750+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:02:33.751+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:02:33.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.454 seconds
[2024-04-30T18:03:04.289+0000] {processor.py:161} INFO - Started process (PID=292) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:03:04.290+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:03:04.291+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:03:04.291+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:03:04.742+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:03:04.741+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:03:04.742+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:03:04.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.490 seconds
[2024-04-30T18:03:35.242+0000] {processor.py:161} INFO - Started process (PID=294) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:03:35.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:03:35.244+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:03:35.244+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:03:35.655+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:03:35.654+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:03:35.655+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:03:35.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.441 seconds
[2024-04-30T18:04:06.101+0000] {processor.py:161} INFO - Started process (PID=296) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:04:06.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:04:06.104+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:04:06.103+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:04:06.475+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:04:06.474+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:04:06.476+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:04:06.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.407 seconds
[2024-04-30T18:04:36.934+0000] {processor.py:161} INFO - Started process (PID=298) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:04:36.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:04:36.937+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:04:36.937+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:04:37.960+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:04:37.958+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:04:37.961+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:04:37.989+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.068 seconds
[2024-04-30T18:05:08.605+0000] {processor.py:161} INFO - Started process (PID=300) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:05:08.606+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:05:08.607+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:05:08.607+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:05:09.091+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:05:09.089+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:05:09.091+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:05:09.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.531 seconds
[2024-04-30T18:05:39.659+0000] {processor.py:161} INFO - Started process (PID=302) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:05:39.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:05:39.661+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:05:39.661+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:05:40.035+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:05:40.034+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:05:40.035+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:05:40.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.410 seconds
[2024-04-30T18:06:10.323+0000] {processor.py:161} INFO - Started process (PID=304) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:06:10.330+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:06:10.332+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:06:10.331+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:06:10.710+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:06:10.709+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:06:10.710+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:06:10.721+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.432 seconds
[2024-04-30T18:06:40.817+0000] {processor.py:161} INFO - Started process (PID=306) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:06:40.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:06:40.820+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:06:40.819+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:06:41.207+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:06:41.206+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:06:41.207+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:06:41.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.433 seconds
[2024-04-30T18:07:11.527+0000] {processor.py:161} INFO - Started process (PID=308) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:07:11.532+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:07:11.535+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:07:11.534+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:07:11.921+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:07:11.920+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:07:11.922+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:07:11.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.430 seconds
[2024-04-30T18:07:42.333+0000] {processor.py:161} INFO - Started process (PID=310) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:07:42.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:07:42.341+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:07:42.339+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:07:42.727+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:07:42.726+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:07:42.727+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:07:42.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.431 seconds
[2024-04-30T18:08:13.208+0000] {processor.py:161} INFO - Started process (PID=312) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:08:13.212+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:08:13.216+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:08:13.215+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:08:13.616+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:08:13.615+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:08:13.616+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:08:13.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.444 seconds
[2024-04-30T18:08:44.108+0000] {processor.py:161} INFO - Started process (PID=314) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:08:44.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:08:44.110+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:08:44.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:08:44.479+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:08:44.478+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:08:44.479+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:08:44.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.396 seconds
[2024-04-30T18:09:14.927+0000] {processor.py:161} INFO - Started process (PID=316) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:09:14.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:09:14.930+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:09:14.929+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:09:15.310+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:09:15.309+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:09:15.311+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:09:15.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.408 seconds
[2024-04-30T18:09:45.743+0000] {processor.py:161} INFO - Started process (PID=318) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:09:45.746+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:09:45.751+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:09:45.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:09:46.122+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:09:46.121+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:09:46.122+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:09:46.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.434 seconds
[2024-04-30T18:10:16.608+0000] {processor.py:161} INFO - Started process (PID=320) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:10:16.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:10:16.628+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:10:16.623+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:10:17.004+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:10:17.003+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:10:17.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:10:17.036+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.444 seconds
[2024-04-30T18:10:47.487+0000] {processor.py:161} INFO - Started process (PID=322) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:10:47.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:10:47.490+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:10:47.489+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:10:47.879+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:10:47.878+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:10:47.879+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:10:47.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.422 seconds
[2024-04-30T18:11:18.317+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:11:18.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:11:18.325+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:11:18.324+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:11:18.720+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:11:18.718+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:11:18.720+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:11:18.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.447 seconds
[2024-04-30T18:11:49.173+0000] {processor.py:161} INFO - Started process (PID=326) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:11:49.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:11:49.177+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:11:49.176+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:11:49.560+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:11:49.559+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:11:49.560+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:11:49.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.436 seconds
[2024-04-30T18:12:19.950+0000] {processor.py:161} INFO - Started process (PID=328) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:12:19.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:12:19.954+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:12:19.953+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:12:20.364+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:12:20.362+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:12:20.365+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:12:20.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.452 seconds
[2024-04-30T18:12:50.894+0000] {processor.py:161} INFO - Started process (PID=330) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:12:50.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:12:50.898+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:12:50.897+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:12:51.304+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:12:51.302+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:12:51.304+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:12:51.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.445 seconds
[2024-04-30T18:13:21.711+0000] {processor.py:161} INFO - Started process (PID=332) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:13:21.713+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:13:21.714+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:13:21.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:13:22.095+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:13:22.094+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:13:22.095+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:13:22.109+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.411 seconds
[2024-04-30T18:13:52.535+0000] {processor.py:161} INFO - Started process (PID=334) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:13:52.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:13:52.538+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:13:52.537+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:13:52.919+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:13:52.918+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:13:52.919+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:13:52.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.443 seconds
[2024-04-30T18:14:23.351+0000] {processor.py:161} INFO - Started process (PID=336) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:14:23.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:14:23.354+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:14:23.354+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:14:23.735+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:14:23.734+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:14:23.735+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:14:23.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.418 seconds
[2024-04-30T18:14:54.219+0000] {processor.py:161} INFO - Started process (PID=338) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:14:54.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:14:54.223+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:14:54.222+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:14:54.633+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:14:54.632+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:14:54.633+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:14:54.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.450 seconds
[2024-04-30T18:15:25.162+0000] {processor.py:161} INFO - Started process (PID=340) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:15:25.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:15:25.166+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:15:25.165+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:15:25.548+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:15:25.547+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:15:25.548+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:15:25.561+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.416 seconds
[2024-04-30T18:15:56.056+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:15:56.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:15:56.059+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:15:56.058+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:15:56.444+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:15:56.443+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:15:56.445+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:15:56.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.419 seconds
[2024-04-30T18:16:27.013+0000] {processor.py:161} INFO - Started process (PID=344) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:16:27.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:16:27.016+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:16:27.015+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:16:27.429+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:16:27.428+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:16:27.429+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:16:27.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.442 seconds
[2024-04-30T18:16:57.909+0000] {processor.py:161} INFO - Started process (PID=346) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:16:57.912+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:16:57.913+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:16:57.912+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:16:58.305+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:16:58.304+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:16:58.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:16:58.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.424 seconds
[2024-04-30T18:17:28.820+0000] {processor.py:161} INFO - Started process (PID=348) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:17:28.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:17:28.823+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:17:28.822+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:17:29.327+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:17:29.326+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:17:29.328+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:17:29.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.541 seconds
[2024-04-30T18:17:59.785+0000] {processor.py:161} INFO - Started process (PID=350) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:17:59.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:17:59.787+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:17:59.787+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:18:00.176+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:18:00.174+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:18:00.176+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:18:00.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.416 seconds
[2024-04-30T18:18:30.599+0000] {processor.py:161} INFO - Started process (PID=352) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:18:30.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:18:30.604+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:18:30.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:18:30.980+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:18:30.979+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:18:30.981+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:18:30.995+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.419 seconds
[2024-04-30T18:19:01.370+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:19:01.372+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:19:01.373+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:19:01.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:19:01.758+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:19:01.757+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:19:01.758+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:19:01.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.410 seconds
[2024-04-30T18:19:31.922+0000] {processor.py:161} INFO - Started process (PID=356) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:19:31.925+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:19:31.926+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:19:31.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:19:32.323+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:19:32.322+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:19:32.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:19:32.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.433 seconds
[2024-04-30T18:20:02.584+0000] {processor.py:161} INFO - Started process (PID=358) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:20:02.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:20:02.587+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:20:02.587+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:20:02.970+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:20:02.968+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:20:02.970+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:20:02.992+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.420 seconds
[2024-04-30T18:20:33.087+0000] {processor.py:161} INFO - Started process (PID=360) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:20:33.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:20:33.101+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:20:33.100+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:20:33.473+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:20:33.472+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:20:33.473+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:20:33.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.415 seconds
[2024-04-30T18:21:03.926+0000] {processor.py:161} INFO - Started process (PID=362) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:21:03.927+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:21:03.928+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:21:03.928+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:21:04.304+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:21:04.303+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:21:04.305+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:21:04.319+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.404 seconds
[2024-04-30T18:21:34.750+0000] {processor.py:161} INFO - Started process (PID=364) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:21:34.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:21:34.753+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:21:34.753+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:21:35.198+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:21:35.197+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:21:35.198+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:21:35.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.498 seconds
[2024-04-30T18:22:05.665+0000] {processor.py:161} INFO - Started process (PID=366) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:22:05.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:22:05.667+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:22:05.667+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:22:06.082+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:22:06.081+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:22:06.082+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:22:06.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.442 seconds
[2024-04-30T18:22:36.568+0000] {processor.py:161} INFO - Started process (PID=368) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:22:36.570+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:22:36.571+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:22:36.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:22:36.960+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:22:36.959+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:22:36.960+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:22:36.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.420 seconds
[2024-04-30T18:23:07.400+0000] {processor.py:161} INFO - Started process (PID=370) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:23:07.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:23:07.403+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:23:07.403+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:23:07.763+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:23:07.762+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:23:07.763+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:23:07.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.408 seconds
[2024-04-30T18:23:38.160+0000] {processor.py:161} INFO - Started process (PID=372) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:23:38.162+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:23:38.163+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:23:38.162+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:23:38.551+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:23:38.550+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:23:38.552+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:23:38.564+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.415 seconds
[2024-04-30T18:24:08.979+0000] {processor.py:161} INFO - Started process (PID=374) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:24:08.980+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:24:08.982+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:24:08.981+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:24:09.357+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:24:09.355+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:24:09.357+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:24:09.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.406 seconds
[2024-04-30T18:24:39.778+0000] {processor.py:161} INFO - Started process (PID=376) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:24:39.781+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:24:39.783+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:24:39.782+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:24:40.178+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:24:40.177+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:24:40.178+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:24:40.193+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.429 seconds
[2024-04-30T18:25:10.613+0000] {processor.py:161} INFO - Started process (PID=378) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:25:10.615+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:25:10.616+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:25:10.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:25:10.986+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:25:10.985+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:25:10.987+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:25:11.002+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.399 seconds
[2024-04-30T18:25:41.394+0000] {processor.py:161} INFO - Started process (PID=380) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:25:41.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:25:41.398+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:25:41.398+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:25:41.817+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:25:41.815+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:25:41.817+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:25:41.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.467 seconds
[2024-04-30T18:26:12.268+0000] {processor.py:161} INFO - Started process (PID=382) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:26:12.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:26:12.275+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:26:12.273+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:26:12.664+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:26:12.663+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:26:12.664+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:26:12.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.421 seconds
[2024-04-30T18:26:43.116+0000] {processor.py:161} INFO - Started process (PID=384) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:26:43.118+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:26:43.119+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:26:43.118+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:26:43.499+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:26:43.497+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:26:43.499+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:26:43.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.405 seconds
[2024-04-30T18:27:13.983+0000] {processor.py:161} INFO - Started process (PID=386) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:27:13.986+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:27:13.990+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:27:13.989+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:27:14.384+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:27:14.382+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:27:14.385+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:27:14.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.443 seconds
[2024-04-30T18:27:44.887+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:27:44.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:27:44.890+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:27:44.890+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:27:45.368+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:27:45.366+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:27:45.368+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:27:45.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.514 seconds
[2024-04-30T18:28:15.680+0000] {processor.py:161} INFO - Started process (PID=390) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:28:15.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:28:15.682+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:28:15.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:28:16.056+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:28:16.055+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:28:16.056+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:28:16.069+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.403 seconds
[2024-04-30T18:28:46.513+0000] {processor.py:161} INFO - Started process (PID=392) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:28:46.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:28:46.517+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:28:46.516+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:28:46.908+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:28:46.907+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:28:46.909+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:28:46.923+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.423 seconds
[2024-04-30T18:29:17.360+0000] {processor.py:161} INFO - Started process (PID=394) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:29:17.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:29:17.363+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:29:17.362+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:29:17.735+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:29:17.734+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:29:17.736+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:29:17.766+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.414 seconds
[2024-04-30T18:29:47.974+0000] {processor.py:161} INFO - Started process (PID=396) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:29:47.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:29:47.977+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:29:47.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:29:48.509+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:29:48.508+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:29:48.509+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:29:48.533+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.579 seconds
[2024-04-30T18:30:18.628+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:30:18.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:30:18.630+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:30:18.630+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:30:19.227+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:30:19.225+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:30:19.228+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:30:19.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.661 seconds
[2024-04-30T18:30:49.542+0000] {processor.py:161} INFO - Started process (PID=400) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:30:49.544+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:30:49.546+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:30:49.545+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:30:49.975+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:30:49.973+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:30:49.977+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:30:50.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.519 seconds
[2024-04-30T18:31:20.556+0000] {processor.py:161} INFO - Started process (PID=402) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:31:20.558+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:31:20.559+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:31:20.559+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:31:20.980+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:31:20.979+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:31:20.981+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:31:20.996+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.525 seconds
[2024-04-30T18:31:51.409+0000] {processor.py:161} INFO - Started process (PID=404) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:31:51.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:31:51.412+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:31:51.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:31:51.792+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:31:51.791+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:31:51.792+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:31:51.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.421 seconds
[2024-04-30T18:32:22.259+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:32:22.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:32:22.261+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:32:22.261+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:32:22.676+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:32:22.670+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:32:22.683+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:32:22.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.518 seconds
[2024-04-30T18:32:53.259+0000] {processor.py:161} INFO - Started process (PID=408) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:32:53.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:32:53.271+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:32:53.270+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:32:53.729+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:32:53.728+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:32:53.730+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:32:53.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.540 seconds
[2024-04-30T18:33:24.156+0000] {processor.py:161} INFO - Started process (PID=410) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:33:24.159+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:33:24.160+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:33:24.160+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:33:24.535+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:33:24.534+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:33:24.536+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:33:24.562+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.425 seconds
[2024-04-30T18:33:55.090+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:33:55.092+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:33:55.093+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:33:55.092+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:33:55.490+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:33:55.486+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:33:55.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:33:55.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.434 seconds
[2024-04-30T18:34:25.996+0000] {processor.py:161} INFO - Started process (PID=414) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:34:25.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:34:25.999+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:34:25.999+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:34:26.537+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:34:26.514+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:34:26.537+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:34:26.594+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.612 seconds
[2024-04-30T18:34:57.024+0000] {processor.py:161} INFO - Started process (PID=416) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:34:57.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:34:57.028+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:34:57.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:34:57.449+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:34:57.448+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:34:57.450+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:34:57.502+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.489 seconds
[2024-04-30T18:35:27.864+0000] {processor.py:161} INFO - Started process (PID=418) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:35:27.866+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:35:27.867+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:35:27.867+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:35:28.271+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:35:28.270+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:35:28.271+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:35:28.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.434 seconds
[2024-04-30T18:35:58.815+0000] {processor.py:161} INFO - Started process (PID=420) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:35:58.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:35:58.825+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:35:58.824+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:35:59.228+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:35:59.227+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:35:59.229+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:35:59.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.461 seconds
[2024-04-30T18:36:29.776+0000] {processor.py:161} INFO - Started process (PID=422) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:36:29.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:36:29.779+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:36:29.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:36:30.198+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:36:30.197+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:36:30.199+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:36:30.220+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.454 seconds
[2024-04-30T18:37:00.653+0000] {processor.py:161} INFO - Started process (PID=424) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:37:00.655+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:37:00.656+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:37:00.656+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:37:01.034+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:37:01.033+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:37:01.034+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:37:01.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.414 seconds
[2024-04-30T18:37:31.458+0000] {processor.py:161} INFO - Started process (PID=426) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:37:31.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:37:31.461+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:37:31.461+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:37:31.830+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:37:31.829+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:37:31.830+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:37:31.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.402 seconds
[2024-04-30T18:38:02.247+0000] {processor.py:161} INFO - Started process (PID=428) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:38:02.250+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:38:02.252+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:38:02.251+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:38:02.640+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:38:02.639+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:38:02.641+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:38:02.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.425 seconds
[2024-04-30T18:38:33.049+0000] {processor.py:161} INFO - Started process (PID=430) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:38:33.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:38:33.052+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:38:33.052+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:38:33.455+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:38:33.454+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:38:33.455+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:38:33.472+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.438 seconds
[2024-04-30T18:39:03.853+0000] {processor.py:161} INFO - Started process (PID=432) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:39:03.862+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:39:03.868+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:39:03.866+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:39:04.249+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:39:04.248+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:39:04.249+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:39:04.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.426 seconds
[2024-04-30T18:39:34.701+0000] {processor.py:161} INFO - Started process (PID=434) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:39:34.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:39:34.704+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:39:34.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:39:35.081+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:39:35.080+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:39:35.082+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:39:35.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.406 seconds
[2024-04-30T18:40:05.491+0000] {processor.py:161} INFO - Started process (PID=436) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:40:05.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:40:05.498+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:40:05.497+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:40:05.867+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:40:05.866+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:40:05.867+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:40:05.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.400 seconds
[2024-04-30T18:40:36.262+0000] {processor.py:161} INFO - Started process (PID=438) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:40:36.265+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:40:36.266+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:40:36.265+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:40:36.628+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:40:36.627+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:40:36.629+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:40:36.643+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.397 seconds
[2024-04-30T18:41:07.073+0000] {processor.py:161} INFO - Started process (PID=440) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:41:07.074+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:41:07.075+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:41:07.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:41:07.468+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:41:07.467+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:41:07.468+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:41:07.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.435 seconds
[2024-04-30T18:41:37.943+0000] {processor.py:161} INFO - Started process (PID=442) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:41:37.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:41:37.946+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:41:37.945+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:41:38.339+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:41:38.338+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:41:38.340+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:41:38.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.442 seconds
[2024-04-30T18:42:08.796+0000] {processor.py:161} INFO - Started process (PID=444) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:42:08.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:42:08.799+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:42:08.799+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:42:09.373+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:42:09.372+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:42:09.374+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:42:09.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.614 seconds
[2024-04-30T18:42:40.025+0000] {processor.py:161} INFO - Started process (PID=446) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:42:40.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:42:40.028+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:42:40.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:42:40.510+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:42:40.509+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:42:40.511+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:42:40.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.543 seconds
[2024-04-30T18:43:11.002+0000] {processor.py:161} INFO - Started process (PID=448) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:43:11.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:43:11.005+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:43:11.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:43:11.693+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:43:11.691+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:43:11.693+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:43:11.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.744 seconds
[2024-04-30T18:43:41.977+0000] {processor.py:161} INFO - Started process (PID=450) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:43:41.978+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:43:41.980+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:43:41.979+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:43:42.483+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:43:42.482+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:43:42.483+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:43:42.496+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.541 seconds
[2024-04-30T18:44:12.882+0000] {processor.py:161} INFO - Started process (PID=452) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:44:12.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:44:12.884+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:44:12.884+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:44:13.267+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:44:13.266+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:44:13.267+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:44:13.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.446 seconds
[2024-04-30T18:44:43.728+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:44:43.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:44:43.730+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:44:43.730+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:44:44.087+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:44:44.086+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:44:44.087+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:44:44.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.392 seconds
[2024-04-30T18:45:14.483+0000] {processor.py:161} INFO - Started process (PID=456) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:45:14.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:45:14.486+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:45:14.485+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:45:14.863+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:45:14.862+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:45:14.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:45:14.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.406 seconds
[2024-04-30T18:45:45.333+0000] {processor.py:161} INFO - Started process (PID=458) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:45:45.335+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:45:45.336+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:45:45.336+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:45:45.696+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:45:45.695+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:45:45.696+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:45:45.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.390 seconds
[2024-04-30T18:46:16.173+0000] {processor.py:161} INFO - Started process (PID=460) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:46:16.174+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:46:16.175+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:46:16.175+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:46:16.552+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:46:16.551+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:46:16.553+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:46:16.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.423 seconds
[2024-04-30T18:46:47.025+0000] {processor.py:161} INFO - Started process (PID=462) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:46:47.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:46:47.028+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:46:47.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:46:47.436+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:46:47.434+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:46:47.436+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:46:47.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.441 seconds
[2024-04-30T18:47:18.031+0000] {processor.py:161} INFO - Started process (PID=464) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:47:18.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:47:18.035+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:47:18.035+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:47:18.414+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:47:18.413+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:47:18.415+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:47:18.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.425 seconds
[2024-04-30T18:47:48.961+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:47:48.965+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:47:48.968+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:47:48.967+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:47:49.808+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:47:49.806+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:47:49.809+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:47:49.833+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.896 seconds
[2024-04-30T18:48:20.133+0000] {processor.py:161} INFO - Started process (PID=468) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:48:20.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:48:20.140+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:48:20.138+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:48:20.631+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:48:20.630+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:48:20.632+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:48:20.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.542 seconds
[2024-04-30T18:48:51.129+0000] {processor.py:161} INFO - Started process (PID=470) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:48:51.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:48:51.132+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:48:51.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:48:51.570+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:48:51.568+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:48:51.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:48:51.595+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.478 seconds
[2024-04-30T18:49:22.059+0000] {processor.py:161} INFO - Started process (PID=472) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:49:22.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:49:22.061+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:49:22.060+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:49:22.442+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:49:22.441+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:49:22.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:49:22.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.419 seconds
[2024-04-30T18:49:52.809+0000] {processor.py:161} INFO - Started process (PID=474) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:49:52.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:49:52.811+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:49:52.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:49:53.209+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:49:53.208+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:49:53.210+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:49:53.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.432 seconds
[2024-04-30T18:50:23.701+0000] {processor.py:161} INFO - Started process (PID=476) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:50:23.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:50:23.703+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:50:23.702+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:50:24.100+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:50:24.099+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:50:24.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:50:24.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.422 seconds
[2024-04-30T18:50:54.487+0000] {processor.py:161} INFO - Started process (PID=478) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:50:54.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:50:54.489+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:50:54.489+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:50:54.858+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:50:54.857+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:50:54.859+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:50:54.872+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.412 seconds
[2024-04-30T18:51:25.297+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:51:25.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:51:25.300+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:51:25.299+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:51:25.647+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:51:25.646+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:51:25.647+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:51:25.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.374 seconds
[2024-04-30T18:51:56.042+0000] {processor.py:161} INFO - Started process (PID=482) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:51:56.043+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:51:56.044+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:51:56.044+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:51:56.411+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:51:56.410+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:51:56.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:51:56.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.399 seconds
[2024-04-30T18:52:26.851+0000] {processor.py:161} INFO - Started process (PID=484) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:52:26.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:52:26.854+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:52:26.854+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:52:27.243+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:52:27.242+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:52:27.244+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:52:27.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.426 seconds
[2024-04-30T18:52:57.607+0000] {processor.py:161} INFO - Started process (PID=486) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:52:57.608+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:52:57.609+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:52:57.609+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:52:57.996+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:52:57.994+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:52:57.996+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:52:58.010+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.414 seconds
[2024-04-30T18:53:28.426+0000] {processor.py:161} INFO - Started process (PID=488) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:53:28.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:53:28.429+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:53:28.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:53:28.807+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:53:28.805+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:53:28.807+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:53:28.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.406 seconds
[2024-04-30T18:53:59.211+0000] {processor.py:161} INFO - Started process (PID=490) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:53:59.213+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:53:59.214+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:53:59.214+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:53:59.602+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:53:59.601+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:53:59.602+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:53:59.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.417 seconds
[2024-04-30T18:54:30.023+0000] {processor.py:161} INFO - Started process (PID=492) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:54:30.026+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:54:30.027+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:54:30.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:54:30.408+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:54:30.407+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:54:30.409+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:54:30.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.417 seconds
[2024-04-30T18:55:00.889+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:55:00.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:55:00.894+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:55:00.893+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:55:01.344+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:55:01.343+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:55:01.344+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:55:01.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.491 seconds
[2024-04-30T18:55:31.820+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:55:31.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:55:31.823+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:55:31.823+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:55:32.291+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:55:32.283+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:55:32.293+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:55:32.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.564 seconds
[2024-04-30T18:56:02.696+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:56:02.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:56:02.707+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:56:02.706+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:56:03.176+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:56:03.174+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:56:03.176+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:56:03.189+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.524 seconds
[2024-04-30T18:56:33.699+0000] {processor.py:161} INFO - Started process (PID=500) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:56:33.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:56:33.704+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:56:33.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:56:34.102+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:56:34.101+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:56:34.102+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:56:34.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.440 seconds
[2024-04-30T18:57:04.565+0000] {processor.py:161} INFO - Started process (PID=502) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:57:04.567+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:57:04.575+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:57:04.568+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:57:04.963+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:57:04.962+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:57:04.964+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:57:04.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.423 seconds
[2024-04-30T18:57:35.426+0000] {processor.py:161} INFO - Started process (PID=504) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:57:35.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:57:35.429+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:57:35.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:57:35.816+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:57:35.814+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:57:35.816+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:57:35.828+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.425 seconds
[2024-04-30T18:58:06.263+0000] {processor.py:161} INFO - Started process (PID=506) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:58:06.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:58:06.268+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:58:06.267+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:58:06.658+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:58:06.656+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:58:06.658+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:58:06.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.426 seconds
[2024-04-30T18:58:29.037+0000] {processor.py:161} INFO - Started process (PID=508) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:58:29.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:58:29.040+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:58:29.039+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:58:29.977+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:58:29.973+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:58:29.978+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:58:30.014+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.989 seconds
[2024-04-30T18:59:00.680+0000] {processor.py:161} INFO - Started process (PID=510) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:59:00.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:59:00.684+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:59:00.683+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:59:01.708+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:59:01.705+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:59:01.709+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:59:01.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.106 seconds
[2024-04-30T18:59:32.269+0000] {processor.py:161} INFO - Started process (PID=512) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T18:59:32.271+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T18:59:32.272+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:59:32.271+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T18:59:32.655+0000] {logging_mixin.py:188} INFO - [2024-04-30T18:59:32.654+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T18:59:32.656+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T18:59:32.671+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.427 seconds
[2024-04-30T19:00:03.119+0000] {processor.py:161} INFO - Started process (PID=514) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:00:03.121+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:00:03.122+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:00:03.122+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:00:03.521+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:00:03.520+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:00:03.522+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:00:03.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.447 seconds
[2024-04-30T19:00:34.001+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:00:34.004+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:00:34.005+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:00:34.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:00:34.374+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:00:34.373+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:00:34.374+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:00:34.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.422 seconds
[2024-04-30T19:01:04.845+0000] {processor.py:161} INFO - Started process (PID=518) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:01:04.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:01:04.848+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:01:04.848+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:01:05.223+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:01:05.222+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:01:05.224+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:01:05.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.405 seconds
[2024-04-30T19:01:35.459+0000] {processor.py:161} INFO - Started process (PID=520) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:01:35.461+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:01:35.462+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:01:35.461+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:01:36.171+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:01:36.169+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:01:36.171+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:01:36.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.746 seconds
[2024-04-30T19:02:06.645+0000] {processor.py:161} INFO - Started process (PID=522) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:02:06.646+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:02:06.647+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:02:06.647+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:02:07.015+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:02:07.014+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:02:07.016+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:02:07.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.411 seconds
[2024-04-30T19:02:37.536+0000] {processor.py:161} INFO - Started process (PID=524) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:02:37.538+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:02:37.539+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:02:37.539+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:02:38.040+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:02:38.038+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:02:38.040+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:02:38.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.539 seconds
[2024-04-30T19:03:08.637+0000] {processor.py:161} INFO - Started process (PID=526) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:03:08.640+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:03:08.641+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:03:08.641+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:03:09.585+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:03:09.584+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:03:09.586+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:03:09.633+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.024 seconds
[2024-04-30T19:03:40.179+0000] {processor.py:161} INFO - Started process (PID=528) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:03:40.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:03:40.182+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:03:40.181+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:03:40.559+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:03:40.558+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:03:40.559+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:03:40.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.412 seconds
[2024-04-30T19:04:10.988+0000] {processor.py:161} INFO - Started process (PID=530) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:04:10.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:04:10.990+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:04:10.990+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:04:11.397+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:04:11.396+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:04:11.397+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:04:11.414+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.439 seconds
[2024-04-30T19:04:41.758+0000] {processor.py:161} INFO - Started process (PID=532) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:04:41.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:04:41.761+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:04:41.761+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:04:42.142+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:04:42.141+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:04:42.143+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:04:42.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.422 seconds
[2024-04-30T19:05:12.587+0000] {processor.py:161} INFO - Started process (PID=534) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:05:12.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:05:12.590+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:05:12.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:05:12.967+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:05:12.966+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:05:12.968+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:05:12.981+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.408 seconds
[2024-04-30T19:05:43.375+0000] {processor.py:161} INFO - Started process (PID=536) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:05:43.377+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:05:43.378+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:05:43.378+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:05:44.249+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:05:44.246+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:05:44.250+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:05:44.307+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.942 seconds
[2024-04-30T19:06:14.409+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:06:14.410+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:06:14.411+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:06:14.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:06:14.837+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:06:14.835+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:06:14.837+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:06:14.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.454 seconds
[2024-04-30T19:06:45.316+0000] {processor.py:161} INFO - Started process (PID=540) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:06:45.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:06:45.319+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:06:45.318+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:06:45.712+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:06:45.710+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:06:45.712+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:06:45.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.419 seconds
[2024-04-30T19:07:16.163+0000] {processor.py:161} INFO - Started process (PID=542) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:07:16.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:07:16.166+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:07:16.165+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:07:16.562+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:07:16.561+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:07:16.563+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:07:16.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.450 seconds
[2024-04-30T19:07:46.981+0000] {processor.py:161} INFO - Started process (PID=544) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:07:46.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:07:46.984+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:07:46.983+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:07:47.368+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:07:47.366+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:07:47.368+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:07:47.386+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.416 seconds
[2024-04-30T19:08:17.769+0000] {processor.py:161} INFO - Started process (PID=546) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:08:17.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:08:17.777+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:08:17.775+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:08:18.144+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:08:18.143+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:08:18.145+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:08:18.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.406 seconds
[2024-04-30T19:08:48.611+0000] {processor.py:161} INFO - Started process (PID=548) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:08:48.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:08:48.615+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:08:48.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:08:48.994+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:08:48.993+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:08:48.995+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:08:49.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.412 seconds
[2024-04-30T19:09:19.420+0000] {processor.py:161} INFO - Started process (PID=550) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:09:19.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:09:19.423+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:09:19.423+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:09:19.811+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:09:19.810+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:09:19.811+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:09:19.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.420 seconds
[2024-04-30T19:09:50.276+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:09:50.278+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:09:50.279+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:09:50.278+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:09:50.634+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:09:50.633+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:09:50.634+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:09:50.647+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.384 seconds
[2024-04-30T19:10:21.079+0000] {processor.py:161} INFO - Started process (PID=554) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:10:21.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:10:21.083+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:10:21.082+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:10:21.461+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:10:21.460+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:10:21.461+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:10:21.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.406 seconds
[2024-04-30T19:10:51.928+0000] {processor.py:161} INFO - Started process (PID=556) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:10:51.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:10:51.931+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:10:51.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:10:52.306+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:10:52.305+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:10:52.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:10:52.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.408 seconds
[2024-04-30T19:11:22.750+0000] {processor.py:161} INFO - Started process (PID=558) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:11:22.752+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:11:22.754+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:11:22.753+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:11:23.098+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:11:23.097+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:11:23.099+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:11:23.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.376 seconds
[2024-04-30T19:11:53.541+0000] {processor.py:161} INFO - Started process (PID=560) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:11:53.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:11:53.544+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:11:53.543+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:11:53.897+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:11:53.896+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:11:53.897+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:11:53.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.405 seconds
[2024-04-30T19:12:24.295+0000] {processor.py:161} INFO - Started process (PID=562) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:12:24.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:12:24.299+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:12:24.299+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:12:24.671+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:12:24.669+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:12:24.671+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:12:24.695+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.412 seconds
[2024-04-30T19:12:55.237+0000] {processor.py:161} INFO - Started process (PID=564) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:12:55.239+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:12:55.240+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:12:55.239+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:12:55.740+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:12:55.738+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:12:55.740+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:12:55.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.527 seconds
[2024-04-30T19:13:26.321+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:13:26.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:13:26.329+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:13:26.327+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:13:27.244+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:13:27.235+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:13:27.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:13:27.309+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.006 seconds
[2024-04-30T19:13:57.778+0000] {processor.py:161} INFO - Started process (PID=568) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:13:57.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:13:57.781+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:13:57.781+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:13:58.441+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:13:58.430+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:13:58.444+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:13:58.577+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.808 seconds
[2024-04-30T19:14:29.216+0000] {processor.py:161} INFO - Started process (PID=570) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:14:29.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:14:29.239+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:14:29.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:14:30.026+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:14:30.025+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:14:30.026+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:14:30.058+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.911 seconds
[2024-04-30T19:15:00.617+0000] {processor.py:161} INFO - Started process (PID=572) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:15:00.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:15:00.620+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:15:00.619+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:15:01.012+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:15:01.011+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:15:01.013+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:15:01.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.449 seconds
[2024-04-30T19:15:31.635+0000] {processor.py:161} INFO - Started process (PID=574) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:15:31.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:15:31.639+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:15:31.638+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:15:32.305+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:15:32.303+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:15:32.305+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:15:32.326+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.716 seconds
[2024-04-30T19:16:02.542+0000] {processor.py:161} INFO - Started process (PID=576) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:16:02.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:16:02.552+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:16:02.551+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:16:03.098+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:16:03.096+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:16:03.099+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:16:03.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.610 seconds
[2024-04-30T19:16:33.548+0000] {processor.py:161} INFO - Started process (PID=578) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:16:33.551+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:16:33.552+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:16:33.551+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:16:34.325+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:16:34.324+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:16:34.326+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:16:34.349+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.827 seconds
[2024-04-30T19:17:05.309+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:17:05.310+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:17:05.311+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:17:05.311+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:17:05.776+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:17:05.775+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:17:05.777+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:17:05.801+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.503 seconds
[2024-04-30T19:17:36.303+0000] {processor.py:161} INFO - Started process (PID=582) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:17:36.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:17:36.307+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:17:36.306+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:17:36.678+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:17:36.677+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:17:36.678+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:17:36.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.419 seconds
[2024-04-30T19:18:07.271+0000] {processor.py:161} INFO - Started process (PID=584) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:18:07.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:18:07.274+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:18:07.273+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:18:07.660+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:18:07.659+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:18:07.661+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:18:07.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.424 seconds
[2024-04-30T19:18:37.976+0000] {processor.py:161} INFO - Started process (PID=586) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:18:37.977+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:18:37.978+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:18:37.978+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:18:38.375+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:18:38.374+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:18:38.376+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:18:38.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.436 seconds
[2024-04-30T19:19:08.799+0000] {processor.py:161} INFO - Started process (PID=588) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:19:08.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:19:08.803+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:19:08.803+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:19:09.163+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:19:09.162+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:19:09.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:19:09.179+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.406 seconds
[2024-04-30T19:19:39.588+0000] {processor.py:161} INFO - Started process (PID=590) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:19:39.590+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:19:39.592+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:19:39.591+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:19:39.970+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:19:39.969+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:19:39.970+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:19:40.017+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.446 seconds
[2024-04-30T19:20:10.487+0000] {processor.py:161} INFO - Started process (PID=592) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:20:10.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:20:10.491+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:20:10.490+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:20:10.876+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:20:10.875+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:20:10.877+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:20:10.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.423 seconds
[2024-04-30T19:20:41.278+0000] {processor.py:161} INFO - Started process (PID=594) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:20:41.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:20:41.282+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:20:41.281+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:20:41.675+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:20:41.674+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:20:41.675+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:20:41.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.432 seconds
[2024-04-30T19:21:12.144+0000] {processor.py:161} INFO - Started process (PID=596) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:21:12.146+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:21:12.147+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:21:12.146+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:21:12.514+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:21:12.513+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:21:12.514+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:21:12.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.428 seconds
[2024-04-30T19:21:42.911+0000] {processor.py:161} INFO - Started process (PID=598) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:21:42.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:21:42.914+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:21:42.914+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:21:43.315+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:21:43.313+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:21:43.315+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:21:43.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.434 seconds
[2024-04-30T19:22:13.780+0000] {processor.py:161} INFO - Started process (PID=600) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:22:13.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:22:13.792+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:22:13.791+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:22:14.193+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:22:14.192+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:22:14.194+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:22:14.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.449 seconds
[2024-04-30T19:22:44.599+0000] {processor.py:161} INFO - Started process (PID=602) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:22:44.601+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:22:44.602+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:22:44.602+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:22:45.015+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:22:45.014+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:22:45.016+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:22:45.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.446 seconds
[2024-04-30T19:23:15.450+0000] {processor.py:161} INFO - Started process (PID=604) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:23:15.452+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:23:15.454+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:23:15.453+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:23:15.829+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:23:15.828+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:23:15.830+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:23:15.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.434 seconds
[2024-04-30T19:23:46.240+0000] {processor.py:161} INFO - Started process (PID=606) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:23:46.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:23:46.243+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:23:46.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:23:46.612+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:23:46.611+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:23:46.613+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:23:46.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.431 seconds
[2024-04-30T19:24:17.066+0000] {processor.py:161} INFO - Started process (PID=608) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:24:17.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:24:17.072+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:24:17.071+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:24:17.475+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:24:17.474+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:24:17.476+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:24:17.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.457 seconds
[2024-04-30T19:24:47.850+0000] {processor.py:161} INFO - Started process (PID=610) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:24:47.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:24:47.855+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:24:47.854+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:24:48.234+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:24:48.233+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:24:48.234+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:24:48.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.435 seconds
[2024-04-30T19:25:18.675+0000] {processor.py:161} INFO - Started process (PID=612) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:25:18.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:25:18.678+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:25:18.677+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:25:19.072+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:25:19.071+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:25:19.073+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:25:19.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.432 seconds
[2024-04-30T19:25:49.519+0000] {processor.py:161} INFO - Started process (PID=614) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:25:49.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:25:49.521+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:25:49.521+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:25:49.879+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:25:49.878+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:25:49.880+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:25:49.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.391 seconds
[2024-04-30T19:26:20.342+0000] {processor.py:161} INFO - Started process (PID=616) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:26:20.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:26:20.345+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:26:20.344+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:26:20.731+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:26:20.730+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:26:20.731+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:26:20.746+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.422 seconds
[2024-04-30T19:26:51.207+0000] {processor.py:161} INFO - Started process (PID=618) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:26:51.208+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:26:51.209+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:26:51.209+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:26:51.583+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:26:51.582+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:26:51.583+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:26:51.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.431 seconds
[2024-04-30T19:27:22.044+0000] {processor.py:161} INFO - Started process (PID=620) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:27:22.045+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:27:22.047+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:27:22.046+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:27:22.464+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:27:22.462+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:27:22.464+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:27:22.478+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.448 seconds
[2024-04-30T19:27:52.876+0000] {processor.py:161} INFO - Started process (PID=622) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:27:52.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:27:52.878+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:27:52.878+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:27:53.308+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:27:53.307+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:27:53.308+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:27:53.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.467 seconds
[2024-04-30T19:28:23.810+0000] {processor.py:161} INFO - Started process (PID=624) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:28:23.812+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:28:23.813+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:28:23.813+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:28:24.195+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:28:24.189+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:28:24.196+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:28:24.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.473 seconds
[2024-04-30T19:28:54.734+0000] {processor.py:161} INFO - Started process (PID=626) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:28:54.739+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:28:54.742+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:28:54.741+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:28:55.161+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:28:55.160+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:28:55.162+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:28:55.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.495 seconds
[2024-04-30T19:29:25.633+0000] {processor.py:161} INFO - Started process (PID=628) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:29:25.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:29:25.636+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:29:25.636+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:29:26.003+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:29:26.002+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:29:26.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:29:26.016+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.401 seconds
[2024-04-30T19:29:56.443+0000] {processor.py:161} INFO - Started process (PID=630) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:29:56.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:29:56.448+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:29:56.447+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:29:56.807+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:29:56.806+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:29:56.808+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:29:56.822+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.398 seconds
[2024-04-30T19:30:26.940+0000] {processor.py:161} INFO - Started process (PID=632) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:30:26.942+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:30:26.943+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:30:26.942+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:30:27.320+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:30:27.319+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:30:27.321+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:30:27.333+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.407 seconds
[2024-04-30T19:30:57.876+0000] {processor.py:161} INFO - Started process (PID=634) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:30:57.884+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:30:57.888+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:30:57.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:30:58.613+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:30:58.611+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:30:58.613+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:30:58.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.795 seconds
[2024-04-30T19:31:29.381+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:31:29.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:31:29.385+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:31:29.384+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:31:30.086+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:31:30.084+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:31:30.086+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:31:30.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.759 seconds
[2024-04-30T19:32:00.609+0000] {processor.py:161} INFO - Started process (PID=638) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:32:00.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:32:00.614+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:32:00.613+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:32:01.044+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:32:01.043+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:32:01.044+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:32:01.061+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.466 seconds
[2024-04-30T19:32:31.458+0000] {processor.py:161} INFO - Started process (PID=640) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:32:31.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:32:31.462+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:32:31.461+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:32:31.824+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:32:31.821+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:32:31.824+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:32:31.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.416 seconds
[2024-04-30T19:33:02.241+0000] {processor.py:161} INFO - Started process (PID=642) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:33:02.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:33:02.244+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:33:02.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:33:02.596+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:33:02.595+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:33:02.596+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:33:02.611+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.384 seconds
[2024-04-30T19:33:33.000+0000] {processor.py:161} INFO - Started process (PID=644) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:33:33.001+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:33:33.002+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:33:33.002+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:33:33.388+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:33:33.387+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:33:33.389+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:33:33.405+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.419 seconds
[2024-04-30T19:34:03.883+0000] {processor.py:161} INFO - Started process (PID=646) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:34:03.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:34:03.886+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:34:03.886+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:34:04.628+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:34:04.627+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:34:04.629+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:34:04.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.782 seconds
[2024-04-30T19:34:34.821+0000] {processor.py:161} INFO - Started process (PID=648) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:34:34.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:34:34.824+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:34:34.824+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:34:35.180+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:34:35.179+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:34:35.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:34:35.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.409 seconds
[2024-04-30T19:35:05.649+0000] {processor.py:161} INFO - Started process (PID=650) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:35:05.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:35:05.652+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:35:05.652+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:35:06.130+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:35:06.129+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv, extract_images
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:35:06.131+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:35:06.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.517 seconds
[2024-04-30T19:35:09.302+0000] {processor.py:161} INFO - Started process (PID=652) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:35:09.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:35:09.306+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:35:09.306+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:35:09.333+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:35:09.331+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 8, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
ModuleNotFoundError: No module named 'pipelines'
[2024-04-30T19:35:09.336+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:35:09.385+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.114 seconds
[2024-04-30T19:35:39.773+0000] {processor.py:161} INFO - Started process (PID=653) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:35:39.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:35:39.775+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:35:39.775+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:35:39.781+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:35:39.781+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 8, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
ModuleNotFoundError: No module named 'pipelines'
[2024-04-30T19:35:39.781+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:35:39.802+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.044 seconds
[2024-04-30T19:36:10.137+0000] {processor.py:161} INFO - Started process (PID=654) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:36:10.138+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:36:10.139+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:36:10.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:36:10.144+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:36:10.143+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 8, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
ModuleNotFoundError: No module named 'pipelines'
[2024-04-30T19:36:10.144+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:36:10.172+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.060 seconds
[2024-04-30T19:36:40.573+0000] {processor.py:161} INFO - Started process (PID=655) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:36:40.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:36:40.578+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:36:40.577+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:36:40.589+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:36:40.588+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 8, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
ModuleNotFoundError: No module named 'pipelines'
[2024-04-30T19:36:40.589+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:36:40.629+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.079 seconds
[2024-04-30T19:36:53.843+0000] {processor.py:161} INFO - Started process (PID=656) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:36:53.845+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:36:53.846+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:36:53.845+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:36:55.066+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:36:55.058+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:36:55.068+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:36:55.090+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.266 seconds
[2024-04-30T19:37:25.308+0000] {processor.py:161} INFO - Started process (PID=658) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:37:25.315+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:37:25.317+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:37:25.316+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:37:25.871+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:37:25.870+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:37:25.872+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:37:25.896+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.609 seconds
[2024-04-30T19:37:56.247+0000] {processor.py:161} INFO - Started process (PID=660) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:37:56.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:37:56.251+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:37:56.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:37:56.655+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:37:56.654+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:37:56.655+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:37:56.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.449 seconds
[2024-04-30T19:38:27.447+0000] {processor.py:161} INFO - Started process (PID=662) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:38:27.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:38:27.451+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:38:27.450+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:38:27.913+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:38:27.912+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/redditEtl.py", line 11, in <module>
    from google.cloud import api_keys_v2
ImportError: cannot import name 'api_keys_v2' from 'google.cloud' (unknown location)
[2024-04-30T19:38:27.913+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:38:27.925+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.498 seconds
[2024-04-30T19:38:58.393+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:38:58.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:38:58.402+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:38:58.398+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:38:59.116+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:38:59.112+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/redditEtl.py", line 10, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 12, in <module>
    GOOGLE_CX = parser.get('googl_api_keys', 'google_cx')
  File "/usr/local/lib/python3.9/configparser.py", line 781, in get
    d = self._unify_values(section, vars)
  File "/usr/local/lib/python3.9/configparser.py", line 1152, in _unify_values
    raise NoSectionError(section) from None
configparser.NoSectionError: No section: 'googl_api_keys'
[2024-04-30T19:38:59.117+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:38:59.166+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.794 seconds
[2024-04-30T19:39:29.641+0000] {processor.py:161} INFO - Started process (PID=666) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:39:29.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:39:29.646+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:39:29.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:39:30.110+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:39:30.106+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/redditEtl.py", line 10, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 12, in <module>
    GOOGLE_CX = parser.get('googl_api_keys', 'google_cx')
  File "/usr/local/lib/python3.9/configparser.py", line 781, in get
    d = self._unify_values(section, vars)
  File "/usr/local/lib/python3.9/configparser.py", line 1152, in _unify_values
    raise NoSectionError(section) from None
configparser.NoSectionError: No section: 'googl_api_keys'
[2024-04-30T19:39:30.111+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:39:30.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.531 seconds
[2024-04-30T19:40:00.727+0000] {processor.py:161} INFO - Started process (PID=668) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T19:40:00.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T19:40:00.731+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:40:00.730+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T19:40:01.162+0000] {logging_mixin.py:188} INFO - [2024-04-30T19:40:01.160+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/redditEtl.py", line 10, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 12, in <module>
    GOOGLE_CX = parser.get('googl_api_keys', 'google_cx')
  File "/usr/local/lib/python3.9/configparser.py", line 781, in get
    d = self._unify_values(section, vars)
  File "/usr/local/lib/python3.9/configparser.py", line 1152, in _unify_values
    raise NoSectionError(section) from None
configparser.NoSectionError: No section: 'googl_api_keys'
[2024-04-30T19:40:01.162+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T19:40:01.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.473 seconds
[2024-04-30T20:29:17.458+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:29:17.470+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:29:17.488+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:29:17.485+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:29:18.751+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:29:18.742+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 12, in <module>
    GOOGLE_CX = parser.get('googl_api_keys', 'google_cx')
  File "/usr/local/lib/python3.9/configparser.py", line 781, in get
    d = self._unify_values(section, vars)
  File "/usr/local/lib/python3.9/configparser.py", line 1152, in _unify_values
    raise NoSectionError(section) from None
configparser.NoSectionError: No section: 'googl_api_keys'
[2024-04-30T20:29:18.752+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:29:18.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.369 seconds
[2024-04-30T20:29:49.106+0000] {processor.py:161} INFO - Started process (PID=31) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:29:49.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:29:49.114+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:29:49.113+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:29:50.028+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:29:50.026+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 10, in <module>
    from pipelines.redditPipeline import reddit_pipeline
  File "/opt/airflow/pipelines/redditPipeline.py", line 4, in <module>
    from etls.redditEtl import connect_reddit, extract_posts, transform_data, load_data_to_csv
  File "/opt/airflow/etls/redditEtl.py", line 8, in <module>
    from utils.constants import POST_FIELDS
  File "/opt/airflow/utils/constants.py", line 12, in <module>
    GOOGLE_CX = parser.get('googl_api_keys', 'google_cx')
  File "/usr/local/lib/python3.9/configparser.py", line 781, in get
    d = self._unify_values(section, vars)
  File "/usr/local/lib/python3.9/configparser.py", line 1152, in _unify_values
    raise NoSectionError(section) from None
configparser.NoSectionError: No section: 'googl_api_keys'
[2024-04-30T20:29:50.029+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:29:50.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.971 seconds
[2024-04-30T20:30:20.661+0000] {processor.py:161} INFO - Started process (PID=33) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:30:20.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:30:20.668+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:30:20.667+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:30:21.916+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:30:21.937+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:30:21.936+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:30:21.953+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:30:21.952+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-29 00:00:00+00:00, run_after=2024-04-30 00:00:00+00:00
[2024-04-30T20:30:21.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.315 seconds
[2024-04-30T20:30:52.112+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:30:52.114+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:30:52.120+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:30:52.118+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:30:52.770+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:30:52.855+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:30:52.855+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:30:52.869+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:30:52.869+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:30:52.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.787 seconds
[2024-04-30T20:31:23.669+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:31:23.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:31:23.683+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:31:23.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:31:24.540+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:31:24.604+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:31:24.603+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:31:24.642+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:31:24.641+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:31:24.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.006 seconds
[2024-04-30T20:31:42.297+0000] {processor.py:161} INFO - Started process (PID=45) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:31:42.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:31:42.307+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:31:42.306+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:31:42.803+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:31:42.905+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:31:42.904+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:31:42.919+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:31:42.919+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:31:42.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.655 seconds
[2024-04-30T20:32:13.356+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:32:13.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:32:13.371+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:32:13.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:32:13.820+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:32:13.847+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:32:13.847+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:32:13.857+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:32:13.857+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:32:13.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.525 seconds
[2024-04-30T20:32:44.318+0000] {processor.py:161} INFO - Started process (PID=53) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:32:44.321+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:32:44.326+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:32:44.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:32:44.761+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:32:44.780+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:32:44.780+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:32:44.799+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:32:44.799+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:32:44.808+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.506 seconds
[2024-04-30T20:33:15.231+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:33:15.234+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:33:15.238+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:33:15.237+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:33:15.706+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:33:15.738+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:33:15.738+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:33:15.749+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:33:15.748+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:33:15.756+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.539 seconds
[2024-04-30T20:33:46.087+0000] {processor.py:161} INFO - Started process (PID=57) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:33:46.089+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:33:46.092+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:33:46.092+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:33:46.524+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:33:46.539+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:33:46.539+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:33:46.549+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:33:46.549+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:33:46.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.487 seconds
[2024-04-30T20:34:16.936+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:34:16.938+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:34:16.941+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:34:16.941+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:34:17.385+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:34:17.401+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:34:17.401+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:34:17.411+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:34:17.411+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:34:17.419+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.504 seconds
[2024-04-30T20:34:47.898+0000] {processor.py:161} INFO - Started process (PID=61) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:34:47.901+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:34:47.906+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:34:47.905+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:34:48.382+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:34:48.400+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:34:48.399+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:34:48.409+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:34:48.409+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:34:48.417+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.540 seconds
[2024-04-30T20:35:19.014+0000] {processor.py:161} INFO - Started process (PID=63) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:35:19.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:35:19.031+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:35:19.029+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:35:19.723+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:35:19.746+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:35:19.745+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:35:19.767+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:35:19.766+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:35:19.775+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.796 seconds
[2024-04-30T20:35:24.971+0000] {processor.py:161} INFO - Started process (PID=65) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:35:24.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:35:24.976+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:35:24.975+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:35:25.832+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:35:25.929+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:35:25.929+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:35:25.952+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:35:25.952+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:35:25.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.025 seconds
[2024-04-30T20:35:56.521+0000] {processor.py:161} INFO - Started process (PID=71) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:35:56.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:35:56.526+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:35:56.525+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:35:57.019+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:35:57.036+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:35:57.036+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:35:57.051+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:35:57.051+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:35:57.060+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.554 seconds
[2024-04-30T20:36:27.527+0000] {processor.py:161} INFO - Started process (PID=73) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:36:27.530+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:36:27.533+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:36:27.532+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:36:27.982+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:36:28.000+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:36:28.000+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:36:28.011+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:36:28.011+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:36:28.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.512 seconds
[2024-04-30T20:36:58.456+0000] {processor.py:161} INFO - Started process (PID=75) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:36:58.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:36:58.461+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:36:58.461+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:36:58.910+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:36:58.931+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:36:58.931+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:36:58.949+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:36:58.949+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:36:58.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.535 seconds
[2024-04-30T20:37:29.384+0000] {processor.py:161} INFO - Started process (PID=77) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:37:29.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:37:29.389+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:37:29.389+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:37:29.813+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:37:29.852+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:37:29.852+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:37:29.863+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:37:29.863+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:37:29.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.500 seconds
[2024-04-30T20:38:00.298+0000] {processor.py:161} INFO - Started process (PID=79) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:38:00.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:38:00.303+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:38:00.303+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:38:00.749+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:38:00.765+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:38:00.765+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:38:00.778+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:38:00.777+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:38:00.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.507 seconds
[2024-04-30T20:38:31.371+0000] {processor.py:161} INFO - Started process (PID=81) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:38:31.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:38:31.377+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:38:31.377+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:38:31.858+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:38:31.875+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:38:31.875+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:38:31.888+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:38:31.887+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:38:31.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.553 seconds
[2024-04-30T20:39:02.310+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:39:02.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:39:02.315+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:39:02.315+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:39:02.770+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:39:02.789+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:39:02.789+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:39:02.799+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:39:02.799+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:39:02.807+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.526 seconds
[2024-04-30T20:39:33.227+0000] {processor.py:161} INFO - Started process (PID=85) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:39:33.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:39:33.233+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:39:33.232+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:39:33.626+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:39:33.623+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 38
    'totalResults': data['searchInformation']['totalResults'],
    ^
SyntaxError: invalid syntax
[2024-04-30T20:39:33.626+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:39:33.644+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.443 seconds
[2024-04-30T20:40:04.097+0000] {processor.py:161} INFO - Started process (PID=87) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:40:04.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:40:04.118+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:40:04.117+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:40:04.555+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:40:04.553+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 38
    'totalResults': data['searchInformation']['totalResults'],
    ^
SyntaxError: invalid syntax
[2024-04-30T20:40:04.555+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:40:04.570+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.485 seconds
[2024-04-30T20:40:35.150+0000] {processor.py:161} INFO - Started process (PID=89) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:40:35.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:40:35.154+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:40:35.154+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:40:35.575+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:40:35.574+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 38
    'totalResults': data['searchInformation']['totalResults'],
    ^
SyntaxError: invalid syntax
[2024-04-30T20:40:35.576+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:40:35.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.472 seconds
[2024-04-30T20:41:05.929+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:41:05.931+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:41:05.933+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:41:05.932+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:41:06.302+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:41:06.301+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 38
    'totalResults': data['searchInformation']['totalResults'],
    ^
SyntaxError: invalid syntax
[2024-04-30T20:41:06.302+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:41:06.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.421 seconds
[2024-04-30T20:41:36.745+0000] {processor.py:161} INFO - Started process (PID=93) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:41:36.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:41:36.749+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:41:36.748+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:41:37.131+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:41:37.130+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 38
    'totalResults': data['searchInformation']['totalResults'],
    ^
SyntaxError: invalid syntax
[2024-04-30T20:41:37.132+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:41:37.147+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.416 seconds
[2024-04-30T20:42:07.719+0000] {processor.py:161} INFO - Started process (PID=95) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:42:07.723+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:42:07.724+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:42:07.724+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:42:08.318+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:42:08.418+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:42:08.418+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:42:08.429+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:42:08.429+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:42:08.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.769 seconds
[2024-04-30T20:42:38.906+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:42:38.908+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:42:38.909+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:42:38.909+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:42:39.741+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:42:39.798+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:42:39.798+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:42:39.827+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:42:39.827+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:42:39.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.952 seconds
[2024-04-30T20:43:10.332+0000] {processor.py:161} INFO - Started process (PID=99) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:43:10.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:43:10.342+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:43:10.341+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:43:11.268+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:43:11.294+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:43:11.294+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:43:11.308+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:43:11.308+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:43:11.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.105 seconds
[2024-04-30T20:43:41.492+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:43:41.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:43:41.495+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:43:41.495+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:43:41.918+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:43:41.941+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:43:41.940+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:43:41.951+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:43:41.951+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:43:41.958+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.479 seconds
[2024-04-30T20:44:12.108+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:44:12.118+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:44:12.121+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:44:12.119+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:44:12.782+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:44:12.820+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:44:12.820+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:44:12.832+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:44:12.832+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:44:12.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.745 seconds
[2024-04-30T20:44:43.572+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:44:43.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:44:43.576+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:44:43.575+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:44:44.162+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:44:44.182+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:44:44.181+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:44:44.202+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:44:44.202+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:44:44.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.648 seconds
[2024-04-30T20:45:14.711+0000] {processor.py:161} INFO - Started process (PID=115) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:45:14.714+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:45:14.715+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:45:14.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:45:15.295+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:45:15.321+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:45:15.321+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:45:15.336+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:45:15.335+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:45:15.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.648 seconds
[2024-04-30T20:45:45.897+0000] {processor.py:161} INFO - Started process (PID=117) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:45:45.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:45:45.900+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:45:45.899+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:45:46.455+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:45:46.488+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:45:46.488+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:45:46.502+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:45:46.502+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:45:46.513+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.626 seconds
[2024-04-30T20:46:16.644+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:46:16.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:46:16.646+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:46:16.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:46:17.127+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:46:17.147+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:46:17.147+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:46:17.160+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:46:17.160+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:46:17.167+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.552 seconds
[2024-04-30T20:46:47.584+0000] {processor.py:161} INFO - Started process (PID=121) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:46:47.585+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:46:47.586+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:46:47.586+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:46:48.080+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:46:48.111+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:46:48.111+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:46:48.122+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:46:48.122+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:46:48.135+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.573 seconds
[2024-04-30T20:47:18.615+0000] {processor.py:161} INFO - Started process (PID=123) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:47:18.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:47:18.618+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:47:18.618+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:47:19.672+0000] {logging_mixin.py:188} INFO - {'kind': 'customsearch#search', 'url': {'type': 'application/json', 'template': 'https://www.googleapis.com/customsearch/v1?q={searchTerms}&num={count?}&start={startIndex?}&lr={language?}&safe={safe?}&cx={cx?}&sort={sort?}&filter={filter?}&gl={gl?}&cr={cr?}&googlehost={googleHost?}&c2coff={disableCnTwTranslation?}&hq={hq?}&hl={hl?}&siteSearch={siteSearch?}&siteSearchFilter={siteSearchFilter?}&exactTerms={exactTerms?}&excludeTerms={excludeTerms?}&linkSite={linkSite?}&orTerms={orTerms?}&dateRestrict={dateRestrict?}&lowRange={lowRange?}&highRange={highRange?}&searchType={searchType}&fileType={fileType?}&rights={rights?}&imgSize={imgSize?}&imgType={imgType?}&imgColorType={imgColorType?}&imgDominantColor={imgDominantColor?}&alt=json'}, 'queries': {'request': [{'title': 'Google Custom Search - data engineering', 'totalResults': '26500', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 1, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}], 'nextPage': [{'title': 'Google Custom Search - data engineering', 'totalResults': '26500', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 11, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}]}, 'context': {'title': 'my-test-search-engine'}, 'searchInformation': {'searchTime': 0.25812, 'formattedSearchTime': '0.26', 'totalResults': '26500', 'formattedTotalResults': '26,500'}, 'items': [{'kind': 'customsearch#result', 'title': 'Data Engineering', 'htmlTitle': '<b>Data Engineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/', 'displayLink': 'www.reddit.com', 'snippet': 'r/dataengineering: News & discussion on Data Engineering topics, including but not limited to: data pipelines, databases, data formats, storage, data…', 'htmlSnippet': 'r/<b>dataengineering</b>: News &amp; discussion on <b>Data Engineering</b> topics, including but not limited to: data pipelines, databases, data formats, storage, data…', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/', 'pagemap': {'cse_thumbnail': [{'src': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQk9OkztNOzwb73X1pn3x2keu6xnV-1ekZMpK8R245Gd47DbA7Joj7mMmk&s', 'width': '225', 'height': '225'}], 'metatags': [{'og:image': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png', 'theme-color': '#000000', 'og:image:width': '256', 'og:type': 'website', 'twitter:card': 'summary', 'twitter:title': 'r/dataengineering', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering', 'og:image:height': '256', 'bingbot': 'noarchive', 'msapplication-navbutton-color': '#000000', 'og:description': 'News & discussion on Data Engineering topics, including but not limited to: data pipelines, databases, data formats, storage, data modeling, data governance, cleansing, NoSQL, distributed systems, streaming, batch, Big Data, and workflow engines.', 'twitter:image': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/'}], 'cse_image': [{'src': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png'}]}}, {'kind': 'customsearch#result', 'title': 'Does data engineering not have as much interesting career ...', 'htmlTitle': 'Does <b>data engineering</b> not have as much interesting career ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/12qldg7/does_data_engineering_not_have_as_much/', 'displayLink': 'www.reddit.com', 'snippet': 'Apr 18, 2023 ... Because data eng is already diverse within itself. You can pick up and practice skills in devops, backend development, ML, BI, systems and\xa0...', 'htmlSnippet': 'Apr 18, 2023 <b>...</b> Because <b>data</b> eng is already diverse within itself. You can pick up and practice skills in devops, backend development, ML, BI, systems and&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../does_data_engineering_not_...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../does_<b>data</b>_<b>engineering</b>_not_...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/12qldg7', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Does data engineering not have as much interesting career progression as other areas of engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Does data engineering not have as much interesting career progression as other areas of engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/level_126_programmer - 108 votes and 55 comments', 'twitter:image': 'https://share.redd.it/preview/post/12qldg7', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/12qldg7/does_data_engineering_not_have_as_much/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/12qldg7'}]}}, {'kind': 'customsearch#result', 'title': 'What do you guys think of "Fundamentals of Data Engineering" book ...', 'htmlTitle': 'What do you guys think of &quot;Fundamentals of <b>Data Engineering</b>&quot; book ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/18ydlv0/what_do_you_guys_think_of_fundamentals_of_data/', 'displayLink': 'www.reddit.com', 'snippet': 'Jan 4, 2024 ... IMHO Fundamentals of DE is really good and very useful overview of the field suitable for interview prep as well as for adding breadth to your\xa0...', 'htmlSnippet': 'Jan 4, 2024 <b>...</b> IMHO Fundamentals of DE is really good and very useful overview of the field suitable for interview prep as well as for adding breadth to your&nbsp;...', 'cacheId': 'PqZ2CQqqH7oJ', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../what_do_you_guys_think_of...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../what_do_you_guys_think_of...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/18ydlv0', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: What do you guys think of "Fundamentals of Data Engineering" book?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: What do you guys think of "Fundamentals of Data Engineering" book?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/thethewaza - 47 votes and 23 comments', 'twitter:image': 'https://share.redd.it/preview/post/18ydlv0', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/18ydlv0/what_do_you_guys_think_of_fundamentals_of_data/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/18ydlv0'}]}}, {'kind': 'customsearch#result', 'title': 'Giving up data engineering : r/dataengineering', 'htmlTitle': 'Giving up <b>data engineering</b> : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': "Mar 4, 2024 ... Giving up data engineering · The no1 question is do you enjoy what you do? Life is not about money it's about happiness. · All jobs have burnout\xa0...", 'htmlSnippet': 'Mar 4, 2024 <b>...</b> Giving up <b>data engineering</b> &middot; The no1 question is do you enjoy what you do? Life is not about money it&#39;s about happiness. &middot; All jobs have burnout&nbsp;...', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../giving_up_data_engineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../giving_up_<b>data</b>_<b>engineering</b>/', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/1b67xnz', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Giving up data engineering', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Giving up data engineering', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Two_5536 - 173 votes and 82 comments', 'twitter:image': 'https://share.redd.it/preview/post/1b67xnz', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/1b67xnz'}]}}, {'kind': 'customsearch#result', 'title': 'Any Data Engineering Podcasts? : r/dataengineering', 'htmlTitle': 'Any <b>Data Engineering</b> Podcasts? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/13lppxu/any_data_engineering_podcasts/', 'displayLink': 'www.reddit.com', 'snippet': 'May 19, 2023 ... 95 votes, 18 comments. Want to ask if there are any data engineering podcasts to listen while working :) I am willing to listen more\xa0...', 'htmlSnippet': 'May 19, 2023 <b>...</b> 95 votes, 18 comments. Want to ask if there are any <b>data engineering</b> podcasts to listen while working :) I am willing to listen more&nbsp;...', 'cacheId': 'F3VisjP1jqEJ', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../any_data_engineering_podcast...', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../any_<b>data</b>_<b>engineering</b>_podcast...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/13lppxu', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Any Data Engineering Podcasts?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Any Data Engineering Podcasts?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/paolapardo - 95 votes and 18 comments', 'twitter:image': 'https://share.redd.it/preview/post/13lppxu', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/13lppxu/any_data_engineering_podcasts/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/13lppxu'}]}}, {'kind': 'customsearch#result', 'title': 'Rust in Data Engineering? : r/dataengineering', 'htmlTitle': 'Rust in <b>Data Engineering</b>? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/16dgor2/rust_in_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': 'Sep 8, 2023 ... Rust has a steep getting started curve as you can tell, but it is the most efficient distributed programming paradigm by far with a pedantic\xa0...', 'htmlSnippet': 'Sep 8, 2023 <b>...</b> Rust has a steep getting started curve as you can tell, but it is the most efficient distributed programming paradigm by far with a pedantic&nbsp;...', 'cacheId': 'o8rzSMBF7IsJ', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../rust_in_data_engineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../rust_in_<b>data</b>_<b>engineering</b>/', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/16dgor2', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Rust in Data Engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Rust in Data Engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/hsimpsondata - 23 votes and 32 comments', 'twitter:image': 'https://share.redd.it/preview/post/16dgor2', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/16dgor2/rust_in_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/16dgor2'}]}}, {'kind': 'customsearch#result', 'title': 'Data engineering blogs worth reading : r/dataengineering', 'htmlTitle': '<b>Data engineering</b> blogs worth reading : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/u99v1q/data_engineering_blogs_worth_reading/', 'displayLink': 'www.reddit.com', 'snippet': 'Apr 22, 2022 ... Data engineering blogs worth reading · Data Engineering on Medium and Towards Data Science · Benn, Sarah, Mikkel, Tristan on dbt blog · Cool\xa0...', 'htmlSnippet': 'Apr 22, 2022 <b>...</b> <b>Data engineering</b> blogs worth reading &middot; <b>Data Engineering</b> on Medium and Towards <b>Data Science</b> &middot; Benn, Sarah, Mikkel, Tristan on dbt blog &middot; Cool&nbsp;...', 'cacheId': 'hkHfkPdOgL8J', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../data_engineering_blogs_wort...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../<b>data</b>_<b>engineering</b>_blogs_wort...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/u99v1q', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Data engineering blogs worth reading', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Data engineering blogs worth reading', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Anna-Kraska - 133 votes and 20 comments', 'twitter:image': 'https://share.redd.it/preview/post/u99v1q', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/u99v1q/data_engineering_blogs_worth_reading/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/u99v1q'}]}}, {'kind': 'customsearch#result', 'title': "Any feedback on Zach Wilson's Data Engineering bootcamp? : r ...", 'htmlTitle': 'Any feedback on Zach Wilson&#39;s <b>Data Engineering</b> bootcamp? : r ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/14ieh8u/any_feedback_on_zach_wilsons_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': 'Jun 25, 2023 ... Each class was roughly half lecture, half lab/applied learning, and I would say I learned a lot of applicable concepts and techniques in each\xa0...', 'htmlSnippet': 'Jun 25, 2023 <b>...</b> Each class was roughly half lecture, half lab/applied learning, and I would say I learned a lot of applicable concepts and techniques in each&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../any_feedback_on_zach_wils...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../any_feedback_on_zach_wils...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/14ieh8u', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Any feedback on Zach Wilson’s Data Engineering bootcamp?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Any feedback on Zach Wilson’s Data Engineering bootcamp?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/techblogp - 39 votes and 114 comments', 'twitter:image': 'https://share.redd.it/preview/post/14ieh8u', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/14ieh8u/any_feedback_on_zach_wilsons_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/14ieh8u'}]}}, {'kind': 'customsearch#result', 'title': 'Scala or Python for Data engineering? : r/dataengineering', 'htmlTitle': 'Scala or Python for <b>Data engineering</b>? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': "Oct 31, 2022 ... I've watched multiple data engineers switch to scala over time due to performance gains. As they got deeper into development they found scala to\xa0...", 'htmlSnippet': 'Oct 31, 2022 <b>...</b> I&#39;ve watched multiple <b>data engineers</b> switch to scala over time due to performance gains. As they got deeper into development they found scala to&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../scala_or_python_for_data_en...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../scala_or_python_for_<b>data</b>_<b>en</b>...', 'pagemap': {'cse_thumbnail': [{'src': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQPe6wVSU03P_xl2S8EUeJw2RDir-arhdX20ADvXRHwf-DbpMgcPHQKJWU&s', 'width': '311', 'height': '162'}], 'metatags': [{'og:image': 'https://share.redd.it/preview/post/yieto6', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Scala or Python for Data engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Scala or Python for Data engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/forneptune - 56 votes and 34 comments', 'twitter:image': 'https://share.redd.it/preview/post/yieto6', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/'}], 'cse_image': [{'src': 'https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?auto=webp&s=28b9ae149e0b4d698c919c86cb9694173c82dafd'}]}}, {'kind': 'customsearch#result', 'title': 'Why are there no entry-level data engineering jobs? : r ...', 'htmlTitle': 'Why are there no entry-level <b>data engineering</b> jobs? : r ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/qv43ad/why_are_there_no_entrylevel_data_engineering_jobs/', 'displayLink': 'www.reddit.com', 'snippet': 'Nov 16, 2021 ... There are probably not many entry-level data engineer positions because of how cross-disciplinary it is. You need to know coding, SQL, DBA,\xa0...', 'htmlSnippet': 'Nov 16, 2021 <b>...</b> There are probably not many entry-level <b>data engineer</b> positions because of how cross-disciplinary it is. You need to know coding, SQL, DBA,&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../why_are_there_no_entrylevel...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../why_are_there_no_entrylevel...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/qv43ad', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Why are there no entry-level data engineering jobs?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Why are there no entry-level data engineering jobs?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Born-Comment3359 - 64 votes and 45 comments', 'twitter:image': 'https://share.redd.it/preview/post/qv43ad', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/qv43ad/why_are_there_no_entrylevel_data_engineering_jobs/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/qv43ad'}]}}]}
[2024-04-30T20:47:19.766+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:47:19.804+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:47:19.804+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:47:19.819+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:47:19.818+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:47:19.827+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.224 seconds
[2024-04-30T20:47:50.130+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:47:50.131+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:47:50.133+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:47:50.132+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:47:51.579+0000] {logging_mixin.py:188} INFO - {'kind': 'customsearch#search', 'url': {'type': 'application/json', 'template': 'https://www.googleapis.com/customsearch/v1?q={searchTerms}&num={count?}&start={startIndex?}&lr={language?}&safe={safe?}&cx={cx?}&sort={sort?}&filter={filter?}&gl={gl?}&cr={cr?}&googlehost={googleHost?}&c2coff={disableCnTwTranslation?}&hq={hq?}&hl={hl?}&siteSearch={siteSearch?}&siteSearchFilter={siteSearchFilter?}&exactTerms={exactTerms?}&excludeTerms={excludeTerms?}&linkSite={linkSite?}&orTerms={orTerms?}&dateRestrict={dateRestrict?}&lowRange={lowRange?}&highRange={highRange?}&searchType={searchType}&fileType={fileType?}&rights={rights?}&imgSize={imgSize?}&imgType={imgType?}&imgColorType={imgColorType?}&imgDominantColor={imgDominantColor?}&alt=json'}, 'queries': {'request': [{'title': 'Google Custom Search - data engineering', 'totalResults': '25900', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 1, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}], 'nextPage': [{'title': 'Google Custom Search - data engineering', 'totalResults': '25900', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 11, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}]}, 'context': {'title': 'my-test-search-engine'}, 'searchInformation': {'searchTime': 0.428068, 'formattedSearchTime': '0.43', 'totalResults': '25900', 'formattedTotalResults': '25,900'}, 'items': [{'kind': 'customsearch#result', 'title': 'Data Engineering', 'htmlTitle': '<b>Data Engineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/', 'displayLink': 'www.reddit.com', 'snippet': 'r/dataengineering: News & discussion on Data Engineering topics, including but not limited to: data pipelines, databases, data formats, storage, data…', 'htmlSnippet': 'r/<b>dataengineering</b>: News &amp; discussion on <b>Data Engineering</b> topics, including but not limited to: data pipelines, databases, data formats, storage, data…', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/', 'pagemap': {'cse_thumbnail': [{'src': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQk9OkztNOzwb73X1pn3x2keu6xnV-1ekZMpK8R245Gd47DbA7Joj7mMmk&s', 'width': '225', 'height': '225'}], 'metatags': [{'og:image': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png', 'theme-color': '#000000', 'og:image:width': '256', 'og:type': 'website', 'twitter:card': 'summary', 'twitter:title': 'r/dataengineering', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering', 'og:image:height': '256', 'bingbot': 'noarchive', 'msapplication-navbutton-color': '#000000', 'og:description': 'News & discussion on Data Engineering topics, including but not limited to: data pipelines, databases, data formats, storage, data modeling, data governance, cleansing, NoSQL, distributed systems, streaming, batch, Big Data, and workflow engines.', 'twitter:image': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/'}], 'cse_image': [{'src': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png'}]}}, {'kind': 'customsearch#result', 'title': 'Does data engineering not have as much interesting career ...', 'htmlTitle': 'Does <b>data engineering</b> not have as much interesting career ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/12qldg7/does_data_engineering_not_have_as_much/', 'displayLink': 'www.reddit.com', 'snippet': 'Apr 18, 2023 ... Because data eng is already diverse within itself. You can pick up and practice skills in devops, backend development, ML, BI, systems and\xa0...', 'htmlSnippet': 'Apr 18, 2023 <b>...</b> Because <b>data</b> eng is already diverse within itself. You can pick up and practice skills in devops, backend development, ML, BI, systems and&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../does_data_engineering_not_...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../does_<b>data</b>_<b>engineering</b>_not_...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/12qldg7', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Does data engineering not have as much interesting career progression as other areas of engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Does data engineering not have as much interesting career progression as other areas of engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/level_126_programmer - 108 votes and 55 comments', 'twitter:image': 'https://share.redd.it/preview/post/12qldg7', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/12qldg7/does_data_engineering_not_have_as_much/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/12qldg7'}]}}, {'kind': 'customsearch#result', 'title': 'What do you guys think of "Fundamentals of Data Engineering" book ...', 'htmlTitle': 'What do you guys think of &quot;Fundamentals of <b>Data Engineering</b>&quot; book ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/18ydlv0/what_do_you_guys_think_of_fundamentals_of_data/', 'displayLink': 'www.reddit.com', 'snippet': 'Jan 4, 2024 ... IMHO Fundamentals of DE is really good and very useful overview of the field suitable for interview prep as well as for adding breadth to your\xa0...', 'htmlSnippet': 'Jan 4, 2024 <b>...</b> IMHO Fundamentals of DE is really good and very useful overview of the field suitable for interview prep as well as for adding breadth to your&nbsp;...', 'cacheId': 'PqZ2CQqqH7oJ', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../what_do_you_guys_think_of...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../what_do_you_guys_think_of...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/18ydlv0', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: What do you guys think of "Fundamentals of Data Engineering" book?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: What do you guys think of "Fundamentals of Data Engineering" book?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/thethewaza - 47 votes and 23 comments', 'twitter:image': 'https://share.redd.it/preview/post/18ydlv0', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/18ydlv0/what_do_you_guys_think_of_fundamentals_of_data/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/18ydlv0'}]}}, {'kind': 'customsearch#result', 'title': 'Giving up data engineering : r/dataengineering', 'htmlTitle': 'Giving up <b>data engineering</b> : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': "Mar 4, 2024 ... Giving up data engineering · The no1 question is do you enjoy what you do? Life is not about money it's about happiness. · All jobs have burnout\xa0...", 'htmlSnippet': 'Mar 4, 2024 <b>...</b> Giving up <b>data engineering</b> &middot; The no1 question is do you enjoy what you do? Life is not about money it&#39;s about happiness. &middot; All jobs have burnout&nbsp;...', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../giving_up_data_engineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../giving_up_<b>data</b>_<b>engineering</b>/', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/1b67xnz', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Giving up data engineering', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Giving up data engineering', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Two_5536 - 173 votes and 82 comments', 'twitter:image': 'https://share.redd.it/preview/post/1b67xnz', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/1b67xnz'}]}}, {'kind': 'customsearch#result', 'title': 'Any Data Engineering Podcasts? : r/dataengineering', 'htmlTitle': 'Any <b>Data Engineering</b> Podcasts? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/13lppxu/any_data_engineering_podcasts/', 'displayLink': 'www.reddit.com', 'snippet': 'May 19, 2023 ... 95 votes, 18 comments. Want to ask if there are any data engineering podcasts to listen while working :) I am willing to listen more\xa0...', 'htmlSnippet': 'May 19, 2023 <b>...</b> 95 votes, 18 comments. Want to ask if there are any <b>data engineering</b> podcasts to listen while working :) I am willing to listen more&nbsp;...', 'cacheId': 'F3VisjP1jqEJ', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../any_data_engineering_podcast...', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../any_<b>data</b>_<b>engineering</b>_podcast...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/13lppxu', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Any Data Engineering Podcasts?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Any Data Engineering Podcasts?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/paolapardo - 95 votes and 18 comments', 'twitter:image': 'https://share.redd.it/preview/post/13lppxu', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/13lppxu/any_data_engineering_podcasts/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/13lppxu'}]}}, {'kind': 'customsearch#result', 'title': 'Rust in Data Engineering? : r/dataengineering', 'htmlTitle': 'Rust in <b>Data Engineering</b>? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/16dgor2/rust_in_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': 'Sep 8, 2023 ... Rust has a steep getting started curve as you can tell, but it is the most efficient distributed programming paradigm by far with a pedantic\xa0...', 'htmlSnippet': 'Sep 8, 2023 <b>...</b> Rust has a steep getting started curve as you can tell, but it is the most efficient distributed programming paradigm by far with a pedantic&nbsp;...', 'cacheId': 'o8rzSMBF7IsJ', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../rust_in_data_engineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../rust_in_<b>data</b>_<b>engineering</b>/', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/16dgor2', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Rust in Data Engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Rust in Data Engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/hsimpsondata - 23 votes and 32 comments', 'twitter:image': 'https://share.redd.it/preview/post/16dgor2', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/16dgor2/rust_in_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/16dgor2'}]}}, {'kind': 'customsearch#result', 'title': 'Data engineering blogs worth reading : r/dataengineering', 'htmlTitle': '<b>Data engineering</b> blogs worth reading : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/u99v1q/data_engineering_blogs_worth_reading/', 'displayLink': 'www.reddit.com', 'snippet': 'Apr 22, 2022 ... Data engineering blogs worth reading · Data Engineering on Medium and Towards Data Science · Benn, Sarah, Mikkel, Tristan on dbt blog · Cool\xa0...', 'htmlSnippet': 'Apr 22, 2022 <b>...</b> <b>Data engineering</b> blogs worth reading &middot; <b>Data Engineering</b> on Medium and Towards <b>Data Science</b> &middot; Benn, Sarah, Mikkel, Tristan on dbt blog &middot; Cool&nbsp;...', 'cacheId': 'hkHfkPdOgL8J', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../data_engineering_blogs_wort...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../<b>data</b>_<b>engineering</b>_blogs_wort...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/u99v1q', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Data engineering blogs worth reading', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Data engineering blogs worth reading', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Anna-Kraska - 133 votes and 20 comments', 'twitter:image': 'https://share.redd.it/preview/post/u99v1q', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/u99v1q/data_engineering_blogs_worth_reading/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/u99v1q'}]}}, {'kind': 'customsearch#result', 'title': "Any feedback on Zach Wilson's Data Engineering bootcamp? : r ...", 'htmlTitle': 'Any feedback on Zach Wilson&#39;s <b>Data Engineering</b> bootcamp? : r ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/14ieh8u/any_feedback_on_zach_wilsons_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': 'Jun 25, 2023 ... Each class was roughly half lecture, half lab/applied learning, and I would say I learned a lot of applicable concepts and techniques in each\xa0...', 'htmlSnippet': 'Jun 25, 2023 <b>...</b> Each class was roughly half lecture, half lab/applied learning, and I would say I learned a lot of applicable concepts and techniques in each&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../any_feedback_on_zach_wils...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../any_feedback_on_zach_wils...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/14ieh8u', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Any feedback on Zach Wilson’s Data Engineering bootcamp?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Any feedback on Zach Wilson’s Data Engineering bootcamp?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/techblogp - 39 votes and 114 comments', 'twitter:image': 'https://share.redd.it/preview/post/14ieh8u', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/14ieh8u/any_feedback_on_zach_wilsons_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/14ieh8u'}]}}, {'kind': 'customsearch#result', 'title': 'Scala or Python for Data engineering? : r/dataengineering', 'htmlTitle': 'Scala or Python for <b>Data engineering</b>? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': "Oct 31, 2022 ... I've watched multiple data engineers switch to scala over time due to performance gains. As they got deeper into development they found scala to\xa0...", 'htmlSnippet': 'Oct 31, 2022 <b>...</b> I&#39;ve watched multiple <b>data engineers</b> switch to scala over time due to performance gains. As they got deeper into development they found scala to&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../scala_or_python_for_data_en...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../scala_or_python_for_<b>data</b>_<b>en</b>...', 'pagemap': {'cse_thumbnail': [{'src': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQPe6wVSU03P_xl2S8EUeJw2RDir-arhdX20ADvXRHwf-DbpMgcPHQKJWU&s', 'width': '311', 'height': '162'}], 'metatags': [{'og:image': 'https://share.redd.it/preview/post/yieto6', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Scala or Python for Data engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Scala or Python for Data engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/forneptune - 56 votes and 34 comments', 'twitter:image': 'https://share.redd.it/preview/post/yieto6', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/'}], 'cse_image': [{'src': 'https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?auto=webp&s=28b9ae149e0b4d698c919c86cb9694173c82dafd'}]}}, {'kind': 'customsearch#result', 'title': 'Why are there no entry-level data engineering jobs? : r ...', 'htmlTitle': 'Why are there no entry-level <b>data engineering</b> jobs? : r ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/qv43ad/why_are_there_no_entrylevel_data_engineering_jobs/', 'displayLink': 'www.reddit.com', 'snippet': 'Nov 16, 2021 ... There are probably not many entry-level data engineer positions because of how cross-disciplinary it is. You need to know coding, SQL, DBA,\xa0...', 'htmlSnippet': 'Nov 16, 2021 <b>...</b> There are probably not many entry-level <b>data engineer</b> positions because of how cross-disciplinary it is. You need to know coding, SQL, DBA,&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../why_are_there_no_entrylevel...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../why_are_there_no_entrylevel...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/qv43ad', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Why are there no entry-level data engineering jobs?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Why are there no entry-level data engineering jobs?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Born-Comment3359 - 64 votes and 45 comments', 'twitter:image': 'https://share.redd.it/preview/post/qv43ad', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/qv43ad/why_are_there_no_entrylevel_data_engineering_jobs/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/qv43ad'}]}}]}
[2024-04-30T20:47:51.726+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:47:51.757+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:47:51.757+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:47:51.787+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:47:51.787+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:47:51.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.682 seconds
[2024-04-30T20:48:22.372+0000] {processor.py:161} INFO - Started process (PID=127) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:48:22.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:48:22.374+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:48:22.374+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:48:23.338+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:48:23.332+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 58, in <module>
    search_reddit_subreddit("data engineering","reddit.com/r/dataengineering","AIzaSyABGdVM83A28q2Xecz2e6sKuBDjINnpgSg","7028cb91469b0412d")
  File "/opt/airflow/etls/customSearchEtl.py", line 31, in search_reddit_subreddit
    data = json.loads(data)
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not dict
[2024-04-30T20:48:23.340+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:48:23.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.003 seconds
[2024-04-30T20:48:53.856+0000] {processor.py:161} INFO - Started process (PID=129) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:48:53.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:48:53.859+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:48:53.858+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:48:54.759+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:48:54.753+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 58, in <module>
    search_reddit_subreddit("data engineering","reddit.com/r/dataengineering","AIzaSyABGdVM83A28q2Xecz2e6sKuBDjINnpgSg
  File "/opt/airflow/etls/customSearchEtl.py", line 31, in search_reddit_subreddit
    data = json.loads(response.content.decode("utf"))
  File "/usr/local/lib/python3.9/json/__init__.py", line 339, in loads
    raise TypeError(f'the JSON object must be str, bytes or bytearray, '
TypeError: the JSON object must be str, bytes or bytearray, not Response
[2024-04-30T20:48:54.762+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:48:54.797+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.955 seconds
[2024-04-30T20:49:25.480+0000] {processor.py:161} INFO - Started process (PID=131) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:49:25.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:49:25.482+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:49:25.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:49:26.627+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:49:26.732+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:49:26.731+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:49:26.744+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:49:26.744+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:49:26.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.281 seconds
[2024-04-30T20:49:57.121+0000] {processor.py:161} INFO - Started process (PID=137) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:49:57.140+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:49:57.145+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:49:57.143+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:49:58.734+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:49:58.754+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:49:58.754+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:49:58.775+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:49:58.774+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:49:58.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.782 seconds
[2024-04-30T20:50:29.494+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:50:29.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:50:29.510+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:50:29.505+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:50:31.721+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:50:31.760+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:50:31.759+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:50:31.774+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:50:31.774+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:50:31.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 2.357 seconds
[2024-04-30T20:50:59.298+0000] {processor.py:161} INFO - Started process (PID=29) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:50:59.301+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:50:59.308+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:50:59.307+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:51:00.415+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:51:00.488+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:51:00.486+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:51:00.526+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:51:00.526+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:51:00.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.265 seconds
[2024-04-30T20:51:30.867+0000] {processor.py:161} INFO - Started process (PID=35) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:51:30.869+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:51:30.874+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:51:30.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:51:31.648+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:51:31.656+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:51:31.655+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:51:31.675+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:51:31.675+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:51:31.684+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.839 seconds
[2024-04-30T20:52:02.803+0000] {processor.py:161} INFO - Started process (PID=37) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:52:02.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:52:02.839+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:52:02.831+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:52:05.344+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:52:05.335+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 58, in <module>
    search_reddit_subreddit("data engineering","reddit.com/r/dataengineering","AIzaSyABGdVM83A28q2Xecz2e6sKuBDjINnpgSg","7028cb91469b0412d")
  File "/opt/airflow/etls/customSearchEtl.py", line 32, in search_reddit_subreddit
    print(data['searchTerms'])
KeyError: 'searchTerms'
[2024-04-30T20:52:05.348+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:52:05.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 2.743 seconds
[2024-04-30T20:52:35.934+0000] {processor.py:161} INFO - Started process (PID=39) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:52:35.935+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:52:35.940+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:52:35.939+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:52:36.892+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:52:36.884+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 58, in <module>
    search_reddit_subreddit("data engineering","reddit.com/r/dataengineering","AIzaSyABGdVM83A28q2Xecz2e6sKuBDjINnpgSg","7028cb91469b0412d")
  File "/opt/airflow/etls/customSearchEtl.py", line 32, in search_reddit_subreddit
    print(data['searchTerms'])
KeyError: 'searchTerms'
[2024-04-30T20:52:36.896+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:52:36.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.018 seconds
[2024-04-30T20:53:07.424+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:53:07.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:53:07.426+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:53:07.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:53:08.304+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:53:08.300+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 58, in <module>
    search_reddit_subreddit("data engineering","reddit.com/r/dataengineering","AIzaSyABGdVM83A28q2Xecz2e6sKuBDjINnpgSg","7028cb91469b0412d")
  File "/opt/airflow/etls/customSearchEtl.py", line 32, in search_reddit_subreddit
    print(data['searchTerms'])
KeyError: 'searchTerms'
[2024-04-30T20:53:08.306+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:53:08.346+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.940 seconds
[2024-04-30T20:53:38.955+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:53:38.958+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:53:38.960+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:53:38.959+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:53:39.853+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:53:39.848+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 58, in <module>
  File "/opt/airflow/etls/customSearchEtl.py", line 32, in search_reddit_subreddit
    keys_list = list(data.keys())
KeyError: 'searchTerms'
[2024-04-30T20:53:39.857+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:53:39.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.960 seconds
[2024-04-30T20:54:10.560+0000] {processor.py:161} INFO - Started process (PID=45) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:54:10.563+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:54:10.566+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:54:10.564+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:54:11.478+0000] {logging_mixin.py:188} INFO - ['kind', 'url', 'queries', 'context', 'searchInformation', 'items']
[2024-04-30T20:54:11.625+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:54:11.824+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:54:11.823+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:54:11.838+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:54:11.838+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:54:11.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.305 seconds
[2024-04-30T20:54:42.219+0000] {processor.py:161} INFO - Started process (PID=47) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:54:42.221+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:54:42.222+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:54:42.222+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:54:43.029+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T20:54:43.031+0000] {logging_mixin.py:188} INFO - {'request': [{'title': 'Google Custom Search - data engineering', 'totalResults': '28200', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 1, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}], 'nextPage': [{'title': 'Google Custom Search - data engineering', 'totalResults': '28200', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 11, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}]}
[2024-04-30T20:54:43.033+0000] {logging_mixin.py:188} INFO - [{'kind': 'customsearch#result', 'title': 'Data Engineering', 'htmlTitle': '<b>Data Engineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/', 'displayLink': 'www.reddit.com', 'snippet': 'r/dataengineering: News & discussion on Data Engineering topics, including but not limited to: data pipelines, databases, data formats, storage, data…', 'htmlSnippet': 'r/<b>dataengineering</b>: News &amp; discussion on <b>Data Engineering</b> topics, including but not limited to: data pipelines, databases, data formats, storage, data…', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/', 'pagemap': {'cse_thumbnail': [{'src': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQk9OkztNOzwb73X1pn3x2keu6xnV-1ekZMpK8R245Gd47DbA7Joj7mMmk&s', 'width': '225', 'height': '225'}], 'metatags': [{'og:image': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png', 'theme-color': '#000000', 'og:image:width': '256', 'og:type': 'website', 'twitter:card': 'summary', 'twitter:title': 'r/dataengineering', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering', 'og:image:height': '256', 'bingbot': 'noarchive', 'msapplication-navbutton-color': '#000000', 'og:description': 'News & discussion on Data Engineering topics, including but not limited to: data pipelines, databases, data formats, storage, data modeling, data governance, cleansing, NoSQL, distributed systems, streaming, batch, Big Data, and workflow engines.', 'twitter:image': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/'}], 'cse_image': [{'src': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png'}]}}, {'kind': 'customsearch#result', 'title': 'Does data engineering not have as much interesting career ...', 'htmlTitle': 'Does <b>data engineering</b> not have as much interesting career ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/12qldg7/does_data_engineering_not_have_as_much/', 'displayLink': 'www.reddit.com', 'snippet': 'Apr 18, 2023 ... Because data eng is already diverse within itself. You can pick up and practice skills in devops, backend development, ML, BI, systems and\xa0...', 'htmlSnippet': 'Apr 18, 2023 <b>...</b> Because <b>data</b> eng is already diverse within itself. You can pick up and practice skills in devops, backend development, ML, BI, systems and&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../does_data_engineering_not_...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../does_<b>data</b>_<b>engineering</b>_not_...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/12qldg7', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Does data engineering not have as much interesting career progression as other areas of engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Does data engineering not have as much interesting career progression as other areas of engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/level_126_programmer - 108 votes and 55 comments', 'twitter:image': 'https://share.redd.it/preview/post/12qldg7', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/12qldg7/does_data_engineering_not_have_as_much/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/12qldg7'}]}}, {'kind': 'customsearch#result', 'title': 'What do you guys think of "Fundamentals of Data Engineering" book ...', 'htmlTitle': 'What do you guys think of &quot;Fundamentals of <b>Data Engineering</b>&quot; book ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/18ydlv0/what_do_you_guys_think_of_fundamentals_of_data/', 'displayLink': 'www.reddit.com', 'snippet': 'Jan 4, 2024 ... IMHO Fundamentals of DE is really good and very useful overview of the field suitable for interview prep as well as for adding breadth to your\xa0...', 'htmlSnippet': 'Jan 4, 2024 <b>...</b> IMHO Fundamentals of DE is really good and very useful overview of the field suitable for interview prep as well as for adding breadth to your&nbsp;...', 'cacheId': 'PqZ2CQqqH7oJ', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../what_do_you_guys_think_of...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../what_do_you_guys_think_of...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/18ydlv0', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: What do you guys think of "Fundamentals of Data Engineering" book?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: What do you guys think of "Fundamentals of Data Engineering" book?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/thethewaza - 47 votes and 23 comments', 'twitter:image': 'https://share.redd.it/preview/post/18ydlv0', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/18ydlv0/what_do_you_guys_think_of_fundamentals_of_data/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/18ydlv0'}]}}, {'kind': 'customsearch#result', 'title': 'Giving up data engineering : r/dataengineering', 'htmlTitle': 'Giving up <b>data engineering</b> : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': "Mar 4, 2024 ... Giving up data engineering · The no1 question is do you enjoy what you do? Life is not about money it's about happiness. · All jobs have burnout\xa0...", 'htmlSnippet': 'Mar 4, 2024 <b>...</b> Giving up <b>data engineering</b> &middot; The no1 question is do you enjoy what you do? Life is not about money it&#39;s about happiness. &middot; All jobs have burnout&nbsp;...', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../giving_up_data_engineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../giving_up_<b>data</b>_<b>engineering</b>/', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/1b67xnz', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Giving up data engineering', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Giving up data engineering', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Two_5536 - 173 votes and 82 comments', 'twitter:image': 'https://share.redd.it/preview/post/1b67xnz', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/1b67xnz'}]}}, {'kind': 'customsearch#result', 'title': 'Any Data Engineering Podcasts? : r/dataengineering', 'htmlTitle': 'Any <b>Data Engineering</b> Podcasts? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/13lppxu/any_data_engineering_podcasts/', 'displayLink': 'www.reddit.com', 'snippet': 'May 19, 2023 ... 95 votes, 18 comments. Want to ask if there are any data engineering podcasts to listen while working :) I am willing to listen more\xa0...', 'htmlSnippet': 'May 19, 2023 <b>...</b> 95 votes, 18 comments. Want to ask if there are any <b>data engineering</b> podcasts to listen while working :) I am willing to listen more&nbsp;...', 'cacheId': 'F3VisjP1jqEJ', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../any_data_engineering_podcast...', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../any_<b>data</b>_<b>engineering</b>_podcast...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/13lppxu', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Any Data Engineering Podcasts?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Any Data Engineering Podcasts?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/paolapardo - 95 votes and 18 comments', 'twitter:image': 'https://share.redd.it/preview/post/13lppxu', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/13lppxu/any_data_engineering_podcasts/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/13lppxu'}]}}, {'kind': 'customsearch#result', 'title': 'Rust in Data Engineering? : r/dataengineering', 'htmlTitle': 'Rust in <b>Data Engineering</b>? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/16dgor2/rust_in_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': 'Sep 8, 2023 ... Rust has a steep getting started curve as you can tell, but it is the most efficient distributed programming paradigm by far with a pedantic\xa0...', 'htmlSnippet': 'Sep 8, 2023 <b>...</b> Rust has a steep getting started curve as you can tell, but it is the most efficient distributed programming paradigm by far with a pedantic&nbsp;...', 'cacheId': 'o8rzSMBF7IsJ', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../rust_in_data_engineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../rust_in_<b>data</b>_<b>engineering</b>/', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/16dgor2', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Rust in Data Engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Rust in Data Engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/hsimpsondata - 23 votes and 32 comments', 'twitter:image': 'https://share.redd.it/preview/post/16dgor2', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/16dgor2/rust_in_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/16dgor2'}]}}, {'kind': 'customsearch#result', 'title': 'Data engineering blogs worth reading : r/dataengineering', 'htmlTitle': '<b>Data engineering</b> blogs worth reading : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/u99v1q/data_engineering_blogs_worth_reading/', 'displayLink': 'www.reddit.com', 'snippet': 'Apr 22, 2022 ... Data engineering blogs worth reading · Data Engineering on Medium and Towards Data Science · Benn, Sarah, Mikkel, Tristan on dbt blog · Cool\xa0...', 'htmlSnippet': 'Apr 22, 2022 <b>...</b> <b>Data engineering</b> blogs worth reading &middot; <b>Data Engineering</b> on Medium and Towards <b>Data Science</b> &middot; Benn, Sarah, Mikkel, Tristan on dbt blog &middot; Cool&nbsp;...', 'cacheId': 'hkHfkPdOgL8J', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../data_engineering_blogs_wort...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../<b>data</b>_<b>engineering</b>_blogs_wort...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/u99v1q', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Data engineering blogs worth reading', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Data engineering blogs worth reading', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Anna-Kraska - 133 votes and 20 comments', 'twitter:image': 'https://share.redd.it/preview/post/u99v1q', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/u99v1q/data_engineering_blogs_worth_reading/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/u99v1q'}]}}, {'kind': 'customsearch#result', 'title': "Any feedback on Zach Wilson's Data Engineering bootcamp? : r ...", 'htmlTitle': 'Any feedback on Zach Wilson&#39;s <b>Data Engineering</b> bootcamp? : r ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/14ieh8u/any_feedback_on_zach_wilsons_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': 'Jun 25, 2023 ... Each class was roughly half lecture, half lab/applied learning, and I would say I learned a lot of applicable concepts and techniques in each\xa0...', 'htmlSnippet': 'Jun 25, 2023 <b>...</b> Each class was roughly half lecture, half lab/applied learning, and I would say I learned a lot of applicable concepts and techniques in each&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../any_feedback_on_zach_wils...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../any_feedback_on_zach_wils...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/14ieh8u', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Any feedback on Zach Wilson’s Data Engineering bootcamp?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Any feedback on Zach Wilson’s Data Engineering bootcamp?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/techblogp - 39 votes and 114 comments', 'twitter:image': 'https://share.redd.it/preview/post/14ieh8u', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/14ieh8u/any_feedback_on_zach_wilsons_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/14ieh8u'}]}}, {'kind': 'customsearch#result', 'title': 'Scala or Python for Data engineering? : r/dataengineering', 'htmlTitle': 'Scala or Python for <b>Data engineering</b>? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': "Oct 31, 2022 ... I've watched multiple data engineers switch to scala over time due to performance gains. As they got deeper into development they found scala to\xa0...", 'htmlSnippet': 'Oct 31, 2022 <b>...</b> I&#39;ve watched multiple <b>data engineers</b> switch to scala over time due to performance gains. As they got deeper into development they found scala to&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../scala_or_python_for_data_en...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../scala_or_python_for_<b>data</b>_<b>en</b>...', 'pagemap': {'cse_thumbnail': [{'src': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQPe6wVSU03P_xl2S8EUeJw2RDir-arhdX20ADvXRHwf-DbpMgcPHQKJWU&s', 'width': '311', 'height': '162'}], 'metatags': [{'og:image': 'https://share.redd.it/preview/post/yieto6', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Scala or Python for Data engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Scala or Python for Data engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/forneptune - 56 votes and 34 comments', 'twitter:image': 'https://share.redd.it/preview/post/yieto6', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/'}], 'cse_image': [{'src': 'https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?auto=webp&s=28b9ae149e0b4d698c919c86cb9694173c82dafd'}]}}, {'kind': 'customsearch#result', 'title': 'Why are there no entry-level data engineering jobs? : r ...', 'htmlTitle': 'Why are there no entry-level <b>data engineering</b> jobs? : r ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/qv43ad/why_are_there_no_entrylevel_data_engineering_jobs/', 'displayLink': 'www.reddit.com', 'snippet': 'Nov 16, 2021 ... There are probably not many entry-level data engineer positions because of how cross-disciplinary it is. You need to know coding, SQL, DBA,\xa0...', 'htmlSnippet': 'Nov 16, 2021 <b>...</b> There are probably not many entry-level <b>data engineer</b> positions because of how cross-disciplinary it is. You need to know coding, SQL, DBA,&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../why_are_there_no_entrylevel...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../why_are_there_no_entrylevel...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/qv43ad', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Why are there no entry-level data engineering jobs?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Why are there no entry-level data engineering jobs?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Born-Comment3359 - 64 votes and 45 comments', 'twitter:image': 'https://share.redd.it/preview/post/qv43ad', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/qv43ad/why_are_there_no_entrylevel_data_engineering_jobs/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/qv43ad'}]}}]
[2024-04-30T20:54:43.120+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:54:43.134+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:54:43.133+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:54:43.144+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:54:43.144+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:54:43.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.947 seconds
[2024-04-30T20:55:13.617+0000] {processor.py:161} INFO - Started process (PID=49) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:55:13.619+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:55:13.620+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:55:13.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:55:14.670+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T20:55:14.672+0000] {logging_mixin.py:188} INFO - {'request': [{'title': 'Google Custom Search - data engineering', 'totalResults': '30500', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 1, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}], 'nextPage': [{'title': 'Google Custom Search - data engineering', 'totalResults': '30500', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 11, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}]}
[2024-04-30T20:55:14.673+0000] {logging_mixin.py:188} INFO - [{'kind': 'customsearch#result', 'title': 'Data Engineering', 'htmlTitle': '<b>Data Engineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/', 'displayLink': 'www.reddit.com', 'snippet': 'r/dataengineering: News & discussion on Data Engineering topics, including but not limited to: data pipelines, databases, data formats, storage, data…', 'htmlSnippet': 'r/<b>dataengineering</b>: News &amp; discussion on <b>Data Engineering</b> topics, including but not limited to: data pipelines, databases, data formats, storage, data…', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/', 'pagemap': {'cse_thumbnail': [{'src': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQk9OkztNOzwb73X1pn3x2keu6xnV-1ekZMpK8R245Gd47DbA7Joj7mMmk&s', 'width': '225', 'height': '225'}], 'metatags': [{'og:image': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png', 'theme-color': '#000000', 'og:image:width': '256', 'og:type': 'website', 'twitter:card': 'summary', 'twitter:title': 'r/dataengineering', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering', 'og:image:height': '256', 'bingbot': 'noarchive', 'msapplication-navbutton-color': '#000000', 'og:description': 'News & discussion on Data Engineering topics, including but not limited to: data pipelines, databases, data formats, storage, data modeling, data governance, cleansing, NoSQL, distributed systems, streaming, batch, Big Data, and workflow engines.', 'twitter:image': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/'}], 'cse_image': [{'src': 'https://styles.redditmedia.com/t5_36en4/styles/communityIcon_t74nv7kttaz61.png'}]}}, {'kind': 'customsearch#result', 'title': 'Does data engineering not have as much interesting career ...', 'htmlTitle': 'Does <b>data engineering</b> not have as much interesting career ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/12qldg7/does_data_engineering_not_have_as_much/', 'displayLink': 'www.reddit.com', 'snippet': 'Apr 18, 2023 ... Because data eng is already diverse within itself. You can pick up and practice skills in devops, backend development, ML, BI, systems and\xa0...', 'htmlSnippet': 'Apr 18, 2023 <b>...</b> Because <b>data</b> eng is already diverse within itself. You can pick up and practice skills in devops, backend development, ML, BI, systems and&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../does_data_engineering_not_...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../does_<b>data</b>_<b>engineering</b>_not_...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/12qldg7', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Does data engineering not have as much interesting career progression as other areas of engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Does data engineering not have as much interesting career progression as other areas of engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/level_126_programmer - 108 votes and 55 comments', 'twitter:image': 'https://share.redd.it/preview/post/12qldg7', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/12qldg7/does_data_engineering_not_have_as_much/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/12qldg7'}]}}, {'kind': 'customsearch#result', 'title': 'What do you guys think of "Fundamentals of Data Engineering" book ...', 'htmlTitle': 'What do you guys think of &quot;Fundamentals of <b>Data Engineering</b>&quot; book ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/18ydlv0/what_do_you_guys_think_of_fundamentals_of_data/', 'displayLink': 'www.reddit.com', 'snippet': 'Jan 4, 2024 ... IMHO Fundamentals of DE is really good and very useful overview of the field suitable for interview prep as well as for adding breadth to your\xa0...', 'htmlSnippet': 'Jan 4, 2024 <b>...</b> IMHO Fundamentals of DE is really good and very useful overview of the field suitable for interview prep as well as for adding breadth to your&nbsp;...', 'cacheId': 'PqZ2CQqqH7oJ', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../what_do_you_guys_think_of...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../what_do_you_guys_think_of...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/18ydlv0', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: What do you guys think of "Fundamentals of Data Engineering" book?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: What do you guys think of "Fundamentals of Data Engineering" book?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/thethewaza - 47 votes and 23 comments', 'twitter:image': 'https://share.redd.it/preview/post/18ydlv0', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/18ydlv0/what_do_you_guys_think_of_fundamentals_of_data/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/18ydlv0'}]}}, {'kind': 'customsearch#result', 'title': 'Giving up data engineering : r/dataengineering', 'htmlTitle': 'Giving up <b>data engineering</b> : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': "Mar 4, 2024 ... Giving up data engineering · The no1 question is do you enjoy what you do? Life is not about money it's about happiness. · All jobs have burnout\xa0...", 'htmlSnippet': 'Mar 4, 2024 <b>...</b> Giving up <b>data engineering</b> &middot; The no1 question is do you enjoy what you do? Life is not about money it&#39;s about happiness. &middot; All jobs have burnout&nbsp;...', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../giving_up_data_engineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../giving_up_<b>data</b>_<b>engineering</b>/', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/1b67xnz', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Giving up data engineering', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Giving up data engineering', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Two_5536 - 173 votes and 82 comments', 'twitter:image': 'https://share.redd.it/preview/post/1b67xnz', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/1b67xnz/giving_up_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/1b67xnz'}]}}, {'kind': 'customsearch#result', 'title': 'Any Data Engineering Podcasts? : r/dataengineering', 'htmlTitle': 'Any <b>Data Engineering</b> Podcasts? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/13lppxu/any_data_engineering_podcasts/', 'displayLink': 'www.reddit.com', 'snippet': 'May 19, 2023 ... 95 votes, 18 comments. Want to ask if there are any data engineering podcasts to listen while working :) I am willing to listen more\xa0...', 'htmlSnippet': 'May 19, 2023 <b>...</b> 95 votes, 18 comments. Want to ask if there are any <b>data engineering</b> podcasts to listen while working :) I am willing to listen more&nbsp;...', 'cacheId': 'F3VisjP1jqEJ', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../any_data_engineering_podcast...', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../any_<b>data</b>_<b>engineering</b>_podcast...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/13lppxu', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Any Data Engineering Podcasts?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Any Data Engineering Podcasts?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/paolapardo - 95 votes and 18 comments', 'twitter:image': 'https://share.redd.it/preview/post/13lppxu', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/13lppxu/any_data_engineering_podcasts/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/13lppxu'}]}}, {'kind': 'customsearch#result', 'title': 'Rust in Data Engineering? : r/dataengineering', 'htmlTitle': 'Rust in <b>Data Engineering</b>? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/16dgor2/rust_in_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': 'Sep 8, 2023 ... Rust has a steep getting started curve as you can tell, but it is the most efficient distributed programming paradigm by far with a pedantic\xa0...', 'htmlSnippet': 'Sep 8, 2023 <b>...</b> Rust has a steep getting started curve as you can tell, but it is the most efficient distributed programming paradigm by far with a pedantic&nbsp;...', 'cacheId': 'o8rzSMBF7IsJ', 'formattedUrl': 'https://www.reddit.com/r/dataengineering/.../rust_in_data_engineering/', 'htmlFormattedUrl': 'https://www.reddit.com/r/<b>dataengineering</b>/.../rust_in_<b>data</b>_<b>engineering</b>/', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/16dgor2', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Rust in Data Engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Rust in Data Engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/hsimpsondata - 23 votes and 32 comments', 'twitter:image': 'https://share.redd.it/preview/post/16dgor2', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/16dgor2/rust_in_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/16dgor2'}]}}, {'kind': 'customsearch#result', 'title': 'Data engineering blogs worth reading : r/dataengineering', 'htmlTitle': '<b>Data engineering</b> blogs worth reading : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/u99v1q/data_engineering_blogs_worth_reading/', 'displayLink': 'www.reddit.com', 'snippet': 'Apr 22, 2022 ... Data engineering blogs worth reading · Data Engineering on Medium and Towards Data Science · Benn, Sarah, Mikkel, Tristan on dbt blog · Cool\xa0...', 'htmlSnippet': 'Apr 22, 2022 <b>...</b> <b>Data engineering</b> blogs worth reading &middot; <b>Data Engineering</b> on Medium and Towards <b>Data Science</b> &middot; Benn, Sarah, Mikkel, Tristan on dbt blog &middot; Cool&nbsp;...', 'cacheId': 'hkHfkPdOgL8J', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../data_engineering_blogs_wort...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../<b>data</b>_<b>engineering</b>_blogs_wort...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/u99v1q', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Data engineering blogs worth reading', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Data engineering blogs worth reading', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Anna-Kraska - 133 votes and 20 comments', 'twitter:image': 'https://share.redd.it/preview/post/u99v1q', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/u99v1q/data_engineering_blogs_worth_reading/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/u99v1q'}]}}, {'kind': 'customsearch#result', 'title': "Any feedback on Zach Wilson's Data Engineering bootcamp? : r ...", 'htmlTitle': 'Any feedback on Zach Wilson&#39;s <b>Data Engineering</b> bootcamp? : r ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/14ieh8u/any_feedback_on_zach_wilsons_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': 'Jun 25, 2023 ... Each class was roughly half lecture, half lab/applied learning, and I would say I learned a lot of applicable concepts and techniques in each\xa0...', 'htmlSnippet': 'Jun 25, 2023 <b>...</b> Each class was roughly half lecture, half lab/applied learning, and I would say I learned a lot of applicable concepts and techniques in each&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../any_feedback_on_zach_wils...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../any_feedback_on_zach_wils...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/14ieh8u', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Any feedback on Zach Wilson’s Data Engineering bootcamp?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Any feedback on Zach Wilson’s Data Engineering bootcamp?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/techblogp - 39 votes and 114 comments', 'twitter:image': 'https://share.redd.it/preview/post/14ieh8u', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/14ieh8u/any_feedback_on_zach_wilsons_data_engineering/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/14ieh8u'}]}}, {'kind': 'customsearch#result', 'title': 'Scala or Python for Data engineering? : r/dataengineering', 'htmlTitle': 'Scala or Python for <b>Data engineering</b>? : r/<b>dataengineering</b>', 'link': 'https://www.reddit.com/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/', 'displayLink': 'www.reddit.com', 'snippet': "Oct 31, 2022 ... I've watched multiple data engineers switch to scala over time due to performance gains. As they got deeper into development they found scala to\xa0...", 'htmlSnippet': 'Oct 31, 2022 <b>...</b> I&#39;ve watched multiple <b>data engineers</b> switch to scala over time due to performance gains. As they got deeper into development they found scala to&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../scala_or_python_for_data_en...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../scala_or_python_for_<b>data</b>_<b>en</b>...', 'pagemap': {'cse_thumbnail': [{'src': 'https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQPe6wVSU03P_xl2S8EUeJw2RDir-arhdX20ADvXRHwf-DbpMgcPHQKJWU&s', 'width': '311', 'height': '162'}], 'metatags': [{'og:image': 'https://share.redd.it/preview/post/yieto6', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Scala or Python for Data engineering?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Scala or Python for Data engineering?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/forneptune - 56 votes and 34 comments', 'twitter:image': 'https://share.redd.it/preview/post/yieto6', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/yieto6/scala_or_python_for_data_engineering/'}], 'cse_image': [{'src': 'https://external-preview.redd.it/GJ7MpqsUo8YEPDKlUylWBTa_GWPu4xBncdzyhz_ieJg.jpg?auto=webp&s=28b9ae149e0b4d698c919c86cb9694173c82dafd'}]}}, {'kind': 'customsearch#result', 'title': 'Why are there no entry-level data engineering jobs? : r ...', 'htmlTitle': 'Why are there no entry-level <b>data engineering</b> jobs? : r ...', 'link': 'https://www.reddit.com/r/dataengineering/comments/qv43ad/why_are_there_no_entrylevel_data_engineering_jobs/', 'displayLink': 'www.reddit.com', 'snippet': 'Nov 16, 2021 ... There are probably not many entry-level data engineer positions because of how cross-disciplinary it is. You need to know coding, SQL, DBA,\xa0...', 'htmlSnippet': 'Nov 16, 2021 <b>...</b> There are probably not many entry-level <b>data engineer</b> positions because of how cross-disciplinary it is. You need to know coding, SQL, DBA,&nbsp;...', 'formattedUrl': 'https://www.reddit.com/.../dataengineering/.../why_are_there_no_entrylevel...', 'htmlFormattedUrl': 'https://www.reddit.com/.../<b>dataengineering</b>/.../why_are_there_no_entrylevel...', 'pagemap': {'metatags': [{'og:image': 'https://share.redd.it/preview/post/qv43ad', 'theme-color': '#000000', 'og:image:width': '1200', 'og:type': 'website', 'og:image:alt': 'An image containing a preview of the post', 'twitter:card': 'summary_large_image', 'twitter:title': 'r/dataengineering on Reddit: Why are there no entry-level data engineering jobs?', 'og:site_name': 'Reddit', 'og:title': 'r/dataengineering on Reddit: Why are there no entry-level data engineering jobs?', 'og:image:height': '630', 'msapplication-navbutton-color': '#000000', 'og:description': 'Posted by u/Born-Comment3359 - 64 votes and 45 comments', 'twitter:image': 'https://share.redd.it/preview/post/qv43ad', 'apple-mobile-web-app-status-bar-style': 'black', 'twitter:site': '@reddit', 'viewport': 'width=device-width, initial-scale=1, viewport-fit=cover', 'apple-mobile-web-app-capable': 'yes', 'og:ttl': '600', 'og:url': 'https://www.reddit.com/r/dataengineering/comments/qv43ad/why_are_there_no_entrylevel_data_engineering_jobs/'}], 'cse_image': [{'src': 'https://share.redd.it/preview/post/qv43ad'}]}}]
[2024-04-30T20:55:14.762+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:55:14.779+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:55:14.778+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:55:14.788+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:55:14.788+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:55:14.795+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.188 seconds
[2024-04-30T20:55:45.148+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:55:45.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:55:45.152+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:55:45.151+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:55:45.897+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T20:55:45.900+0000] {logging_mixin.py:188} INFO - {'request': [{'title': 'Google Custom Search - data engineering', 'totalResults': '28200', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 1, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}], 'nextPage': [{'title': 'Google Custom Search - data engineering', 'totalResults': '28200', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 11, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}]}
[2024-04-30T20:55:46.007+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:55:46.025+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:55:46.025+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:55:46.036+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:55:46.036+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:55:46.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.905 seconds
[2024-04-30T20:56:16.537+0000] {processor.py:161} INFO - Started process (PID=53) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:56:16.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:56:16.541+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:56:16.540+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:56:17.437+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T20:56:17.440+0000] {logging_mixin.py:188} INFO - {'request': [{'title': 'Google Custom Search - data engineering', 'totalResults': '30500', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 1, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}], 'nextPage': [{'title': 'Google Custom Search - data engineering', 'totalResults': '30500', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 11, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}]}
[2024-04-30T20:56:17.555+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:56:17.572+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:56:17.572+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:56:17.581+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:56:17.581+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:56:17.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.066 seconds
[2024-04-30T20:56:48.088+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:56:48.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:56:48.092+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:56:48.091+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:56:49.087+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T20:56:49.094+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:56:49.090+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/redditDag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/redditDag.py", line 12, in <module>
    from pipelines.googleSearchPipeline import custom_search_pipeline
  File "/opt/airflow/pipelines/googleSearchPipeline.py", line 4, in <module>
    from etls.customSearchEtl import search_reddit_subreddit, process_subreddit_search, load_data_to_csv
  File "/opt/airflow/etls/customSearchEtl.py", line 63, in <module>
    search_reddit_subreddit("data engineering","reddit.com/r/dataengineering","AIzaSyABGdVM83A28q2Xecz2e6sKuBDjINnpgSg","7028cb91469b0412d")
  File "/opt/airflow/etls/customSearchEtl.py", line 35, in search_reddit_subreddit
    print(data['queries']['request']['searchTerms'])
TypeError: list indices must be integers or slices, not str
[2024-04-30T20:56:49.096+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:56:49.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.065 seconds
[2024-04-30T20:57:19.621+0000] {processor.py:161} INFO - Started process (PID=57) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:57:19.624+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:57:19.625+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:57:19.625+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:57:20.419+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T20:57:20.419+0000] {logging_mixin.py:188} INFO - {'request': [{'title': 'Google Custom Search - data engineering', 'totalResults': '28200', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 1, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}], 'nextPage': [{'title': 'Google Custom Search - data engineering', 'totalResults': '28200', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 11, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}]}
[2024-04-30T20:57:20.513+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:57:20.528+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:57:20.528+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:57:20.538+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:57:20.538+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:57:20.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.938 seconds
[2024-04-30T20:57:50.983+0000] {processor.py:161} INFO - Started process (PID=59) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:57:50.985+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:57:50.986+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:57:50.986+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:57:51.663+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T20:57:51.665+0000] {logging_mixin.py:188} INFO - {'request': [{'title': 'Google Custom Search - data engineering', 'totalResults': '28200', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 1, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}], 'nextPage': [{'title': 'Google Custom Search - data engineering', 'totalResults': '28200', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 11, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}]}
[2024-04-30T20:57:51.750+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:57:51.765+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:57:51.765+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:57:51.775+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:57:51.775+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:57:51.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.812 seconds
[2024-04-30T20:58:22.469+0000] {processor.py:161} INFO - Started process (PID=61) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:58:22.472+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:58:22.473+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:58:22.473+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:58:23.403+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T20:58:23.405+0000] {logging_mixin.py:188} INFO - {'request': [{'title': 'Google Custom Search - data engineering', 'totalResults': '30500', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 1, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}], 'nextPage': [{'title': 'Google Custom Search - data engineering', 'totalResults': '30500', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 11, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}]}
[2024-04-30T20:58:23.479+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:58:23.501+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:58:23.500+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:58:23.511+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:58:23.511+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:58:23.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.060 seconds
[2024-04-30T20:58:54.124+0000] {processor.py:161} INFO - Started process (PID=63) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T20:58:54.128+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T20:58:54.130+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:58:54.129+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T20:58:55.047+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T20:58:55.049+0000] {logging_mixin.py:188} INFO - {'request': [{'title': 'Google Custom Search - data engineering', 'totalResults': '28200', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 1, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}], 'nextPage': [{'title': 'Google Custom Search - data engineering', 'totalResults': '28200', 'searchTerms': 'data engineering', 'count': 10, 'startIndex': 11, 'inputEncoding': 'utf8', 'outputEncoding': 'utf8', 'safe': 'off', 'cx': '7028cb91469b0412d', 'siteSearch': 'reddit.com/r/dataengineering'}]}
[2024-04-30T20:58:55.170+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T20:58:55.792+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:58:55.782+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T20:58:55.834+0000] {logging_mixin.py:188} INFO - [2024-04-30T20:58:55.833+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T20:58:55.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.754 seconds
[2024-04-30T22:19:03.686+0000] {processor.py:161} INFO - Started process (PID=65) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:19:03.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:19:03.689+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:19:03.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:19:04.680+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:19:04.719+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:19:04.718+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:19:04.731+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:19:04.731+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:19:04.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.064 seconds
[2024-04-30T22:19:35.207+0000] {processor.py:161} INFO - Started process (PID=67) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:19:35.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:19:35.210+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:19:35.210+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:19:36.356+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:19:36.383+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:19:36.382+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:19:36.403+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:19:36.403+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:19:36.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.222 seconds
[2024-04-30T22:20:06.787+0000] {processor.py:161} INFO - Started process (PID=69) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:20:06.789+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:20:06.790+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:20:06.790+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:20:07.851+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:20:07.877+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:20:07.877+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:20:07.888+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:20:07.888+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:20:07.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.119 seconds
[2024-04-30T22:24:21.418+0000] {processor.py:161} INFO - Started process (PID=71) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:24:21.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:24:21.422+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:24:21.421+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:24:22.536+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:24:22.555+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:24:22.555+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:24:22.566+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:24:22.566+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:24:22.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.175 seconds
[2024-04-30T22:24:53.044+0000] {processor.py:161} INFO - Started process (PID=77) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:24:53.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:24:53.048+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:24:53.048+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:24:53.588+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:24:53.617+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:24:53.617+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:24:53.637+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:24:53.637+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:24:53.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.624 seconds
[2024-04-30T22:25:24.192+0000] {processor.py:161} INFO - Started process (PID=79) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:25:24.196+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:25:24.197+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:25:24.196+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:25:24.685+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:25:24.717+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:25:24.717+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:25:24.753+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:25:24.753+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:25:24.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.594 seconds
[2024-04-30T22:25:55.225+0000] {processor.py:161} INFO - Started process (PID=81) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:25:55.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:25:55.232+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:25:55.230+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:25:56.397+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T22:25:56.516+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:25:56.563+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:25:56.562+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:25:56.601+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:25:56.601+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:25:56.619+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.430 seconds
[2024-04-30T22:26:27.045+0000] {processor.py:161} INFO - Started process (PID=83) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:26:27.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:26:27.048+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:26:27.048+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:26:27.964+0000] {logging_mixin.py:188} INFO - customsearch#search
[2024-04-30T22:26:28.057+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:26:28.078+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:26:28.078+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:26:28.103+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:26:28.103+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:26:28.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 1.098 seconds
[2024-04-30T22:26:58.696+0000] {processor.py:161} INFO - Started process (PID=85) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:26:58.699+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:26:58.701+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:26:58.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:26:59.153+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:26:59.176+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:26:59.175+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:26:59.188+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:26:59.188+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:26:59.196+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.524 seconds
[2024-04-30T22:27:29.774+0000] {processor.py:161} INFO - Started process (PID=91) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:27:29.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:27:29.781+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:27:29.779+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:27:30.547+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:27:30.567+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:27:30.567+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:27:30.578+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:27:30.578+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:27:30.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.860 seconds
[2024-04-30T22:28:01.025+0000] {processor.py:161} INFO - Started process (PID=93) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:28:01.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:28:01.028+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:28:01.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:28:01.567+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:28:01.592+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:28:01.592+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:28:01.607+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:28:01.607+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:28:01.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.612 seconds
[2024-04-30T22:28:32.104+0000] {processor.py:161} INFO - Started process (PID=95) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:28:32.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:28:32.112+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:28:32.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:28:32.769+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:28:32.806+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:28:32.805+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:28:32.824+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:28:32.823+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:28:32.833+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.759 seconds
[2024-04-30T22:29:03.359+0000] {processor.py:161} INFO - Started process (PID=97) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:29:03.370+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:29:03.372+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:29:03.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:29:03.863+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:29:03.923+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:29:03.923+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:29:03.944+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:29:03.943+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:29:03.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.619 seconds
[2024-04-30T22:29:34.362+0000] {processor.py:161} INFO - Started process (PID=99) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:29:34.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:29:34.373+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:29:34.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:29:34.936+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:29:34.959+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:29:34.958+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:29:34.971+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:29:34.971+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:29:34.980+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.642 seconds
[2024-04-30T22:30:05.444+0000] {processor.py:161} INFO - Started process (PID=101) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:30:05.446+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:30:05.447+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:30:05.447+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:30:05.886+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:30:05.904+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:30:05.904+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:30:05.913+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:30:05.913+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:30:05.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.508 seconds
[2024-04-30T22:30:36.371+0000] {processor.py:161} INFO - Started process (PID=103) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:30:36.374+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:30:36.375+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:30:36.375+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:30:36.814+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:30:36.843+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:30:36.843+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:30:36.856+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:30:36.856+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:30:36.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.510 seconds
[2024-04-30T22:31:07.332+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:31:07.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:31:07.335+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:31:07.335+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:31:07.809+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:31:07.827+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:31:07.827+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:31:07.836+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:31:07.836+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:31:07.843+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.526 seconds
[2024-04-30T22:31:38.308+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:31:38.311+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:31:38.312+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:31:38.312+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:31:38.984+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:31:39.006+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:31:39.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:31:39.017+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:31:39.017+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:31:39.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.750 seconds
[2024-04-30T22:32:09.147+0000] {processor.py:161} INFO - Started process (PID=109) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:32:09.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:32:09.160+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:32:09.159+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:32:09.585+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:32:09.601+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:32:09.600+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:32:09.610+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:32:09.609+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:32:09.617+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.484 seconds
[2024-04-30T22:32:39.829+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:32:39.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:32:39.833+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:32:39.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:32:40.359+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:32:40.381+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:32:40.380+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:32:40.391+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:32:40.391+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:32:40.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.593 seconds
[2024-04-30T22:33:10.796+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:33:10.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:33:10.809+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:33:10.807+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:33:11.347+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:33:11.368+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:33:11.368+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:33:11.380+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:33:11.380+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:33:11.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.607 seconds
[2024-04-30T22:33:41.784+0000] {processor.py:161} INFO - Started process (PID=115) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:33:41.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:33:41.788+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:33:41.788+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:33:42.221+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:33:42.237+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:33:42.237+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:33:42.246+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:33:42.246+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:33:42.253+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.486 seconds
[2024-04-30T22:34:12.657+0000] {processor.py:161} INFO - Started process (PID=117) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:34:12.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:34:12.660+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:34:12.660+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:34:13.090+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:34:13.106+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:34:13.105+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:34:13.115+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:34:13.115+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:34:13.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.483 seconds
[2024-04-30T22:34:43.609+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:34:43.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:34:43.612+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:34:43.612+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:34:44.033+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:34:44.049+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:34:44.049+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:34:44.058+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:34:44.058+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:34:44.071+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.476 seconds
[2024-04-30T22:35:14.460+0000] {processor.py:161} INFO - Started process (PID=121) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:35:14.463+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:35:14.465+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:35:14.464+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:35:14.911+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:35:14.942+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:35:14.941+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:35:14.954+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:35:14.954+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:35:14.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.521 seconds
[2024-04-30T22:35:45.271+0000] {processor.py:161} INFO - Started process (PID=123) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:35:45.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:35:45.275+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:35:45.274+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:35:45.761+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:35:45.776+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:35:45.776+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:35:45.786+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:35:45.786+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:35:45.793+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.532 seconds
[2024-04-30T22:36:16.179+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:36:16.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:36:16.184+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:36:16.183+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:36:16.632+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:36:16.649+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:36:16.649+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:36:16.669+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:36:16.669+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:36:16.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.535 seconds
[2024-04-30T22:36:47.014+0000] {processor.py:161} INFO - Started process (PID=127) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:36:47.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:36:47.017+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:36:47.016+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:36:47.429+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:36:47.445+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:36:47.445+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:36:47.454+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:36:47.454+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:36:47.461+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.480 seconds
[2024-04-30T22:37:17.895+0000] {processor.py:161} INFO - Started process (PID=129) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:37:17.896+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:37:17.897+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:37:17.897+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:37:18.314+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:37:18.331+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:37:18.331+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:37:18.354+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:37:18.354+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:37:18.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.482 seconds
[2024-04-30T22:37:48.903+0000] {processor.py:161} INFO - Started process (PID=131) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:37:48.907+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:37:48.908+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:37:48.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:37:49.318+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:37:49.336+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:37:49.336+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:37:49.346+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:37:49.346+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:37:49.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.481 seconds
[2024-04-30T22:38:19.773+0000] {processor.py:161} INFO - Started process (PID=133) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:38:19.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:38:19.779+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:38:19.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:38:20.211+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:38:20.256+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:38:20.256+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:38:20.267+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:38:20.267+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:38:20.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.525 seconds
[2024-04-30T22:38:50.723+0000] {processor.py:161} INFO - Started process (PID=135) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:38:50.726+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:38:50.728+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:38:50.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:38:51.157+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:38:51.174+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:38:51.174+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:38:51.184+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:38:51.184+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:38:51.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.486 seconds
[2024-04-30T22:39:21.636+0000] {processor.py:161} INFO - Started process (PID=137) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:39:21.639+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:39:21.641+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:39:21.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:39:22.059+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:39:22.089+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:39:22.089+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:39:22.099+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:39:22.099+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:39:22.106+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.487 seconds
[2024-04-30T22:39:52.667+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:39:52.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:39:52.669+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:39:52.669+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:39:53.060+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:39:53.078+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:39:53.078+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:39:53.087+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:39:53.087+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:39:53.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.438 seconds
[2024-04-30T22:40:23.586+0000] {processor.py:161} INFO - Started process (PID=141) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:40:23.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:40:23.591+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:40:23.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:40:24.018+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:40:24.037+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:40:24.037+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:40:24.047+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:40:24.047+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:40:24.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.495 seconds
[2024-04-30T22:40:54.530+0000] {processor.py:161} INFO - Started process (PID=143) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:40:54.531+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:40:54.532+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:40:54.532+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:40:54.975+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:40:54.992+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:40:54.992+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:40:55.001+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:40:55.001+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:40:55.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.494 seconds
[2024-04-30T22:41:25.396+0000] {processor.py:161} INFO - Started process (PID=145) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:41:25.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:41:25.401+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:41:25.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:41:25.840+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:41:25.858+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:41:25.857+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:41:25.867+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:41:25.867+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:41:25.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.495 seconds
[2024-04-30T22:41:56.258+0000] {processor.py:161} INFO - Started process (PID=147) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:41:56.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:41:56.266+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:41:56.264+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:41:56.700+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:41:56.723+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:41:56.723+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:41:56.740+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:41:56.740+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:41:56.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.502 seconds
[2024-04-30T22:42:27.246+0000] {processor.py:161} INFO - Started process (PID=149) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:42:27.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:42:27.249+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:42:27.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:42:27.654+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:42:27.673+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:42:27.673+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:42:27.682+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:42:27.682+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:42:27.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.458 seconds
[2024-04-30T22:42:58.153+0000] {processor.py:161} INFO - Started process (PID=151) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:42:58.155+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:42:58.157+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:42:58.156+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:42:58.573+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:42:58.590+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:42:58.590+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:42:58.600+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:42:58.600+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:42:58.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.467 seconds
[2024-04-30T22:43:29.025+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:43:29.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:43:29.029+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:43:29.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:43:29.443+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:43:29.461+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:43:29.461+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:43:29.470+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:43:29.470+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:43:29.477+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.485 seconds
[2024-04-30T22:43:59.911+0000] {processor.py:161} INFO - Started process (PID=155) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:43:59.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:43:59.914+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:43:59.914+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:44:00.319+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:44:00.349+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:44:00.349+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:44:00.359+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:44:00.359+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:44:00.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.466 seconds
[2024-04-30T22:44:30.807+0000] {processor.py:161} INFO - Started process (PID=157) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:44:30.809+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:44:30.811+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:44:30.810+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:44:31.245+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:44:31.281+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:44:31.281+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:44:31.292+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:44:31.292+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:44:31.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.507 seconds
[2024-04-30T22:45:01.680+0000] {processor.py:161} INFO - Started process (PID=159) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:45:01.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:45:01.684+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:45:01.684+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:45:02.127+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:45:02.153+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:45:02.153+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:45:02.167+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:45:02.167+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:45:02.174+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.508 seconds
[2024-04-30T22:45:32.464+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:45:32.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:45:32.466+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:45:32.466+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:45:32.915+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:45:32.933+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:45:32.933+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:45:32.955+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:45:32.955+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:45:32.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.509 seconds
[2024-04-30T22:46:03.386+0000] {processor.py:161} INFO - Started process (PID=163) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:46:03.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:46:03.389+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:46:03.389+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:46:03.802+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:46:03.819+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:46:03.818+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:46:03.828+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:46:03.828+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:46:03.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.486 seconds
[2024-04-30T22:46:34.228+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:46:34.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:46:34.232+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:46:34.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:46:34.638+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:46:34.657+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:46:34.657+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:46:34.667+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:46:34.667+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:46:34.674+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.458 seconds
[2024-04-30T22:47:05.108+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:47:05.110+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:47:05.111+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:47:05.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:47:05.517+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:47:05.534+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:47:05.534+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:47:05.553+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:47:05.553+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:47:05.560+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.482 seconds
[2024-04-30T22:47:36.002+0000] {processor.py:161} INFO - Started process (PID=169) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:47:36.005+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:47:36.007+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:47:36.006+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:47:36.405+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:47:36.422+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:47:36.422+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:47:36.432+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:47:36.432+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:47:36.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.459 seconds
[2024-04-30T22:48:06.832+0000] {processor.py:161} INFO - Started process (PID=171) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:48:06.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:48:06.837+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:48:06.836+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:48:07.257+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:48:07.275+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:48:07.275+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:48:07.285+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:48:07.284+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:48:07.292+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.493 seconds
[2024-04-30T22:48:37.726+0000] {processor.py:161} INFO - Started process (PID=173) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:48:37.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:48:37.730+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:48:37.730+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:48:38.163+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:48:38.176+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:48:38.176+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:48:38.185+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:48:38.185+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:48:38.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.483 seconds
[2024-04-30T22:49:08.566+0000] {processor.py:161} INFO - Started process (PID=175) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:49:08.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:49:08.571+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:49:08.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:49:09.044+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:49:09.058+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:49:09.058+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:49:09.068+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:49:09.068+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:49:09.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.527 seconds
[2024-04-30T22:49:39.478+0000] {processor.py:161} INFO - Started process (PID=177) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:49:39.480+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:49:39.481+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:49:39.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:49:39.925+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:49:39.943+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:49:39.943+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:49:39.953+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:49:39.953+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:49:39.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.495 seconds
[2024-04-30T22:50:10.330+0000] {processor.py:161} INFO - Started process (PID=179) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:50:10.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:50:10.340+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:50:10.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:50:10.742+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:50:10.756+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:50:10.756+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:50:10.766+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:50:10.766+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:50:10.773+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.463 seconds
[2024-04-30T22:50:41.207+0000] {processor.py:161} INFO - Started process (PID=181) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:50:41.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:50:41.212+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:50:41.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:50:41.621+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:50:41.636+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:50:41.636+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:50:41.645+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:50:41.645+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:50:41.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.480 seconds
[2024-04-30T22:51:12.019+0000] {processor.py:161} INFO - Started process (PID=183) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:51:12.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:51:12.022+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:51:12.022+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:51:12.457+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:51:12.478+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:51:12.478+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:51:12.501+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:51:12.501+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:51:12.510+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.504 seconds
[2024-04-30T22:51:42.970+0000] {processor.py:161} INFO - Started process (PID=185) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:51:42.972+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:51:42.973+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:51:42.973+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:51:43.455+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:51:43.473+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:51:43.473+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:51:43.483+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:51:43.483+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:51:43.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.537 seconds
[2024-04-30T22:52:13.833+0000] {processor.py:161} INFO - Started process (PID=187) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:52:13.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:52:13.835+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:52:13.835+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:52:14.255+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:52:14.272+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:52:14.272+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:52:14.285+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:52:14.285+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:52:14.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.474 seconds
[2024-04-30T22:52:44.682+0000] {processor.py:161} INFO - Started process (PID=189) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:52:44.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:52:44.692+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:52:44.689+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:52:45.114+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:52:45.136+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:52:45.136+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:52:45.154+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:52:45.154+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:52:45.165+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.503 seconds
[2024-04-30T22:53:15.624+0000] {processor.py:161} INFO - Started process (PID=191) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:53:15.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:53:15.629+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:53:15.628+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:53:16.046+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:53:16.061+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:53:16.061+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:53:16.072+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:53:16.072+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:53:16.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.472 seconds
[2024-04-30T22:53:46.457+0000] {processor.py:161} INFO - Started process (PID=193) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:53:46.459+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:53:46.460+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:53:46.460+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:53:46.880+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:53:46.897+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:53:46.897+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:53:46.907+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:53:46.907+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:53:46.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.469 seconds
[2024-04-30T22:54:17.339+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:54:17.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:54:17.343+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:54:17.343+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:54:17.857+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:54:17.882+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:54:17.882+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:54:17.895+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:54:17.895+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:54:17.903+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.583 seconds
[2024-04-30T22:54:48.574+0000] {processor.py:161} INFO - Started process (PID=197) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:54:48.577+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:54:48.579+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:54:48.578+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:54:49.165+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:54:49.197+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:54:49.197+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:54:49.210+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:54:49.210+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:54:49.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.660 seconds
[2024-04-30T22:55:19.687+0000] {processor.py:161} INFO - Started process (PID=199) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:55:19.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:55:19.691+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:55:19.690+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:55:20.134+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:55:20.154+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:55:20.154+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:55:20.169+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:55:20.169+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:55:20.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.513 seconds
[2024-04-30T22:55:50.494+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:55:50.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:55:50.498+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:55:50.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:55:50.942+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:55:50.965+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:55:50.964+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:55:50.983+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:55:50.983+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:55:50.990+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.513 seconds
[2024-04-30T22:56:21.377+0000] {processor.py:161} INFO - Started process (PID=203) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:56:21.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:56:21.380+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:56:21.380+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:56:21.786+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:56:21.810+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:56:21.809+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:56:21.819+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:56:21.819+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:56:21.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.463 seconds
[2024-04-30T22:56:52.252+0000] {processor.py:161} INFO - Started process (PID=205) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:56:52.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:56:52.255+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:56:52.255+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:56:52.677+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:56:52.697+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:56:52.696+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:56:52.708+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:56:52.707+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:56:52.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.504 seconds
[2024-04-30T22:57:23.224+0000] {processor.py:161} INFO - Started process (PID=207) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:57:23.226+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:57:23.228+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:57:23.227+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:57:23.723+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:57:23.758+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:57:23.758+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:57:23.780+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:57:23.779+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:57:23.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.585 seconds
[2024-04-30T22:57:54.253+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:57:54.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:57:54.256+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:57:54.256+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:57:54.708+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:57:54.742+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:57:54.742+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:57:54.752+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:57:54.752+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:57:54.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.525 seconds
[2024-04-30T22:58:26.934+0000] {processor.py:161} INFO - Started process (PID=211) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:58:26.973+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:58:27.006+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:58:27.004+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:58:32.406+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:58:32.437+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:58:32.437+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:58:32.449+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:58:32.449+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:58:32.458+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 6.455 seconds
[2024-04-30T22:59:02.879+0000] {processor.py:161} INFO - Started process (PID=213) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:59:02.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:59:02.884+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:59:02.883+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:59:03.279+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:59:03.296+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:59:03.295+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:59:03.306+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:59:03.306+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:59:03.313+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.450 seconds
[2024-04-30T22:59:33.774+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T22:59:33.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T22:59:33.777+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:59:33.777+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T22:59:34.192+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T22:59:34.221+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:59:34.221+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T22:59:34.231+0000] {logging_mixin.py:188} INFO - [2024-04-30T22:59:34.231+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T22:59:34.238+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.498 seconds
[2024-04-30T23:00:04.676+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:00:04.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:00:04.679+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:00:04.679+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:00:05.099+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:00:05.141+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:00:05.141+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:00:05.152+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:00:05.152+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:00:05.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.500 seconds
[2024-04-30T23:00:35.551+0000] {processor.py:161} INFO - Started process (PID=219) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:00:35.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:00:35.554+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:00:35.553+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:00:35.979+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:00:36.008+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:00:36.006+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:00:36.030+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:00:36.029+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:00:36.041+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.506 seconds
[2024-04-30T23:01:06.508+0000] {processor.py:161} INFO - Started process (PID=221) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:01:06.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:01:06.511+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:01:06.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:01:06.967+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:01:06.983+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:01:06.983+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:01:06.993+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:01:06.993+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:01:07.000+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.521 seconds
[2024-04-30T23:01:37.320+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:01:37.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:01:37.323+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:01:37.322+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:01:37.740+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:01:37.754+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:01:37.754+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:01:37.767+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:01:37.767+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:01:37.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.475 seconds
[2024-04-30T23:02:08.185+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:02:08.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:02:08.192+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:02:08.190+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:02:08.594+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:02:08.610+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:02:08.610+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:02:08.620+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:02:08.620+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:02:08.628+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.478 seconds
[2024-04-30T23:02:39.017+0000] {processor.py:161} INFO - Started process (PID=227) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:02:39.019+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:02:39.021+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:02:39.020+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:02:39.432+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:02:39.450+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:02:39.450+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:02:39.460+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:02:39.460+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:02:39.467+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.468 seconds
[2024-04-30T23:03:09.854+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:03:09.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:03:09.857+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:03:09.857+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:03:10.290+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:03:10.315+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:03:10.315+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:03:10.326+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:03:10.326+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:03:10.335+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.495 seconds
[2024-04-30T23:03:40.800+0000] {processor.py:161} INFO - Started process (PID=231) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:03:40.802+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:03:40.804+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:03:40.803+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:03:41.222+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:03:41.239+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:03:41.239+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:03:41.248+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:03:41.248+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:03:41.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.501 seconds
[2024-04-30T23:04:11.687+0000] {processor.py:161} INFO - Started process (PID=233) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:04:11.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:04:11.691+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:04:11.691+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:04:12.124+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:04:12.150+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:04:12.150+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:04:12.161+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:04:12.161+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:04:12.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.518 seconds
[2024-04-30T23:04:42.641+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:04:42.653+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:04:42.655+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:04:42.655+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:04:43.041+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:04:43.060+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:04:43.060+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:04:43.074+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:04:43.073+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:04:43.080+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.461 seconds
[2024-04-30T23:05:13.530+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:05:13.533+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:05:13.535+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:05:13.534+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:05:13.975+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:05:13.992+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:05:13.992+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:05:14.001+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:05:14.001+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:05:14.008+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.497 seconds
[2024-04-30T23:05:44.505+0000] {processor.py:161} INFO - Started process (PID=239) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:05:44.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:05:44.515+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:05:44.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:05:44.977+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:05:44.996+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:05:44.996+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:05:45.006+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:05:45.006+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:05:45.014+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.543 seconds
[2024-04-30T23:06:15.402+0000] {processor.py:161} INFO - Started process (PID=241) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:06:15.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:06:15.404+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:06:15.404+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:06:15.872+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:06:15.915+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:06:15.915+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:06:15.932+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:06:15.932+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:06:15.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.547 seconds
[2024-04-30T23:06:46.300+0000] {processor.py:161} INFO - Started process (PID=243) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:06:46.306+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:06:46.309+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:06:46.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:06:46.865+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:06:46.901+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:06:46.900+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:06:46.923+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:06:46.923+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:06:46.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.649 seconds
[2024-04-30T23:07:17.416+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:07:17.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:07:17.420+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:07:17.420+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:07:17.822+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:07:17.854+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:07:17.854+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:07:17.864+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:07:17.864+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:07:17.871+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.484 seconds
[2024-04-30T23:07:48.096+0000] {processor.py:161} INFO - Started process (PID=247) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:07:48.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:07:48.099+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:07:48.098+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:07:48.500+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:07:48.517+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:07:48.517+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:07:48.527+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:07:48.527+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:07:48.535+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.451 seconds
[2024-04-30T23:08:18.915+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:08:18.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:08:18.918+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:08:18.917+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:08:19.332+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:08:19.352+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:08:19.351+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:08:19.361+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:08:19.361+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:08:19.368+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.467 seconds
[2024-04-30T23:08:49.809+0000] {processor.py:161} INFO - Started process (PID=251) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:08:49.811+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:08:49.812+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:08:49.812+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:08:50.230+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:08:50.247+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:08:50.247+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:08:50.257+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:08:50.257+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:08:50.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.492 seconds
[2024-04-30T23:09:20.753+0000] {processor.py:161} INFO - Started process (PID=253) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:09:20.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:09:20.755+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:09:20.755+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:09:21.169+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:09:21.201+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:09:21.201+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:09:21.212+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:09:21.212+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:09:21.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.475 seconds
[2024-04-30T23:09:51.595+0000] {processor.py:161} INFO - Started process (PID=255) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:09:51.597+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:09:51.598+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:09:51.598+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:09:52.020+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:09:52.038+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:09:52.038+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:09:52.057+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:09:52.057+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:09:52.064+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.489 seconds
[2024-04-30T23:10:22.562+0000] {processor.py:161} INFO - Started process (PID=257) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:10:22.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:10:22.566+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:10:22.565+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:10:22.988+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:10:23.004+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:10:23.004+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:10:23.023+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:10:23.023+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:10:23.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.479 seconds
[2024-04-30T23:10:53.320+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:10:53.322+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:10:53.324+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:10:53.323+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:10:53.755+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:10:53.771+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:10:53.771+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:10:53.780+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:10:53.780+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:10:53.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.484 seconds
[2024-04-30T23:11:24.238+0000] {processor.py:161} INFO - Started process (PID=261) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:11:24.241+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:11:24.242+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:11:24.242+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:11:24.652+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:11:24.671+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:11:24.671+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:11:24.680+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:11:24.680+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:11:24.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.462 seconds
[2024-04-30T23:11:55.059+0000] {processor.py:161} INFO - Started process (PID=263) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:11:55.065+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:11:55.068+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:11:55.067+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:11:55.566+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:11:55.585+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:11:55.585+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:11:55.604+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:11:55.604+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:11:55.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.576 seconds
[2024-04-30T23:12:26.081+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:12:26.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:12:26.083+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:12:26.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:12:26.514+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:12:26.532+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:12:26.532+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:12:26.542+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:12:26.542+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:12:26.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.484 seconds
[2024-04-30T23:12:56.920+0000] {processor.py:161} INFO - Started process (PID=267) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:12:56.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:12:56.924+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:12:56.923+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:12:57.351+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:12:57.382+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:12:57.381+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:12:57.391+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:12:57.391+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:12:57.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.491 seconds
[2024-04-30T23:13:27.787+0000] {processor.py:161} INFO - Started process (PID=269) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:13:27.788+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:13:27.789+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:13:27.789+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:13:28.216+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:13:28.233+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:13:28.233+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:13:28.243+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:13:28.243+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:13:28.250+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.480 seconds
[2024-04-30T23:13:58.665+0000] {processor.py:161} INFO - Started process (PID=271) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:13:58.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:13:58.670+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:13:58.669+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:13:59.105+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:13:59.124+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:13:59.124+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:13:59.133+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:13:59.133+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:13:59.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.517 seconds
[2024-04-30T23:14:29.477+0000] {processor.py:161} INFO - Started process (PID=273) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:14:29.479+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:14:29.480+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:14:29.479+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:14:29.895+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:14:29.928+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:14:29.927+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:14:29.942+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:14:29.941+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:14:29.949+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.483 seconds
[2024-04-30T23:15:00.403+0000] {processor.py:161} INFO - Started process (PID=275) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:15:00.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:15:00.406+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:15:00.406+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:15:00.866+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:15:00.887+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:15:00.887+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:15:00.903+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:15:00.903+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:15:00.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.524 seconds
[2024-04-30T23:15:31.367+0000] {processor.py:161} INFO - Started process (PID=277) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:15:31.368+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:15:31.369+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:15:31.369+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:15:31.806+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:15:31.822+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:15:31.822+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:15:31.833+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:15:31.833+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:15:31.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.483 seconds
[2024-04-30T23:16:02.240+0000] {processor.py:161} INFO - Started process (PID=279) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:16:02.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:16:02.257+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:16:02.257+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:16:02.678+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:16:02.696+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:16:02.696+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:16:02.707+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:16:02.706+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:16:02.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.489 seconds
[2024-04-30T23:16:33.200+0000] {processor.py:161} INFO - Started process (PID=281) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:16:33.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:16:33.203+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:16:33.202+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:16:33.648+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:16:33.665+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:16:33.665+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:16:33.674+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:16:33.674+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:16:33.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.496 seconds
[2024-04-30T23:17:04.086+0000] {processor.py:161} INFO - Started process (PID=283) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:17:04.088+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:17:04.089+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:17:04.088+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:17:04.493+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:17:04.512+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:17:04.512+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:17:04.523+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:17:04.523+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:17:04.529+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.469 seconds
[2024-04-30T23:17:34.938+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:17:34.940+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:17:34.943+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:17:34.942+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:17:35.369+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:17:35.386+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:17:35.386+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:17:35.395+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:17:35.395+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:17:35.403+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.494 seconds
[2024-04-30T23:18:05.804+0000] {processor.py:161} INFO - Started process (PID=287) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:18:05.806+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:18:05.811+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:18:05.809+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:18:06.274+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:18:06.292+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:18:06.291+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:18:06.305+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:18:06.305+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:18:06.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.527 seconds
[2024-04-30T23:18:36.848+0000] {processor.py:161} INFO - Started process (PID=289) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:18:36.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:18:36.854+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:18:36.853+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:18:37.265+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:18:37.282+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:18:37.282+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:18:37.292+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:18:37.292+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:18:37.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.472 seconds
[2024-04-30T23:19:07.776+0000] {processor.py:161} INFO - Started process (PID=291) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:19:07.780+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:19:07.781+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:19:07.781+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:19:08.239+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:19:08.272+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:19:08.271+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:19:08.282+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:19:08.282+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:19:08.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.529 seconds
[2024-04-30T23:19:38.844+0000] {processor.py:161} INFO - Started process (PID=293) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:19:38.847+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:19:38.849+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:19:38.848+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:19:39.255+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:19:39.279+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:19:39.279+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:19:39.293+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:19:39.293+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:19:39.300+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.469 seconds
[2024-04-30T23:20:09.750+0000] {processor.py:161} INFO - Started process (PID=295) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:20:09.759+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:20:09.761+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:20:09.760+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:20:10.215+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:20:10.234+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:20:10.234+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:20:10.243+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:20:10.243+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:20:10.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.515 seconds
[2024-04-30T23:20:40.589+0000] {processor.py:161} INFO - Started process (PID=297) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:20:40.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:20:40.592+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:20:40.592+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:20:40.984+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:20:40.998+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:20:40.998+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:20:41.007+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:20:41.007+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:20:41.015+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.435 seconds
[2024-04-30T23:21:11.420+0000] {processor.py:161} INFO - Started process (PID=299) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:21:11.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:21:11.426+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:21:11.425+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:21:11.840+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:21:11.869+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:21:11.868+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:21:11.883+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:21:11.882+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:21:11.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.491 seconds
[2024-04-30T23:21:42.296+0000] {processor.py:161} INFO - Started process (PID=301) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:21:42.299+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:21:42.300+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:21:42.300+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:21:42.735+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:21:42.751+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:21:42.751+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:21:42.762+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:21:42.762+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:21:42.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.490 seconds
[2024-04-30T23:22:13.204+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:22:13.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:22:13.213+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:22:13.212+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:22:13.626+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:22:13.641+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:22:13.641+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:22:13.651+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:22:13.651+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:22:13.658+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.486 seconds
[2024-04-30T23:22:44.007+0000] {processor.py:161} INFO - Started process (PID=305) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:22:44.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:22:44.012+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:22:44.011+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:22:44.537+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:22:44.560+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:22:44.560+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:22:44.577+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:22:44.576+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:22:44.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.596 seconds
[2024-04-30T23:23:14.968+0000] {processor.py:161} INFO - Started process (PID=307) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:23:14.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:23:14.972+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:23:14.971+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:23:15.392+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:23:15.411+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:23:15.411+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:23:15.420+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:23:15.420+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:23:15.427+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.477 seconds
[2024-04-30T23:23:45.841+0000] {processor.py:161} INFO - Started process (PID=309) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:23:45.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:23:45.845+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:23:45.844+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:23:46.272+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:23:46.289+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:23:46.288+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:23:46.298+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:23:46.298+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:23:46.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.477 seconds
[2024-04-30T23:24:16.679+0000] {processor.py:161} INFO - Started process (PID=311) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:24:16.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:24:16.684+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:24:16.684+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:24:17.138+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:24:17.157+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:24:17.157+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:24:17.168+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:24:17.168+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:24:17.183+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.528 seconds
[2024-04-30T23:24:47.584+0000] {processor.py:161} INFO - Started process (PID=313) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:24:47.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:24:47.587+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:24:47.587+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:24:47.999+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:24:48.016+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:24:48.015+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:24:48.025+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:24:48.025+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:24:48.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.475 seconds
[2024-04-30T23:25:18.453+0000] {processor.py:161} INFO - Started process (PID=315) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:25:18.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:25:18.456+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:25:18.455+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:25:18.843+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:25:18.859+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:25:18.859+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:25:18.868+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:25:18.868+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:25:18.875+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.446 seconds
[2024-04-30T23:25:49.325+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:25:49.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:25:49.328+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:25:49.328+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:25:49.738+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:25:49.773+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:25:49.772+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:25:49.785+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:25:49.785+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:25:49.792+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.481 seconds
[2024-04-30T23:26:20.260+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:26:20.262+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:26:20.263+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:26:20.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:26:20.678+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:26:20.696+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:26:20.695+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:26:20.705+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:26:20.705+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:26:20.713+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.481 seconds
[2024-04-30T23:26:51.134+0000] {processor.py:161} INFO - Started process (PID=321) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:26:51.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:26:51.139+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:26:51.138+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:26:51.552+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:26:51.567+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:26:51.567+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:26:51.576+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:26:51.576+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:26:51.583+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.475 seconds
[2024-04-30T23:27:22.015+0000] {processor.py:161} INFO - Started process (PID=323) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:27:22.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:27:22.018+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:27:22.018+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:27:22.442+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:27:22.462+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:27:22.462+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:27:22.472+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:27:22.472+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:27:22.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.475 seconds
[2024-04-30T23:27:52.900+0000] {processor.py:161} INFO - Started process (PID=325) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:27:52.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:27:52.911+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:27:52.910+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:27:53.357+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:27:53.377+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:27:53.377+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:27:53.387+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:27:53.387+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:27:53.394+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.519 seconds
[2024-04-30T23:28:23.808+0000] {processor.py:161} INFO - Started process (PID=327) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:28:23.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:28:23.811+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:28:23.811+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:28:24.268+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:28:24.287+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:28:24.287+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:28:24.297+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:28:24.297+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:28:24.305+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.520 seconds
[2024-04-30T23:28:54.722+0000] {processor.py:161} INFO - Started process (PID=329) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:28:54.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:28:54.725+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:28:54.725+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:28:55.148+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:28:55.167+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:28:55.167+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:28:55.177+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:28:55.176+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:28:55.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.472 seconds
[2024-04-30T23:29:25.601+0000] {processor.py:161} INFO - Started process (PID=331) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:29:25.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:29:25.604+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:29:25.604+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:29:26.000+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:29:26.020+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:29:26.020+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:29:26.036+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:29:26.036+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:29:26.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.481 seconds
[2024-04-30T23:29:56.463+0000] {processor.py:161} INFO - Started process (PID=333) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:29:56.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:29:56.466+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:29:56.466+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:29:56.906+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:29:56.935+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:29:56.935+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:29:56.947+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:29:56.947+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:29:56.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.500 seconds
[2024-04-30T23:30:27.330+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:30:27.342+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:30:27.347+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:30:27.344+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:30:27.804+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:30:27.823+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:30:27.822+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:30:27.832+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:30:27.832+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:30:27.842+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.528 seconds
[2024-04-30T23:30:58.228+0000] {processor.py:161} INFO - Started process (PID=337) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:30:58.230+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:30:58.231+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:30:58.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:30:58.642+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:30:58.675+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:30:58.675+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:30:58.684+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:30:58.684+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:30:58.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.481 seconds
[2024-04-30T23:31:29.085+0000] {processor.py:161} INFO - Started process (PID=339) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:31:29.087+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:31:29.088+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:31:29.088+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:31:29.470+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:31:29.487+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:31:29.487+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:31:29.497+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:31:29.497+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:31:29.504+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.432 seconds
[2024-04-30T23:31:59.888+0000] {processor.py:161} INFO - Started process (PID=341) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:31:59.897+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:31:59.899+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:31:59.898+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:32:00.321+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:32:00.340+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:32:00.339+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:32:00.349+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:32:00.349+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:32:00.357+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.484 seconds
[2024-04-30T23:32:30.806+0000] {processor.py:161} INFO - Started process (PID=343) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:32:30.808+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:32:30.809+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:32:30.808+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:32:31.228+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:32:31.244+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:32:31.244+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:32:31.269+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:32:31.269+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:32:31.276+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.497 seconds
[2024-04-30T23:33:01.751+0000] {processor.py:161} INFO - Started process (PID=345) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:33:01.754+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:33:01.756+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:33:01.754+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:33:02.214+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:33:02.232+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:33:02.232+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:33:02.242+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:33:02.242+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:33:02.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.511 seconds
[2024-04-30T23:33:32.689+0000] {processor.py:161} INFO - Started process (PID=347) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:33:32.696+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:33:32.697+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:33:32.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:33:33.097+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:33:33.114+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:33:33.114+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:33:33.123+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:33:33.123+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:33:33.142+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.482 seconds
[2024-04-30T23:34:03.482+0000] {processor.py:161} INFO - Started process (PID=349) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:34:03.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:34:03.485+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:34:03.485+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:34:03.901+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:34:03.929+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:34:03.929+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:34:03.938+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:34:03.938+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:34:03.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.473 seconds
[2024-04-30T23:34:34.378+0000] {processor.py:161} INFO - Started process (PID=351) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:34:34.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:34:34.382+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:34:34.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:34:34.800+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:34:34.818+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:34:34.818+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:34:34.828+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:34:34.828+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:34:34.835+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.473 seconds
[2024-04-30T23:35:05.291+0000] {processor.py:161} INFO - Started process (PID=353) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:35:05.292+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:35:05.294+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:35:05.293+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:35:05.708+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:35:05.725+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:35:05.725+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:35:05.741+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:35:05.741+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:35:05.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.480 seconds
[2024-04-30T23:35:36.142+0000] {processor.py:161} INFO - Started process (PID=355) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:35:36.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:35:36.147+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:35:36.146+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:35:36.565+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:35:36.581+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:35:36.581+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:35:36.591+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:35:36.591+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:35:36.598+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.468 seconds
[2024-04-30T23:36:07.056+0000] {processor.py:161} INFO - Started process (PID=357) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:36:07.058+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:36:07.059+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:36:07.059+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:36:07.491+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:36:07.514+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:36:07.514+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:36:07.527+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:36:07.527+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:36:07.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.501 seconds
[2024-04-30T23:36:37.967+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:36:37.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:36:37.971+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:36:37.970+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:36:38.367+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:36:38.383+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:36:38.382+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:36:38.392+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:36:38.391+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:36:38.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.443 seconds
[2024-04-30T23:37:08.747+0000] {processor.py:161} INFO - Started process (PID=361) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:37:08.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:37:08.751+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:37:08.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:37:09.142+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:37:09.155+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:37:09.155+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:37:09.164+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:37:09.164+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:37:09.171+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.450 seconds
[2024-04-30T23:37:39.569+0000] {processor.py:161} INFO - Started process (PID=363) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:37:39.571+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:37:39.572+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:37:39.572+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:37:39.971+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:37:40.003+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:37:40.003+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:37:40.012+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:37:40.012+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:37:40.020+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.483 seconds
[2024-04-30T23:38:10.378+0000] {processor.py:161} INFO - Started process (PID=365) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:38:10.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:38:10.382+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:38:10.380+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:38:10.867+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:38:10.884+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:38:10.884+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:38:10.895+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:38:10.895+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:38:10.902+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.537 seconds
[2024-04-30T23:38:41.339+0000] {processor.py:161} INFO - Started process (PID=367) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:38:41.341+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:38:41.342+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:38:41.342+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:38:41.748+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:38:41.764+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:38:41.763+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:38:41.773+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:38:41.773+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:38:41.780+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.457 seconds
[2024-04-30T23:39:12.096+0000] {processor.py:161} INFO - Started process (PID=369) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:39:12.098+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:39:12.099+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:39:12.099+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:39:12.512+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:39:12.526+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:39:12.525+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:39:12.535+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:39:12.534+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:39:12.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.459 seconds
[2024-04-30T23:39:42.959+0000] {processor.py:161} INFO - Started process (PID=371) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:39:42.961+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:39:42.963+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:39:42.962+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:39:43.358+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:39:43.372+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:39:43.372+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:39:43.381+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:39:43.381+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:39:43.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.442 seconds
[2024-04-30T23:40:13.763+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:40:13.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:40:13.769+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:40:13.768+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:40:14.178+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:40:14.192+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:40:14.192+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:40:14.201+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:40:14.201+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:40:14.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.475 seconds
[2024-04-30T23:40:44.643+0000] {processor.py:161} INFO - Started process (PID=375) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:40:44.646+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:40:44.647+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:40:44.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:40:45.094+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:40:45.111+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:40:45.111+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:40:45.120+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:40:45.120+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:40:45.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.499 seconds
[2024-04-30T23:41:15.440+0000] {processor.py:161} INFO - Started process (PID=377) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:41:15.443+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:41:15.445+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:41:15.444+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:41:15.846+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:41:15.872+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:41:15.872+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:41:15.884+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:41:15.884+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:41:15.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.491 seconds
[2024-04-30T23:41:46.303+0000] {processor.py:161} INFO - Started process (PID=379) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:41:46.307+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:41:46.309+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:41:46.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:41:46.749+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:41:46.771+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:41:46.771+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:41:46.783+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:41:46.783+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:41:46.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.517 seconds
[2024-04-30T23:42:17.260+0000] {processor.py:161} INFO - Started process (PID=381) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:42:17.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:42:17.262+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:42:17.261+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:42:17.649+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:42:17.683+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:42:17.682+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:42:17.693+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:42:17.692+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:42:17.699+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.448 seconds
[2024-04-30T23:42:48.102+0000] {processor.py:161} INFO - Started process (PID=383) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:42:48.104+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:42:48.106+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:42:48.105+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:42:48.503+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:42:48.526+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:42:48.526+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:42:48.542+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:42:48.542+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:42:48.550+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.462 seconds
[2024-04-30T23:43:18.953+0000] {processor.py:161} INFO - Started process (PID=385) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:43:18.956+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:43:18.957+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:43:18.956+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:43:19.380+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:43:19.398+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:43:19.398+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:43:19.418+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:43:19.418+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:43:19.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.504 seconds
[2024-04-30T23:43:49.949+0000] {processor.py:161} INFO - Started process (PID=387) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:43:49.951+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:43:49.952+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:43:49.952+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:43:50.373+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:43:50.392+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:43:50.391+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:43:50.404+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:43:50.404+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:43:50.413+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.476 seconds
[2024-04-30T23:44:20.898+0000] {processor.py:161} INFO - Started process (PID=389) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:44:20.899+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:44:20.901+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:44:20.900+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:44:21.372+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:44:21.392+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:44:21.392+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:44:21.402+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:44:21.402+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:44:21.409+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.522 seconds
[2024-04-30T23:44:51.912+0000] {processor.py:161} INFO - Started process (PID=391) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:44:51.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:44:51.916+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:44:51.915+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:44:52.358+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:44:52.376+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:44:52.376+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:44:52.386+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:44:52.386+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:44:52.393+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.493 seconds
[2024-04-30T23:45:22.699+0000] {processor.py:161} INFO - Started process (PID=393) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:45:22.702+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:45:22.703+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:45:22.702+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:45:23.093+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:45:23.112+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:45:23.112+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:45:23.121+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:45:23.121+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:45:23.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.445 seconds
[2024-04-30T23:45:53.597+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:45:53.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:45:53.606+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:45:53.603+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:45:54.298+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:45:54.355+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:45:54.354+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:45:54.374+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:45:54.374+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:45:54.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.834 seconds
[2024-04-30T23:46:24.503+0000] {processor.py:161} INFO - Started process (PID=397) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:46:24.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:46:24.506+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:46:24.505+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:46:25.018+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:46:25.081+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:46:25.080+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:46:25.101+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:46:25.100+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:46:25.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.644 seconds
[2024-04-30T23:46:55.560+0000] {processor.py:161} INFO - Started process (PID=399) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:46:55.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:46:55.563+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:46:55.562+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:46:56.001+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:46:56.037+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:46:56.037+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:46:56.048+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:46:56.048+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:46:56.055+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.504 seconds
[2024-04-30T23:47:26.496+0000] {processor.py:161} INFO - Started process (PID=401) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:47:26.497+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:47:26.499+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:47:26.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:47:26.895+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:47:26.927+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:47:26.927+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:47:26.937+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:47:26.937+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:47:26.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.470 seconds
[2024-04-30T23:47:57.359+0000] {processor.py:161} INFO - Started process (PID=403) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:47:57.361+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:47:57.362+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:47:57.362+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:47:57.824+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:47:57.846+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:47:57.846+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:47:57.856+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:47:57.856+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:47:57.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.513 seconds
[2024-04-30T23:48:28.259+0000] {processor.py:161} INFO - Started process (PID=405) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:48:28.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:48:28.262+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:48:28.262+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:48:28.691+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:48:28.714+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:48:28.714+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:48:28.724+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:48:28.724+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:48:28.731+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.483 seconds
[2024-04-30T23:48:59.175+0000] {processor.py:161} INFO - Started process (PID=407) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:48:59.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:48:59.180+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:48:59.180+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:48:59.570+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:48:59.593+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:48:59.593+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:48:59.605+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:48:59.605+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:48:59.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.457 seconds
[2024-04-30T23:49:30.147+0000] {processor.py:161} INFO - Started process (PID=409) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:49:30.148+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:49:30.150+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:49:30.149+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:49:30.647+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:49:30.687+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:49:30.687+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:49:30.710+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:49:30.710+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:49:30.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.622 seconds
[2024-04-30T23:50:01.134+0000] {processor.py:161} INFO - Started process (PID=411) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:50:01.136+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:50:01.138+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:50:01.137+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:50:01.675+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:50:01.713+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:50:01.713+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:50:01.728+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:50:01.728+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:50:01.743+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.620 seconds
[2024-04-30T23:50:31.918+0000] {processor.py:161} INFO - Started process (PID=413) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:50:31.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:50:31.922+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:50:31.921+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:50:32.330+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:50:32.355+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:50:32.355+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:50:32.370+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:50:32.370+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:50:32.384+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.478 seconds
[2024-04-30T23:51:02.508+0000] {processor.py:161} INFO - Started process (PID=415) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:51:02.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:51:02.511+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:51:02.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:51:02.931+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:51:02.956+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:51:02.956+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:51:02.967+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:51:02.967+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:51:02.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.479 seconds
[2024-04-30T23:51:33.079+0000] {processor.py:161} INFO - Started process (PID=417) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:51:33.082+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:51:33.084+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:51:33.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:51:33.498+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:51:33.519+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:51:33.519+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:51:33.530+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:51:33.530+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:51:33.537+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.472 seconds
[2024-04-30T23:52:03.772+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:52:03.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:52:03.776+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:52:03.776+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:52:04.194+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:52:04.213+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:52:04.213+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:52:04.223+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:52:04.223+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:52:04.231+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.472 seconds
[2024-04-30T23:52:34.625+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:52:34.627+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:52:34.628+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:52:34.628+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:52:35.017+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:52:35.039+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:52:35.038+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:52:35.049+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:52:35.049+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:52:35.056+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.440 seconds
[2024-04-30T23:53:05.481+0000] {processor.py:161} INFO - Started process (PID=423) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:53:05.483+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:53:05.485+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:53:05.484+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:53:05.946+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:53:05.988+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:53:05.988+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:53:05.998+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:53:05.998+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:53:06.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.536 seconds
[2024-04-30T23:53:36.487+0000] {processor.py:161} INFO - Started process (PID=425) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:53:36.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:53:36.502+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:53:36.501+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:53:36.954+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:53:36.987+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:53:36.986+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:53:36.999+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:53:36.999+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:53:37.007+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.532 seconds
[2024-04-30T23:54:07.490+0000] {processor.py:161} INFO - Started process (PID=427) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:54:07.495+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:54:07.505+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:54:07.501+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:54:07.935+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:54:07.955+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:54:07.955+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:54:07.966+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:54:07.966+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:54:07.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.499 seconds
[2024-04-30T23:54:38.468+0000] {processor.py:161} INFO - Started process (PID=429) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:54:38.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:54:38.481+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:54:38.480+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:54:38.911+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:54:38.941+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:54:38.941+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:54:38.954+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:54:38.954+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:54:38.963+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.550 seconds
[2024-04-30T23:55:09.303+0000] {processor.py:161} INFO - Started process (PID=431) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:55:09.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:55:09.313+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:55:09.311+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:55:09.734+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:55:09.754+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:55:09.753+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:55:09.779+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:55:09.779+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:55:09.788+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.506 seconds
[2024-04-30T23:55:40.230+0000] {processor.py:161} INFO - Started process (PID=433) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:55:40.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:55:40.239+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:55:40.236+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:55:40.632+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:55:40.646+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:55:40.646+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:55:40.660+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:55:40.659+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:55:40.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.473 seconds
[2024-04-30T23:56:11.030+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:56:11.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:56:11.036+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:56:11.035+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:56:11.453+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:56:11.469+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:56:11.468+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:56:11.480+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:56:11.480+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:56:11.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.476 seconds
[2024-04-30T23:56:41.941+0000] {processor.py:161} INFO - Started process (PID=437) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:56:41.944+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:56:41.945+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:56:41.945+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:56:42.341+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:56:42.360+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:56:42.359+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:56:42.371+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:56:42.371+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:56:42.378+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.453 seconds
[2024-04-30T23:57:12.754+0000] {processor.py:161} INFO - Started process (PID=439) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:57:12.755+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:57:12.756+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:57:12.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:57:13.165+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:57:13.232+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:57:13.232+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:57:13.268+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:57:13.268+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:57:13.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.537 seconds
[2024-04-30T23:57:43.658+0000] {processor.py:161} INFO - Started process (PID=441) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:57:43.661+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:57:43.663+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:57:43.662+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:57:44.073+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:57:44.093+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:57:44.092+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:57:44.117+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:57:44.117+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:57:44.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.489 seconds
[2024-04-30T23:58:14.501+0000] {processor.py:161} INFO - Started process (PID=443) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:58:14.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:58:14.504+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:58:14.504+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:58:14.897+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:58:14.911+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:58:14.911+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:58:14.938+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:58:14.938+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:58:14.946+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.472 seconds
[2024-04-30T23:58:45.334+0000] {processor.py:161} INFO - Started process (PID=445) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:58:45.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:58:45.339+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:58:45.338+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:58:45.760+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:58:45.779+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:58:45.779+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:58:45.792+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:58:45.792+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:58:45.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.483 seconds
[2024-04-30T23:59:16.206+0000] {processor.py:161} INFO - Started process (PID=447) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:59:16.218+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:59:16.221+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:59:16.221+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:59:16.623+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:59:16.642+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:59:16.642+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:59:16.654+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:59:16.654+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:59:16.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.475 seconds
[2024-04-30T23:59:47.106+0000] {processor.py:161} INFO - Started process (PID=449) to work on /opt/airflow/dags/redditDag.py
[2024-04-30T23:59:47.113+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/redditDag.py for tasks to queue
[2024-04-30T23:59:47.114+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:59:47.113+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/redditDag.py
[2024-04-30T23:59:47.560+0000] {processor.py:840} INFO - DAG(s) 'etl_reddit_pipeline' retrieved from /opt/airflow/dags/redditDag.py
[2024-04-30T23:59:47.590+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:59:47.590+0000] {dag.py:3096} INFO - Sync 1 DAGs
[2024-04-30T23:59:47.622+0000] {logging_mixin.py:188} INFO - [2024-04-30T23:59:47.622+0000] {dag.py:3954} INFO - Setting next_dagrun for etl_reddit_pipeline to 2024-04-30 00:00:00+00:00, run_after=2024-05-01 00:00:00+00:00
[2024-04-30T23:59:47.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/redditDag.py took 0.557 seconds
