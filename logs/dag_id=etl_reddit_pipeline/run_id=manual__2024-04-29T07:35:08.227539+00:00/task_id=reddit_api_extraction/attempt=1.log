[2024-04-29T07:35:09.366+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_api_extraction manual__2024-04-29T07:35:08.227539+00:00 [queued]>
[2024-04-29T07:35:09.371+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: etl_reddit_pipeline.reddit_api_extraction manual__2024-04-29T07:35:08.227539+00:00 [queued]>
[2024-04-29T07:35:09.371+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 1
[2024-04-29T07:35:09.377+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): reddit_api_extraction> on 2024-04-29 07:35:08.227539+00:00
[2024-04-29T07:35:09.382+0000] {standard_task_runner.py:57} INFO - Started process 58 to run task
[2024-04-29T07:35:09.385+0000] {standard_task_runner.py:84} INFO - Running: ['airflow', 'tasks', 'run', 'etl_reddit_pipeline', 'reddit_api_extraction', 'manual__2024-04-29T07:35:08.227539+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/redditDag.py', '--cfg-path', '/tmp/tmp8kugouo7']
[2024-04-29T07:35:09.387+0000] {standard_task_runner.py:85} INFO - Job 4: Subtask reddit_api_extraction
[2024-04-29T07:35:09.496+0000] {task_command.py:416} INFO - Running <TaskInstance: etl_reddit_pipeline.reddit_api_extraction manual__2024-04-29T07:35:08.227539+00:00 [running]> on host 42bc25d25e16
[2024-04-29T07:35:09.578+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Vaibhav Sharma' AIRFLOW_CTX_DAG_ID='etl_reddit_pipeline' AIRFLOW_CTX_TASK_ID='reddit_api_extraction' AIRFLOW_CTX_EXECUTION_DATE='2024-04-29T07:35:08.227539+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-04-29T07:35:08.227539+00:00'
[2024-04-29T07:35:09.589+0000] {logging_mixin.py:151} INFO - connected to reddit!
[2024-04-29T07:35:10.171+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hello everyone, I uploaded a PySpark course to my YouTube channel. I tried to cover wide range of topics including SparkContext and SparkSession, Resilient Distributed Datasets (RDDs), DataFrame and Dataset APIs, Data Cleaning and Preprocessing, Exploratory Data Analysis, Data Transformation and Manipulation, Group By and Window ,User Defined Functions and Machine Learning with Spark MLlib. I am leaving the link to this post, have a great day!\n\n\n\n[https://www.youtube.com/watch?v=jWZ9K1agm5Y&list=PLTsu3dft3CWiow7L7WrCd27ohlra\\_5PGH&index=9&t=1s](https://www.youtube.com/watch?v=jWZ9K1agm5Y&list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&index=9&t=1s)', 'author_fullname': 't2_me12im5a', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'I recorded a Python PySpark Big Data Course and uploaded it on YouTube', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cf6vob', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.89, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 64, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 64, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'post_hint': 'self', 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714312281.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello everyone, I uploaded a PySpark course to my YouTube channel. I tried to cover wide range of topics including SparkContext and SparkSession, Resilient Distributed Datasets (RDDs), DataFrame and Dataset APIs, Data Cleaning and Preprocessing, Exploratory Data Analysis, Data Transformation and Manipulation, Group By and Window ,User Defined Functions and Machine Learning with Spark MLlib. I am leaving the link to this post, have a great day!</p>\n\n<p><a href="https://www.youtube.com/watch?v=jWZ9K1agm5Y&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;index=9&amp;t=1s">https://www.youtube.com/watch?v=jWZ9K1agm5Y&amp;list=PLTsu3dft3CWiow7L7WrCd27ohlra_5PGH&amp;index=9&amp;t=1s</a></p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'preview': {'images': [{'source': {'url': 'https://external-preview.redd.it/RoGlDlJ5EeMkuIDG7L0h1ZJAjJdSDFruFNFfE3aJSJo.jpg?auto=webp&s=fd1fe186d37ce12f0889670e7390f48d531f5a76', 'width': 480, 'height': 360}, 'resolutions': [{'url': 'https://external-preview.redd.it/RoGlDlJ5EeMkuIDG7L0h1ZJAjJdSDFruFNFfE3aJSJo.jpg?width=108&crop=smart&auto=webp&s=649b28490eddddcd1cb82b5e5fb771c3966fd913', 'width': 108, 'height': 81}, {'url': 'https://external-preview.redd.it/RoGlDlJ5EeMkuIDG7L0h1ZJAjJdSDFruFNFfE3aJSJo.jpg?width=216&crop=smart&auto=webp&s=6eb7c9668133830060ceefb88fe4724109e5fc8d', 'width': 216, 'height': 162}, {'url': 'https://external-preview.redd.it/RoGlDlJ5EeMkuIDG7L0h1ZJAjJdSDFruFNFfE3aJSJo.jpg?width=320&crop=smart&auto=webp&s=cb0f364e17c913ba0838097b292bc0a0aa50d917', 'width': 320, 'height': 240}], 'variants': {}, 'id': 'CDiJRNVf3_txLk4dA8nvyevdXUhspqATqRzfkv2sPLc'}], 'enabled': False}, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1cf6vob', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='onurbaltaci'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cf6vob/i_recorded_a_python_pyspark_big_data_course_and/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cf6vob/i_recorded_a_python_pyspark_big_data_course_and/', 'subreddit_subscribers': 179737, 'created_utc': 1714312281.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.172+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'At various stages of the pipeline from development to deployment, what aspects of security do you consider? I am thinking along the lines of :\n\n* Principle of least privilege in general\n* Secure Developer access to cluster(Oauth/OIDC)\n* Encryption at rest/Encryption in transit\n* CICD pipeline with DevSecOps & proper SAST, DAST tooling \n* PII anonymization in logs\n\n\n\nPlease tell how you approach it at your work. If you have any resource suggestion to learn more on these, especially in context of data engineering, that would be great too.', 'author_fullname': 't2_g4v8h', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What security aspects do you consider when designing data pipeline from scratch?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cf77oy', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.9, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 39, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 39, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714313202.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>At various stages of the pipeline from development to deployment, what aspects of security do you consider? I am thinking along the lines of :</p>\n\n<ul>\n<li>Principle of least privilege in general</li>\n<li>Secure Developer access to cluster(Oauth/OIDC)</li>\n<li>Encryption at rest/Encryption in transit</li>\n<li>CICD pipeline with DevSecOps &amp; proper SAST, DAST tooling </li>\n<li>PII anonymization in logs</li>\n</ul>\n\n<p>Please tell how you approach it at your work. If you have any resource suggestion to learn more on these, especially in context of data engineering, that would be great too.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cf77oy', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='swapripper'), 'discussion_type': None, 'num_comments': 24, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cf77oy/what_security_aspects_do_you_consider_when/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cf77oy/what_security_aspects_do_you_consider_when/', 'subreddit_subscribers': 179737, 'created_utc': 1714313202.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.173+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Pretty much the title!!! \n\nIs there something that you have implemented and was liked by everybody and even better if it resulted in savings in term or efforts/cost.', 'author_fullname': 't2_qs0gyvrr5', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What is one solution/idea that you implemented in your organization and you are proud of?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfkl30', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.92, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 30, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 30, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714347387.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Pretty much the title!!! </p>\n\n<p>Is there something that you have implemented and was liked by everybody and even better if it resulted in savings in term or efforts/cost.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cfkl30', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='entitled-hypocrite'), 'discussion_type': None, 'num_comments': 26, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfkl30/what_is_one_solutionidea_that_you_implemented_in/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfkl30/what_is_one_solutionidea_that_you_implemented_in/', 'subreddit_subscribers': 179737, 'created_utc': 1714347387.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.173+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Before all the cloud databases/data lakehouses like Snowflake, Redshift, Databricks came on the seen, most data warehouses I saw were on-premises using SQL Server or PostgreSQL.\n\nAt one company I worked at, our largest fact tables had slightly above 500 million rows on SQL Server. Query performance wasn’t too bad, some queries would run in a couple minutes and only the most complex queries would take 20 - 60 minutes max. \n\nI’m trying to understand from others experiences:\n\n1. What’s the limit of an on-premise data warehouse on PostgreSQL or SQL Server? I’m assuming this depends heavily on the size of the server either of the aforementioned RDBMS are installed on? At a certain point though, you can only get so large of a server so there must be a limit?\n\n2. What’s the largest amount of data you’ve been able to query in an on-premises database while still having reasonable query times? \n\n3. At what point do you know you truly need to spend money to move to Snowflake or Databricks? \n\nAt my current job, our largest fact table has around 80 billion rows, most of our other fact tables have a couple billion rows while our Dimension tables have at max a couple million rows. So I can understand why we need Snowflake, Databricks, or Redshift but I’ve seen some places use Databricks and their largest tables are barely over 200 million rows… \n', 'author_fullname': 't2_8wpw0e1t', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'At what size did your companies on-premises Data Warehouse grow to that required moving to cloud databases like Snowflake, Redshift, etc? ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfpoua', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.95, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 15, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 15, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1714363746.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714362946.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Before all the cloud databases/data lakehouses like Snowflake, Redshift, Databricks came on the seen, most data warehouses I saw were on-premises using SQL Server or PostgreSQL.</p>\n\n<p>At one company I worked at, our largest fact tables had slightly above 500 million rows on SQL Server. Query performance wasn’t too bad, some queries would run in a couple minutes and only the most complex queries would take 20 - 60 minutes max. </p>\n\n<p>I’m trying to understand from others experiences:</p>\n\n<ol>\n<li><p>What’s the limit of an on-premise data warehouse on PostgreSQL or SQL Server? I’m assuming this depends heavily on the size of the server either of the aforementioned RDBMS are installed on? At a certain point though, you can only get so large of a server so there must be a limit?</p></li>\n<li><p>What’s the largest amount of data you’ve been able to query in an on-premises database while still having reasonable query times? </p></li>\n<li><p>At what point do you know you truly need to spend money to move to Snowflake or Databricks? </p></li>\n</ol>\n\n<p>At my current job, our largest fact table has around 80 billion rows, most of our other fact tables have a couple billion rows while our Dimension tables have at max a couple million rows. So I can understand why we need Snowflake, Databricks, or Redshift but I’ve seen some places use Databricks and their largest tables are barely over 200 million rows… </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cfpoua', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='khaili109'), 'discussion_type': None, 'num_comments': 15, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfpoua/at_what_size_did_your_companies_onpremises_data/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfpoua/at_what_size_did_your_companies_onpremises_data/', 'subreddit_subscribers': 179737, 'created_utc': 1714362946.0, 'num_crossposts': 1, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.174+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Curious what you're on-call rotation (if you have one) looks like for Data Engineering and Data Teams? Do you have something defined, including weekends, what kind of hours? Or do you never have to be on call?", 'author_fullname': 't2_hdte75ow1', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'What does your "On-Call" look like?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfgbak', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.89, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 13, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 13, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714336331.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Curious what you&#39;re on-call rotation (if you have one) looks like for Data Engineering and Data Teams? Do you have something defined, including weekends, what kind of hours? Or do you never have to be on call?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cfgbak', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='dataengineeringdude'), 'discussion_type': None, 'num_comments': 14, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfgbak/what_does_your_oncall_look_like/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfgbak/what_does_your_oncall_look_like/', 'subreddit_subscribers': 179737, 'created_utc': 1714336331.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.174+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I identify myself as ambitious Data Engineer and want to be the person people ask for advice on the latest technologies and projects.', 'author_fullname': 't2_6f1oduvf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How do you make sure to work in the latest/most interesting projects in your company to secure personal growth', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cf4x6j', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.74, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 12, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 12, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714306215.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I identify myself as ambitious Data Engineer and want to be the person people ask for advice on the latest technologies and projects.</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1cf4x6j', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Zestyclose-Ad-5400'), 'discussion_type': None, 'num_comments': 13, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cf4x6j/how_do_you_make_sure_to_work_in_the_latestmost/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cf4x6j/how_do_you_make_sure_to_work_in_the_latestmost/', 'subreddit_subscribers': 179737, 'created_utc': 1714306215.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.175+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "My background leans towards solid-state physics, and I've been working as an R&D engineer for the last 5+ years. \n\nI'm looking for a career with more geographic mobility (should've become a physician but I think that boat has sailed). In my current field, all the well-paying jobs are primarily in the Bay Area. I'd like to have the ability to move to another state some day, and I see SWE/IT/CS jobs generally get paid decently in most large cities (100k-150k). \n\nMy interest in data is the quality of that data (how it was obtained, what it represents, etc.), and how useful it is to make data-driven decisions. From a first principles standpoint, if your model is taking in data with many confounding factors - it won't be reliable. \n\nIt seems data *scientist* would be the most natural transition, since I already do some of that in my current role. My thought is that practicing data *engineering* would give me a more complete toolbox. Dream job would be doing a data-related role at a scientific company, but if that's not available, healthcare/finance/manufacturing/gov would all be great as well. \n\nHas anyone made a transition like this? \n\n\n--\n\nThe other option would be to go the Product Management route, like what a particular Materials Engineer did and ended up heading one of the world's largest SW companies.\n\n--\n\nEdit: A third option would be to practice Embedded SWE. Perhaps that would be a better fit for someone coming from physics/scientist background. \n", 'author_fullname': 't2_2wn6zpc8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Anyone move from physics/scientist/general engineering to Data Engineering?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfgcet', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.87, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 11, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 11, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': 1714338683.0, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714336405.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>My background leans towards solid-state physics, and I&#39;ve been working as an R&amp;D engineer for the last 5+ years. </p>\n\n<p>I&#39;m looking for a career with more geographic mobility (should&#39;ve become a physician but I think that boat has sailed). In my current field, all the well-paying jobs are primarily in the Bay Area. I&#39;d like to have the ability to move to another state some day, and I see SWE/IT/CS jobs generally get paid decently in most large cities (100k-150k). </p>\n\n<p>My interest in data is the quality of that data (how it was obtained, what it represents, etc.), and how useful it is to make data-driven decisions. From a first principles standpoint, if your model is taking in data with many confounding factors - it won&#39;t be reliable. </p>\n\n<p>It seems data <em>scientist</em> would be the most natural transition, since I already do some of that in my current role. My thought is that practicing data <em>engineering</em> would give me a more complete toolbox. Dream job would be doing a data-related role at a scientific company, but if that&#39;s not available, healthcare/finance/manufacturing/gov would all be great as well. </p>\n\n<p>Has anyone made a transition like this? </p>\n\n<h2></h2>\n\n<p>The other option would be to go the Product Management route, like what a particular Materials Engineer did and ended up heading one of the world&#39;s largest SW companies.</p>\n\n<h2></h2>\n\n<p>Edit: A third option would be to practice Embedded SWE. Perhaps that would be a better fit for someone coming from physics/scientist background. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1cfgcet', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='go_go_go_go_go_go'), 'discussion_type': None, 'num_comments': 9, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfgcet/anyone_move_from_physicsscientistgeneral/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfgcet/anyone_move_from_physicsscientistgeneral/', 'subreddit_subscribers': 179737, 'created_utc': 1714336405.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.175+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'And please don\'t say "anywhere". I already know a decent bit of surrounding topics, yet simultaneously so little when it comes to the core of data engineering. I wrote here cause I hope to get human perspective instead of chatgpt starting to hallucinate a list of 6 different unnecessary techs I would need for such a solution, and who knows not up-to-date in even that.\n\nI know python quite well. I know SQL queries and have dabbled a bit with databases (both creating my own with python & sqlite as well as working on a proper one, though not a warehouse, as an analyst). I also understand the basics of cloud technologies and have worked a bit with Azure. I even studied some databricks on a conceptual level and know a bit of spark from before, but the latter was as part of a uni course and on Scala.\n\nI\'d like to create a full-on ETL process with modern tools, and understand how exactly different tools are related. (This is a real project, but also a learning experience) I want to create an ETL process which would pull data from two separate REST APIs, Google Drives, and a MS SQL Server, transform it, and load it into some reasonable source (I\'ve ofc heard how delta tables are the hot new thing but idk if in relatively small scale spark would make sense & if I should go for some SQL solution instead), then "run the code" i.e. "refresh" e.g. once a day. Now, I would prefer to not start making investments, so there\'s that, too. I have access to Azure but would like to keep the expenses to minimum and e.g. not start learning data factory for this. I\'d prefer to do the ET + orchestration part outside Azure tools at least.\n\nI more or less know this could be done with python, and even then using many combinations of libraries, \n\nbut what tools would a data engineer use? I\'ve heard of e.g. dbt which seems to have it\'s own product, yet you can also install it for free with pip (what\'s up?) I keep hearing of airflow and airbyte. Are they both fot orchestration? I\'ve heard & read for other techs, but these are some I\'m curious about.\n\nI\'d really appreciate a couple of sentemces how you would start approaching a problem like this. Cheers', 'author_fullname': 't2_7cors5yi', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Practical project: Where to start as a DE newbie', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfaj43', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.91, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 9, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 9, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714321964.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>And please don&#39;t say &quot;anywhere&quot;. I already know a decent bit of surrounding topics, yet simultaneously so little when it comes to the core of data engineering. I wrote here cause I hope to get human perspective instead of chatgpt starting to hallucinate a list of 6 different unnecessary techs I would need for such a solution, and who knows not up-to-date in even that.</p>\n\n<p>I know python quite well. I know SQL queries and have dabbled a bit with databases (both creating my own with python &amp; sqlite as well as working on a proper one, though not a warehouse, as an analyst). I also understand the basics of cloud technologies and have worked a bit with Azure. I even studied some databricks on a conceptual level and know a bit of spark from before, but the latter was as part of a uni course and on Scala.</p>\n\n<p>I&#39;d like to create a full-on ETL process with modern tools, and understand how exactly different tools are related. (This is a real project, but also a learning experience) I want to create an ETL process which would pull data from two separate REST APIs, Google Drives, and a MS SQL Server, transform it, and load it into some reasonable source (I&#39;ve ofc heard how delta tables are the hot new thing but idk if in relatively small scale spark would make sense &amp; if I should go for some SQL solution instead), then &quot;run the code&quot; i.e. &quot;refresh&quot; e.g. once a day. Now, I would prefer to not start making investments, so there&#39;s that, too. I have access to Azure but would like to keep the expenses to minimum and e.g. not start learning data factory for this. I&#39;d prefer to do the ET + orchestration part outside Azure tools at least.</p>\n\n<p>I more or less know this could be done with python, and even then using many combinations of libraries, </p>\n\n<p>but what tools would a data engineer use? I&#39;ve heard of e.g. dbt which seems to have it&#39;s own product, yet you can also install it for free with pip (what&#39;s up?) I keep hearing of airflow and airbyte. Are they both fot orchestration? I&#39;ve heard &amp; read for other techs, but these are some I&#39;m curious about.</p>\n\n<p>I&#39;d really appreciate a couple of sentemces how you would start approaching a problem like this. Cheers</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cfaj43', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Skin_Life'), 'discussion_type': None, 'num_comments': 11, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfaj43/practical_project_where_to_start_as_a_de_newbie/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfaj43/practical_project_where_to_start_as_a_de_newbie/', 'subreddit_subscribers': 179737, 'created_utc': 1714321964.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.176+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Does anyone have ideas on how to implement real time streaming in Databricks to AWS SQS?\n\nWe currently have CDC data getting pushed to S3 and we have auto-loader stream this data to Databricks bronze layer. \n\nWe will build SCD1 in silver and build business logic in gold. From gold we want to send the data to SQS from where application team consume the transformed data. All the solutions we’ve currently tried are taking 3-5 mins. \n\nHas anyone implemented something similar to this before and if so how did you do it to achieve near realtime streaming? Basically when there is an update in the source, we want that update to reach SQS in almost real time <10 seconds at most. \n', 'author_fullname': 't2_4l8znnwf', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Real Time Streaming In Databricks ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfjejr', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.89, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 7, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Discussion', 'can_mod_post': False, 'score': 7, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714344163.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Does anyone have ideas on how to implement real time streaming in Databricks to AWS SQS?</p>\n\n<p>We currently have CDC data getting pushed to S3 and we have auto-loader stream this data to Databricks bronze layer. </p>\n\n<p>We will build SCD1 in silver and build business logic in gold. From gold we want to send the data to SQS from where application team consume the transformed data. All the solutions we’ve currently tried are taking 3-5 mins. </p>\n\n<p>Has anyone implemented something similar to this before and if so how did you do it to achieve near realtime streaming? Basically when there is an update in the source, we want that update to reach SQS in almost real time &lt;10 seconds at most. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '92b74b58-aaca-11eb-b160-0e6181e3773f', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff4500', 'id': '1cfjejr', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='ChemicalBig3632'), 'discussion_type': None, 'num_comments': 10, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfjejr/real_time_streaming_in_databricks/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfjejr/real_time_streaming_in_databricks/', 'subreddit_subscribers': 179737, 'created_utc': 1714344163.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.176+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hi all,\n\n  \nCurrently working as a Technical Data Analyst in an SME, with just over 2 years of experience. In terms of technical tools, I'm using a lot of Python daily to develop all sorts of report automation solutions and SQL. I like my current company (good benefits, culture) but realistically speaking there's not much left for me in terms of career progression anymore (at least in a short-to-medium timeframe) given my company's current priorities and my own career aspirations.\n\n  \nI have an iterview lined up with a significantly larger company for the role of data warehouse engineer. It seems like a good fit as I match most of the essential requirements (trying to move from DA to DE has been a real challenge as the market for junior roles is extremely competitive). Similar to my current employer, the company seems to be good in terms of culture, benefits etc. However, the technical tools listed in the description are giving me doubts.\n\nBesides the usual suspects (Python/SQL), they mention Netezza, Perl, SQLServer - most of which seem to be a bit outdated to me? This made me think that I might have even more troubles in a few years if I want to switch to an actual DE position with a more modern stack.\n\nAm I just overthinking?", 'author_fullname': 't2_7zqeh9vu', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Trying to break into DE - got a dilemma', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cf4wi1', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.69, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 6, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 6, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714306153.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi all,</p>\n\n<p>Currently working as a Technical Data Analyst in an SME, with just over 2 years of experience. In terms of technical tools, I&#39;m using a lot of Python daily to develop all sorts of report automation solutions and SQL. I like my current company (good benefits, culture) but realistically speaking there&#39;s not much left for me in terms of career progression anymore (at least in a short-to-medium timeframe) given my company&#39;s current priorities and my own career aspirations.</p>\n\n<p>I have an iterview lined up with a significantly larger company for the role of data warehouse engineer. It seems like a good fit as I match most of the essential requirements (trying to move from DA to DE has been a real challenge as the market for junior roles is extremely competitive). Similar to my current employer, the company seems to be good in terms of culture, benefits etc. However, the technical tools listed in the description are giving me doubts.</p>\n\n<p>Besides the usual suspects (Python/SQL), they mention Netezza, Perl, SQLServer - most of which seem to be a bit outdated to me? This made me think that I might have even more troubles in a few years if I want to switch to an actual DE position with a more modern stack.</p>\n\n<p>Am I just overthinking?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1cf4wi1', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='rolledsausage'), 'discussion_type': None, 'num_comments': 8, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cf4wi1/trying_to_break_into_de_got_a_dilemma/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cf4wi1/trying_to_break_into_de_got_a_dilemma/', 'subreddit_subscribers': 179737, 'created_utc': 1714306153.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.177+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hello all, \nI am trying to use spark with kubernetes. The installation part is done. But when I try to read through a 3GB CSV file, it doesn't increase the number of pods.\n\nConfig:\nI haven't attached any GPU, instead I went with CPU with 4 cores, and set the executor memory as 2GB. ", 'author_fullname': 't2_n4l51yqm8', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Spark with kubernetes ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfopsf', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714359700.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hello all, \nI am trying to use spark with kubernetes. The installation part is done. But when I try to read through a 3GB CSV file, it doesn&#39;t increase the number of pods.</p>\n\n<p>Config:\nI haven&#39;t attached any GPU, instead I went with CPU with 4 cores, and set the executor memory as 2GB. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cfopsf', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Excellent-Silver4135'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfopsf/spark_with_kubernetes/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfopsf/spark_with_kubernetes/', 'subreddit_subscribers': 179737, 'created_utc': 1714359700.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.177+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi guys,\n\nI\'m looking to set up a rather simple data "pipeline" (at least I think that\'s what I\'m trying to do!).\n\nInput (for one of the pipelines):\n\nREST API serving up financial records.\n\nTarget destination: PostgreSQL.\n\nThis is an open-source "open data" type project so I\'ve focused mostly on self-hostable open access type solutions.\n\nSo far I\'ve stumbled upon:\n\n\\- Airbyte\n\n\\- Apache Airflow\n\n\\- Dagster\n\n\\- Luigi\n\nI know this hub slants towards a practitioner audience (where presumably you\'re not as constrained by budget as I am). But nevertheless, I thought I\'d see if anyone has thoughts as to the respective merits of these tools.\n\nI\'m provisioning on a Linux VPS (I\'ve given up on trying to make Kubernetes \'work\'). And - as almost always - my strong preference is to whatever is the easiest to just get working for this use-case.\n\nTIA! ', 'author_fullname': 't2_poc45', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Thoughts on self-hosted data pipelines / "orchestrators"?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cf8wml', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.83, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 4, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Open Source', 'can_mod_post': False, 'score': 4, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714317792.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi guys,</p>\n\n<p>I&#39;m looking to set up a rather simple data &quot;pipeline&quot; (at least I think that&#39;s what I&#39;m trying to do!).</p>\n\n<p>Input (for one of the pipelines):</p>\n\n<p>REST API serving up financial records.</p>\n\n<p>Target destination: PostgreSQL.</p>\n\n<p>This is an open-source &quot;open data&quot; type project so I&#39;ve focused mostly on self-hostable open access type solutions.</p>\n\n<p>So far I&#39;ve stumbled upon:</p>\n\n<p>- Airbyte</p>\n\n<p>- Apache Airflow</p>\n\n<p>- Dagster</p>\n\n<p>- Luigi</p>\n\n<p>I know this hub slants towards a practitioner audience (where presumably you&#39;re not as constrained by budget as I am). But nevertheless, I thought I&#39;d see if anyone has thoughts as to the respective merits of these tools.</p>\n\n<p>I&#39;m provisioning on a Linux VPS (I&#39;ve given up on trying to make Kubernetes &#39;work&#39;). And - as almost always - my strong preference is to whatever is the easiest to just get working for this use-case.</p>\n\n<p>TIA! </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '3957ca64-3440-11ed-8329-2aa6ad243a59', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#005ba1', 'id': '1cf8wml', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='danielrosehill'), 'discussion_type': None, 'num_comments': 10, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cf8wml/thoughts_on_selfhosted_data_pipelines/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cf8wml/thoughts_on_selfhosted_data_pipelines/', 'subreddit_subscribers': 179737, 'created_utc': 1714317792.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.177+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Not sure how relevant the GCP part is - but basically what I want to do is script the setup of *** via terraform etc.   \n  \nI can setup the project / compute instance and so on with terraform but I'm not sure how to go about managing the *** part - installation / conf file changes and so on. I'm not sure how others typically go about managing this as I've not seen it done and can't seem to find any guides on it, so just curious whether anyone here has gone through this.   ", 'author_fullname': 't2_tczfts4v', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'How to automate (***) database setup on (gcp) compute instance with terraform etc? ', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cf2qy5', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714297991.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Not sure how relevant the GCP part is - but basically what I want to do is script the setup of *** via terraform etc.   </p>\n\n<p>I can setup the project / compute instance and so on with terraform but I&#39;m not sure how to go about managing the *** part - installation / conf file changes and so on. I&#39;m not sure how others typically go about managing this as I&#39;ve not seen it done and can&#39;t seem to find any guides on it, so just curious whether anyone here has gone through this.   </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cf2qy5', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Subject_Fix2471'), 'discussion_type': None, 'num_comments': 6, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cf2qy5/how_to_automate_***_database_setup_on_gcp/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cf2qy5/how_to_automate_***_database_setup_on_gcp/', 'subreddit_subscribers': 179737, 'created_utc': 1714297991.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.178+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "Hi All,\n\nI am planning to appear for DP-203 Microsoft exam in coming month. I have been preparing for the exam since last 1.5 months and have gone through the learning path, Some YouTube questionaires and Microsoft practice tests. \n\nI'm truly trying to understand if I'm ready for the exam. cause in some tests , I'm able to answer most questions correctly while in other I find it hard to even understand the questions. \n\nSome doubts about the exam which I have are as follows \n\n1. For multi select questions, do we get points for the correct options which we have selected? Assuming I selected only subset of them correct?\n2. Same as question 1 , but for multi select with order.\n3. How many case studies do we usually have in exam ? \n4. How the marking system works ?\n5. How do we deal with different security feature questions, as there are quite alot of them and I'm finding it hard to keep track of what supports what ?\n\n\n\nApart from these questions, any additional tips are welcome .", 'author_fullname': 't2_sscx8oda', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Doubts about Microsoft DP-203', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfcfe2', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 3, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 3, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714326806.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi All,</p>\n\n<p>I am planning to appear for DP-203 Microsoft exam in coming month. I have been preparing for the exam since last 1.5 months and have gone through the learning path, Some YouTube questionaires and Microsoft practice tests. </p>\n\n<p>I&#39;m truly trying to understand if I&#39;m ready for the exam. cause in some tests , I&#39;m able to answer most questions correctly while in other I find it hard to even understand the questions. </p>\n\n<p>Some doubts about the exam which I have are as follows </p>\n\n<ol>\n<li>For multi select questions, do we get points for the correct options which we have selected? Assuming I selected only subset of them correct?</li>\n<li>Same as question 1 , but for multi select with order.</li>\n<li>How many case studies do we usually have in exam ? </li>\n<li>How the marking system works ?</li>\n<li>How do we deal with different security feature questions, as there are quite alot of them and I&#39;m finding it hard to keep track of what supports what ?</li>\n</ol>\n\n<p>Apart from these questions, any additional tips are welcome .</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cfcfe2', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Substantial_Lion8436'), 'discussion_type': None, 'num_comments': 7, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfcfe2/doubts_about_microsoft_dp203/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfcfe2/doubts_about_microsoft_dp203/', 'subreddit_subscribers': 179737, 'created_utc': 1714326806.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.178+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'In snowflake, the precision of a timestamp is max 9: timestamp_ntz(9).\n\nThe 9 - in snowflake - refers to the fraction of seconds represented in the time stamp; with 9 being nanoseconds, 6 being microseconds, 3 milliseconds etc.\n\nMy understanding is Informatica uses the scale value in the data type for representing the fraction of second the data type can represent. While date/time(29,9) would hold data at the granularity of a nanosecond, the date/time(20,0) would be a time stamp represented at the granularity of 1 second.\n\nWhat parts of the time stamp would be truncated if I further reduce Informatica’s precision digit below 20?\n\nWhat physically in the date/time does the precision of 20 (or any other precision value) represent?', 'author_fullname': 't2_27wfgi26', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Informatica Date/Time Data Type - in the (29,9) precision/scale, what does the 29 refer to?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cf3ssf', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.63, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714302186.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>In snowflake, the precision of a timestamp is max 9: timestamp_ntz(9).</p>\n\n<p>The 9 - in snowflake - refers to the fraction of seconds represented in the time stamp; with 9 being nanoseconds, 6 being microseconds, 3 milliseconds etc.</p>\n\n<p>My understanding is Informatica uses the scale value in the data type for representing the fraction of second the data type can represent. While date/time(29,9) would hold data at the granularity of a nanosecond, the date/time(20,0) would be a time stamp represented at the granularity of 1 second.</p>\n\n<p>What parts of the time stamp would be truncated if I further reduce Informatica’s precision digit below 20?</p>\n\n<p>What physically in the date/time does the precision of 20 (or any other precision value) represent?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cf3ssf', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='eubann'), 'discussion_type': None, 'num_comments': 2, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cf3ssf/informatica_datetime_data_type_in_the_299/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cf3ssf/informatica_datetime_data_type_in_the_299/', 'subreddit_subscribers': 179737, 'created_utc': 1714302186.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.179+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "I've been doing interviews and I've seen now more than before that companies are using Snowflake to store their Data Warehouses. \n\nI've been working all my data career with Azure, the equivalent platform would be Azure Synapse Analytics... If I've been working with Azure Synapse do you think it's important to learn about Snowflake and highlight it on my CV?\n\n&#x200B;\n\nThanks", 'author_fullname': 't2_6bblasam', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': "It's important to learn Snowflake nowadays?", 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfbkya', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 2, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Career', 'can_mod_post': False, 'score': 2, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714324663.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I&#39;ve been doing interviews and I&#39;ve seen now more than before that companies are using Snowflake to store their Data Warehouses. </p>\n\n<p>I&#39;ve been working all my data career with Azure, the equivalent platform would be Azure Synapse Analytics... If I&#39;ve been working with Azure Synapse do you think it&#39;s important to learn about Snowflake and highlight it on my CV?</p>\n\n<p>&#x200B;</p>\n\n<p>Thanks</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': False, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '069dd614-a7dc-11eb-8e48-0e90f49436a3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#349e48', 'id': '1cfbkya', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Irachar'), 'discussion_type': None, 'num_comments': 3, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfbkya/its_important_to_learn_snowflake_nowadays/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfbkya/its_important_to_learn_snowflake_nowadays/', 'subreddit_subscribers': 179737, 'created_utc': 1714324663.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.179+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'I am using a Json file to create an automated newsfeed. Now I would like to read it like a feed reader and annotate to this file on my iPhone, Ipad or Macbook. I tried "Jayson" but its a little clumsy as you always have to navigate the folder structure back and forth to move between objects and you have to open each value inside the object like title and text body to be able to read the full text. Ideally I would like to swipe or tap to switch to the next object and then see the full values for "Titel" and "full text" on the screen. Is there anything that can help me? I could just read the plain json file but that\'s a little clumsy, especially when I want to edit and edit a boolean value to select some objects. ', 'author_fullname': 't2_bjdqlnl8g', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Json-Reader to read json like an RSS-Feed on IOS or Macos', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': True, 'name': 't3_1cfsa2g', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 1.0, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Blog', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714372343.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>I am using a Json file to create an automated newsfeed. Now I would like to read it like a feed reader and annotate to this file on my iPhone, Ipad or Macbook. I tried &quot;Jayson&quot; but its a little clumsy as you always have to navigate the folder structure back and forth to move between objects and you have to open each value inside the object like title and text body to be able to read the full text. Ideally I would like to swipe or tap to switch to the next object and then see the full values for &quot;Titel&quot; and &quot;full text&quot; on the screen. Is there anything that can help me? I could just read the plain json file but that&#39;s a little clumsy, especially when I want to edit and edit a boolean value to select some objects. </p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'eb739554-a7db-11eb-95d7-0ec0f8f30313', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#0079d3', 'id': '1cfsa2g', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Naht-Tuner'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfsa2g/jsonreader_to_read_json_like_an_rssfeed_on_ios_or/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfsa2g/jsonreader_to_read_json_like_an_rssfeed_on_ios_or/', 'subreddit_subscribers': 179737, 'created_utc': 1714372343.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.180+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "So I joined as DE in a consulting company right after got my Masters degree in MIS. And I have been on the newly awarded project since the beginning, it is about 7 months now. I am junior DE. \nThe problem is things are changing so fast, I was told to use one platform and then switched to other platforms, and back and forth in 7months. I understand that everything is just started so we those leaders are taking many different approaches for optimized solutions  .  \nWhen I felt like I'm expert at one tool that I just learned,  and next day I have to move to other tool for dev/test.  \n\nI feel like there are many opportunities to learn and growth but I can not digest so much in such fast changing learning environment.  \nI want to be an expert at one platform for example like Azure/AWS. But with this project I think I am not doing well. \nAny advice or suggestions ?", 'author_fullname': 't2_93kk2trt', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Data engineer project/ I have no idea', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cflbh4', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714349459.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>So I joined as DE in a consulting company right after got my Masters degree in MIS. And I have been on the newly awarded project since the beginning, it is about 7 months now. I am junior DE. \nThe problem is things are changing so fast, I was told to use one platform and then switched to other platforms, and back and forth in 7months. I understand that everything is just started so we those leaders are taking many different approaches for optimized solutions  .<br/>\nWhen I felt like I&#39;m expert at one tool that I just learned,  and next day I have to move to other tool for dev/test.  </p>\n\n<p>I feel like there are many opportunities to learn and growth but I can not digest so much in such fast changing learning environment.<br/>\nI want to be an expert at one platform for example like Azure/AWS. But with this project I think I am not doing well. \nAny advice or suggestions ?</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cflbh4', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Haneeeio'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cflbh4/data_engineer_project_i_have_no_idea/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cflbh4/data_engineer_project_i_have_no_idea/', 'subreddit_subscribers': 179737, 'created_utc': 1714349459.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.180+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': 'Hi guys \n\nAs a data engineer I always struggled to connect SAP data sources like SAP Hana with external Systems like Snowflake. How hard could it be to expose SAP data from certain modules directly in Snowflake and how could we implement that? I would really like to make SAP a less monopolistic data provider. \n\nCheers', 'author_fullname': 't2_793tedn0', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Building a native Connector in Snowflake to pull SAP Data?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfakwy', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.67, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 1, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Help', 'can_mod_post': False, 'score': 1, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714322092.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>Hi guys </p>\n\n<p>As a data engineer I always struggled to connect SAP data sources like SAP Hana with external Systems like Snowflake. How hard could it be to expose SAP data from certain modules directly in Snowflake and how could we implement that? I would really like to make SAP a less monopolistic data provider. </p>\n\n<p>Cheers</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': '2ca94cd6-ac27-11eb-a8eb-0e7f457f5bd3', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ea0027', 'id': '1cfakwy', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='Ok-Sentence-8542'), 'discussion_type': None, 'num_comments': 4, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfakwy/building_a_native_connector_in_snowflake_to_pull/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfakwy/building_a_native_connector_in_snowflake_to_pull/', 'subreddit_subscribers': 179737, 'created_utc': 1714322092.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.180+0000] {logging_mixin.py:151} INFO - {'comment_limit': 2048, 'comment_sort': 'confidence', '_reddit': <praw.reddit.Reddit object at 0xffff74e696a0>, 'approved_at_utc': None, 'subreddit': Subreddit(display_name='dataengineering'), 'selftext': "EXEC SP_EXECUTESQL N'EXEC SP_EXECUTESQL N''EXEC SP_EXECUTESQL N'''…", 'author_fullname': 't2_6m8ji1eu', 'saved': False, 'mod_reason_title': None, 'gilded': 0, 'clicked': False, 'title': 'Has anyone ever wondered how deep it goes?', 'link_flair_richtext': [], 'subreddit_name_prefixed': 'r/dataengineering', 'hidden': False, 'pwls': 6, 'link_flair_css_class': '', 'downs': 0, 'thumbnail_height': None, 'top_awarded_type': None, 'hide_score': False, 'name': 't3_1cfkucf', 'quarantine': False, 'link_flair_text_color': 'light', 'upvote_ratio': 0.4, 'author_flair_background_color': None, 'subreddit_type': 'public', 'ups': 0, 'total_awards_received': 0, 'media_embed': {}, 'thumbnail_width': None, 'author_flair_template_id': None, 'is_original_content': False, 'user_reports': [], 'secure_media': None, 'is_reddit_media_domain': False, 'is_meta': False, 'category': None, 'secure_media_embed': {}, 'link_flair_text': 'Meme', 'can_mod_post': False, 'score': 0, 'approved_by': None, 'is_created_from_ads_ui': False, 'author_premium': False, 'thumbnail': 'self', 'edited': False, 'author_flair_css_class': None, 'author_flair_richtext': [], 'gildings': {}, 'content_categories': None, 'is_self': True, 'mod_note': None, 'created': 1714348129.0, 'link_flair_type': 'text', 'wls': 6, 'removed_by_category': None, 'banned_by': None, 'author_flair_type': 'text', 'domain': 'self.dataengineering', 'allow_live_comments': False, 'selftext_html': '<!-- SC_OFF --><div class="md"><p>EXEC SP_EXECUTESQL N&#39;EXEC SP_EXECUTESQL N&#39;&#39;EXEC SP_EXECUTESQL N&#39;&#39;&#39;…</p>\n</div><!-- SC_ON -->', 'likes': None, 'suggested_sort': None, 'banned_at_utc': None, 'view_count': None, 'archived': False, 'no_follow': True, 'is_crosspostable': False, 'pinned': False, 'over_18': False, 'all_awardings': [], 'awarders': [], 'media_only': False, 'link_flair_template_id': 'dc9742bc-a7de-11eb-a2e7-0e0348c8a4c1', 'can_gild': False, 'spoiler': False, 'locked': False, 'author_flair_text': None, 'treatment_tags': [], 'visited': False, 'removed_by': None, 'num_reports': None, 'distinguished': None, 'subreddit_id': 't5_36en4', 'author_is_blocked': False, 'mod_reason_by': None, 'removal_reason': None, 'link_flair_background_color': '#ff66ac', 'id': '1cfkucf', 'is_robot_indexable': True, 'report_reasons': None, 'author': Redditor(name='left-right-up-down1'), 'discussion_type': None, 'num_comments': 0, 'send_replies': True, 'whitelist_status': 'all_ads', 'contest_mode': False, 'mod_reports': [], 'author_patreon_flair': False, 'author_flair_text_color': None, 'permalink': '/r/dataengineering/comments/1cfkucf/has_anyone_ever_wondered_how_deep_it_goes/', 'parent_whitelist_status': 'all_ads', 'stickied': False, 'url': 'https://www.reddit.com/r/dataengineering/comments/1cfkucf/has_anyone_ever_wondered_how_deep_it_goes/', 'subreddit_subscribers': 179737, 'created_utc': 1714348129.0, 'num_crossposts': 0, 'media': None, 'is_video': False, '_fetched': False, '_additional_fetch_params': {}, '_comments_by_id': {}}
[2024-04-29T07:35:10.237+0000] {python.py:194} INFO - Done. Returned value was: /opt/airflow/data/output/reddit_20240429.csv
[2024-04-29T07:35:10.267+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=etl_reddit_pipeline, task_id=reddit_api_extraction, execution_date=20240429T073508, start_date=20240429T073509, end_date=20240429T073510
[2024-04-29T07:35:10.313+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2024-04-29T07:35:10.328+0000] {taskinstance.py:2778} INFO - 1 downstream tasks scheduled from follow-on schedule check
